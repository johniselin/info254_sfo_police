{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "# geospatial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# others\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# original\n",
    "from scripts.utils import exchange_coordinate, epsg_converter, df_2_geodf\n",
    "from scripts.utils import add_geometry, add_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code below can get the nearest weahter station data.\n",
    "- But it is computationally very intensive to calculate the nearest distance between polygon and point (point and point is much faster)\n",
    "- So, the average of weather stations in SF is used in stead of the nearest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_nearest_value(point, pts, geodf2, src_col):\n",
    "#     \"\"\"\n",
    "#     return value of src_col in nearest point in geodf2 \n",
    "#     \"\"\"\n",
    "#     nearest_point = nearest_points(point, pts)[1]\n",
    "#     value = geodf2.loc[geodf2[\"geometry\"] == nearest_point, src_col].values[0]\n",
    "    \n",
    "#     return value\n",
    "\n",
    "# # add nearest weather station data\n",
    "# pts = weather.geometry.unary_union\n",
    "# geodf[\"prcp\"] = geodf[:5].apply(lambda x: find_nearest_value(x.geometry, pts, weather, \"PRCP\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(geodf):\n",
    "    \"\"\"\n",
    "    return geodf with datetime columns\n",
    "    \"\"\"\n",
    "    geodf[\"year\"] = geodf.datetime.dt.year\n",
    "    geodf[\"month\"] = geodf.datetime.dt.month\n",
    "    geodf[\"woy\"] = geodf.datetime.dt.weekofyear \n",
    "    geodf[\"dow\"] = geodf.datetime.dt.dayofweek\n",
    "    geodf[\"weekend\"] = geodf[\"dow\"].apply(lambda x: 1 if x >=5 else 0) \n",
    "    geodf[\"hour\"] = geodf.datetime.dt.hour\n",
    "    \n",
    "    return geodf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exponentially weighted mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ewm weights more recent trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ewm(series, alpha, adjust=True, timesteps=1):\n",
    "    \"\"\"\n",
    "    return series with exponential weighted mean\n",
    "    \"\"\"\n",
    "    # shift data to avoid leakage\n",
    "    ewm = series.shift(timesteps).ewm(alpha=alpha, adjust=adjust).mean()\n",
    "    \n",
    "    return ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_ewm(geodf, groupby, alpha, adjust=True, timesteps=1):\n",
    "    \"\"\"\n",
    "    return dataframe with exponentaial weighted mean\n",
    "    \"\"\"\n",
    "    # calculate exponential weighted mean by each groupby unit\n",
    "    # multi-class\n",
    "    if \"incident_type_0\" in geodf.columns:\n",
    "        i_types = [\"incident_type_0\", \"incident_type_1\", \"incident_type_2\"]\n",
    "        for i_type in i_types:\n",
    "            roll = geodf.groupby(groupby).apply(lambda x: get_ewm(x[i_type], alpha, adjust, timesteps))\n",
    "            geodf[i_type + \"_ewm_\" + str(alpha)] = roll.sort_index(level = [groupby, \"datetime\"]).values\n",
    "        \n",
    "    # binary\n",
    "    elif \"crime\" in geodf.columns:\n",
    "        roll = geodf.groupby(groupby).apply(lambda x: get_ewm(x.crime, alpha, adjust, timesteps))\n",
    "        geodf[\"ewm_\" + str(alpha)] = roll.sort_index(level = [groupby, \"datetime\"]).values\n",
    "    \n",
    "    return geodf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (19,21,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load weather data\n",
    "weather = pd.read_csv('data/weather.csv')\n",
    "weather = exchange_coordinate(weather, lon=\"LONGITUDE\", lat=\"LATITUDE\", prefix=\"station\")\n",
    "crs = {'init':'epsg:4326'}\n",
    "weather = df_2_geodf(weather, crs, lon=\"station_lon_fix\", lat=\"station_lat_fix\")\n",
    "\n",
    "# load sf data\n",
    "sf = gpd.read_file(\"data/census2010_ sf_tracks.geojson\", crs=weather.crs)\n",
    "sf = sf[['geometry']]\n",
    "\n",
    "# extract only stations in SF\n",
    "weather_sf = gpd.sjoin(weather, sf, how=\"inner\", op=\"intersects\")\n",
    "weather_sf[\"date\"] = pd.to_datetime(weather_sf[\"DATE\"])\n",
    "weather_sf.set_index(\"date\", inplace=True)\n",
    "\n",
    "# get average precipitation per day\n",
    "weather_day = weather_sf.resample(\"1D\").agg({\"PRCP\": [\"mean\"],})\n",
    "weather_day.reset_index(inplace=True)\n",
    "weather_day.columns = [\"date\", \"prcp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/crime_counts/counts_binary_tract_1H.feather',\n",
       " 'data/crime_counts/counts_multi-class_tract_2H.feather',\n",
       " 'data/crime_counts/counts_binary_tract_2H.feather',\n",
       " 'data/crime_counts/counts_multi-class_tract_1H.feather']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all paths of crime counts files\n",
    "all_paths = glob.glob(\"data/crime_counts/*.feather\")\n",
    "n_paths = len(all_paths)\n",
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608efe3cb1614caabf2d806e00570b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 1 / 4 --------------\n",
      "[14:43:54] data/crime_counts/counts_binary_tract_1H.feather\n",
      "[14:43:55] loaded crime counts data (7334162, 3)\n",
      "[14:43:57] added geometry (7334162, 4)\n",
      "[14:44:02] added precipitation (7334162, 6)\n",
      "[14:44:06] converted datetime (7334162, 12)\n",
      "[14:44:14] saved at data/crime_counts/counts_binary_tract_1H.feather\n",
      "\n",
      "------------- 2 / 4 --------------\n",
      "[14:44:14] data/crime_counts/counts_multi-class_tract_2H.feather\n",
      "[14:44:14] loaded crime counts data (3667171, 5)\n",
      "[14:44:15] added geometry (3667171, 6)\n",
      "[14:44:17] added precipitation (3667171, 8)\n",
      "[14:44:19] converted datetime (3667171, 14)\n",
      "[14:44:23] saved at data/crime_counts/counts_multi-class_tract_2H.feather\n",
      "\n",
      "------------- 3 / 4 --------------\n",
      "[14:44:23] data/crime_counts/counts_binary_tract_2H.feather\n",
      "[14:44:23] loaded crime counts data (3667171, 3)\n",
      "[14:44:24] added geometry (3667171, 4)\n",
      "[14:44:26] added precipitation (3667171, 6)\n",
      "[14:44:28] converted datetime (3667171, 12)\n",
      "[14:44:32] saved at data/crime_counts/counts_binary_tract_2H.feather\n",
      "\n",
      "------------- 4 / 4 --------------\n",
      "[14:44:32] data/crime_counts/counts_multi-class_tract_1H.feather\n",
      "[14:44:32] loaded crime counts data (7334162, 5)\n",
      "[14:44:34] added geometry (7334162, 6)\n",
      "[14:44:38] added precipitation (7334162, 8)\n",
      "[14:44:42] converted datetime (7334162, 14)\n",
      "[14:44:52] saved at data/crime_counts/counts_multi-class_tract_1H.feather\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add features to all crime counts files\n",
    "for i, path in enumerate(tqdm(all_paths)):\n",
    "    \n",
    "    print(\"------------- {} / {} --------------\".format(i+1, n_paths))\n",
    "    print(\"[{0:%H:%M%:%S}] {1}\".format(datetime.now(), path))\n",
    "\n",
    "    # load crime counts data\n",
    "    df = feather.read_dataframe(path)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    print(\"[{0:%H:%M%:%S}] loaded crime counts data {1}\".format(datetime.now(), df.shape))\n",
    "\n",
    "    # convert to geodataframe\n",
    "    geodf = add_geometry(df, crs)\n",
    "    print(\"[{0:%H:%M%:%S}] added geometry {1}\".format(datetime.now(), geodf.shape))\n",
    "\n",
    "    # add precipitation\n",
    "    geodf = add_weather(geodf, weather_day)\n",
    "    print(\"[{0:%H:%M%:%S}] added precipitation {1}\".format(datetime.now(), geodf.shape))\n",
    "    \n",
    "    # convert datetime\n",
    "    geodf = convert_datetime(geodf)\n",
    "    print(\"[{0:%H:%M%:%S}] converted datetime {1}\".format(datetime.now(), geodf.shape))\n",
    "\n",
    "    # add exponential weighted mean\n",
    "    if \"geoid10_tract\" in df.columns:\n",
    "        groupby = \"geoid10_tract\"\n",
    "    elif \"geoid10_block\" in df.columns:\n",
    "        groupby = \"geoid10_block\"\n",
    "    \n",
    "#     geodf = get_grouped_ewm(geodf.set_index(\"datetime\"),\n",
    "#                             groupby=groupby, alpha=0.5,\n",
    "#                             adjust=True, timesteps=1)\n",
    "#     geodf.reset_index(inplace=True)\n",
    "#     print(\"[{0:%H:%M%:%S}] added exponetial weighted mean {1}\".format(datetime.now(), geodf.shape))\n",
    "    \n",
    "    # geometry cannot be included in feather format\n",
    "    geodf.drop([\"geometry\", \"date\"], axis=1, inplace=True)\n",
    "    \n",
    "    # clean\n",
    "    geodf.sort_values(by=[\"datetime\", groupby], inplace=True)\n",
    "    geodf.reset_index(inplace=True, drop=True)\n",
    "    geodf = geodf[geodf.datetime < datetime(2019, 4, 1)] # precipitation missing values after 2019/04/01\n",
    "    \n",
    "    # save\n",
    "    save_path = re.sub(r\".*/counts_\", \"features/features_\", path)\n",
    "    geodf.to_feather(save_path)\n",
    "    print(\"[{0:%H:%M%:%S}] saved at {1}\\n\".format(datetime.now(), path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
