{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# others\n",
    "import os\n",
    "import random as rn\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rnn_data(path, window, predict_ts, isdim3=True, geo_col=[\"geoid10_tract\"], y_cols=[\"crime\"]):\n",
    "    \"\"\"\n",
    "    y_cols: [\"crime\"] or [\"incident_type_0\", \"incident_type_1\", \"incident_type_2\"]\n",
    "    geo_col: [\"geoid10_tract\"] or [\"geoid10_block\"]\n",
    "    return y_all and x_all of given path\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    df = feather.read_dataframe(path)\n",
    "    df.sort_values(by=[\"datetime\", \"geoid10_tract\"], inplace=True)\n",
    "    df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # input columns\n",
    "    x_cols = list(df.drop(y_cols + geo_col, axis=1).columns)\n",
    "\n",
    "    # group by geoid\n",
    "    geo_grs = df.groupby(by=geo_col)\n",
    "\n",
    "    # arrayes to store x and y\n",
    "    # (no of timesteps, window size, no of tracts,  no of features, )\n",
    "    n_timesteps = int(len(df) / len(geo_grs)) - window - predict_ts + 1\n",
    "    x_all = np.empty(shape=(n_timesteps, window, len(geo_grs), len(x_cols + y_cols)))\n",
    "\n",
    "    # (output size, no of tracts, no of outputs)\n",
    "    y_all = np.empty(shape=(n_timesteps, len(geo_grs), len(y_cols)))\n",
    "\n",
    "    # to store geo_ids and y_all's datetime\n",
    "    geo_ids = []\n",
    "\n",
    "    y_datetime = df.index.unique()[window + predict_ts - 1:]\n",
    "\n",
    "    for i, (geo_id, gr) in enumerate(tqdm(geo_grs)):\n",
    "        geo_ids.append(geo_id)\n",
    "        x_values = gr[y_cols + x_cols].values\n",
    "        y_values = gr[y_cols].values\n",
    "\n",
    "        for j in range(window, len(gr) - predict_ts + 1):\n",
    "            # generate x_all\n",
    "            x_all[j - window, :, i, :] = x_values[j - window:j, :]\n",
    "            y_all[j - window, i, :] = y_values[j + predict_ts - 1, :]\n",
    "\n",
    "    if isdim3:\n",
    "        x_all = np.reshape(x_all,\n",
    "                           newshape=(x_all.shape[0], x_all.shape[1], x_all.shape[2] * x_all.shape[3]))\n",
    "        y_all = np.reshape(y_all,\n",
    "                           newshape=(y_all.shape[0], y_all.shape[1] * y_all.shape[2]))\n",
    "\n",
    "    return x_all, y_all, geo_ids, y_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configuration\n",
    "path = \"./features/features_binary_tract_2H.feather\"\n",
    "window = 12\n",
    "predict_ts = 1  # how many timesteps future does the model predict? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f033ba1db0c4a74ad2f7f6f16d43983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load x and y\n",
    "x_all, y_all, geo_ids, y_datetime = load_rnn_data(path=path,\n",
    "                                                  window=window,\n",
    "                                                  predict_ts=predict_ts,\n",
    "                                                  isdim3=True,\n",
    "                                                  geo_col=[\"geoid10_tract\"],\n",
    "                                                  y_cols=[\"crime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 12, 1560)\n",
      "(18600, 195)\n",
      "195\n",
      "18600\n"
     ]
    }
   ],
   "source": [
    "print(x_all.shape)\n",
    "print(y_all.shape)\n",
    "print(len(geo_ids))  # to convert model output later\n",
    "print(len(y_datetime))  # to convert model output later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scaling\n",
    "# scaler = MinMaxScaler()\n",
    "# x_all = scaler.fit_transform(x_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(x_all, y_all, n_splits=5, model=None, fit_params=None, baseline=False):\n",
    "    \"\"\"\n",
    "    :param baseline: True or False (defualt: False)\n",
    "    :return: train and test scores and prediction of y on test data\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare dictionary to store scores\n",
    "    train_scores = {}\n",
    "    metrics = [\"acc\", \"log_loss\"]\n",
    "    for metric in metrics:\n",
    "        train_scores[metric] = []\n",
    "    test_scores = deepcopy(train_scores)\n",
    "\n",
    "    # prepare dictionary to store predictions\n",
    "    y_test_probs = np.zeros_like(y_all)\n",
    "\n",
    "    # time series split\n",
    "    tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    for split, (train_idx, test_idx) in enumerate(tss.split(x_all, y_all)):\n",
    "\n",
    "        print(\"---------- split {0} ----------\".format(split))\n",
    "        print(\"[{0:%H:%M:%S}] train_index:{1}~{2} test_index:{3}~{4}\".format(\n",
    "            datetime.now(), train_idx[0], train_idx[-1], test_idx[0], test_idx[-1]))\n",
    "\n",
    "        # create train and test set\n",
    "        x_train = x_all[:train_idx[-1]]\n",
    "        y_train = y_all[:train_idx[-1]]\n",
    "        x_test = x_all[test_idx[0]:test_idx[-1]]\n",
    "        y_test = y_all[test_idx[0]:test_idx[-1]]\n",
    "\n",
    "        if baseline:\n",
    "            # return 0 for all predicted probabiliby\n",
    "            y_train_prob = np.zeros_like(y_train)\n",
    "            y_test_prob = np.zeros_like(y_test)\n",
    "\n",
    "            # return 0 for all binary predictions\n",
    "            y_train_pred = np.zeros_like(y_train)\n",
    "            y_test_pred = np.zeros_like(y_test)\n",
    "\n",
    "        else:            \n",
    "            # train\n",
    "            model.fit(x_train, y_train, **fit_params)\n",
    "\n",
    "            # predict\n",
    "            y_train_prob = model.predict(x_train)\n",
    "            y_test_prob = model.predict(x_test)\n",
    "\n",
    "            # convert form probability to binary\n",
    "            y_train_pred = np.around(y_train_prob)\n",
    "            y_test_pred = np.around(y_test_prob)\n",
    "\n",
    "        # store test prediction\n",
    "        y_test_probs[test_idx[0]:test_idx[-1]] = y_test_prob\n",
    "\n",
    "        # calculate metrics\n",
    "        train_log_loss = log_loss(y_train.flatten(), y_train_prob.flatten())\n",
    "        test_log_loss = log_loss(y_test.flatten(), y_test_prob.flatten())\n",
    "        train_acc = accuracy_score(y_train.flatten(), y_train_pred.flatten())\n",
    "        test_acc = accuracy_score(y_test.flatten(), y_test_pred.flatten())\n",
    "\n",
    "        # store scores\n",
    "        train_scores[\"log_loss\"].append(train_log_loss)\n",
    "        test_scores[\"log_loss\"].append(test_log_loss)\n",
    "        train_scores[\"acc\"].append(train_acc)\n",
    "        test_scores[\"acc\"].append(test_acc)\n",
    "\n",
    "        print(\"[{0:%H:%M:%S}] train_log_loss:{1} test_log_loss:{2}\".format(\n",
    "            datetime.now(), train_log_loss, test_log_loss))\n",
    "        print(\"[{0:%H:%M:%S}] train_acc:{1} test_acc:{2}\\n\".format(\n",
    "            datetime.now(), train_acc, test_acc))\n",
    "\n",
    "        # convert to dataframe\n",
    "        train_scores_df = pd.DataFrame(train_scores)\n",
    "        test_scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "    return train_scores_df, test_scores_df, y_test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM():\n",
    "    \"\"\"\n",
    "    class to input into function time_series_cv\n",
    "    \"\"\"\n",
    "    def __init__(self, units=100,\n",
    "                 dropout_rate=0.2, activation=\"sigmoid\",\n",
    "                 optimizer=\"adam\", loss=\"binary_crossentropy\"):\n",
    "        \"\"\"\n",
    "        define LSTM model with given arguments\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs=200, early_stopping_patience=5,\n",
    "            batch_size=128, validation_split=0.1, train_shuffle=False):\n",
    "        \"\"\"\n",
    "        fit train data\n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(units=self.units, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "        self.model.add(Dropout(self.dropout_rate))\n",
    "        self.model.add(Dense(units=y_train.shape[1], activation=self.activation))\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss, metrics=[\"acc\"])\n",
    "\n",
    "        earlystopping = EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience)\n",
    "        self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                       validation_split=validation_split, shuffle=train_shuffle,\n",
    "                       callbacks=[earlystopping])\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        return predicted values of x_test\n",
    "        \"\"\"\n",
    "        y_prob = self.model.predict(x_test)\n",
    "        return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# parameters at model definition\n",
    "def_params = {\n",
    "    \"units\":100,\n",
    "    \"dropout_rate\":0.159961594635,\n",
    "    \"activation\":\"sigmoid\",\n",
    "    \"optimizer\":Adam(lr=1.77547438185e-05),\n",
    "    \"loss\":\"binary_crossentropy\"\n",
    "}\n",
    "\n",
    "# parameters at model training\n",
    "fit_params = {\n",
    "    \"epochs\":500,\n",
    "    \"early_stopping_patience\":5,\n",
    "    \"batch_size\":128,\n",
    "    \"validation_split\":0.1,\n",
    "    \"train_shuffle\":False\n",
    "}\n",
    "\n",
    "# number of time series cv splits\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(0)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "rn.seed(0)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(0)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- split 0 ----------\n",
      "[16:57:27] train_index:0~3099 test_index:3100~6199\n",
      "[16:57:27] train_log_loss:3.7914609505286054 test_log_loss:2.744732641319857\n",
      "[16:57:27] train_acc:0.8902259620555845 test_acc:0.9205318506383366\n",
      "\n",
      "---------- split 1 ----------\n",
      "[16:57:27] train_index:0~6199 test_index:6200~9299\n",
      "[16:57:28] train_log_loss:3.267798179800001 test_log_loss:2.880874763878297\n",
      "[16:57:28] train_acc:0.9053875521692911 test_acc:0.9165901324662216\n",
      "\n",
      "---------- split 2 ----------\n",
      "[16:57:28] train_index:0~9299 test_index:9300~12399\n",
      "[16:57:29] train_log_loss:3.138861934241693 test_log_loss:3.137727282256813\n",
      "[16:57:29] train_acc:0.9091206388335111 test_acc:0.9091534903732387\n",
      "\n",
      "---------- split 3 ----------\n",
      "[16:57:29] train_index:0~12399 test_index:12400~15499\n",
      "[16:57:31] train_log_loss:3.1386966000817376 test_log_loss:3.453963371306283\n",
      "[16:57:31] train_acc:0.909125425747734 test_acc:0.8999975178097153\n",
      "\n",
      "---------- split 4 ----------\n",
      "[16:57:31] train_index:0~15499 test_index:15500~18599\n",
      "[16:57:32] train_log_loss:3.201634023450785 test_log_loss:3.6321712378626256\n",
      "[16:57:32] train_acc:0.9073032007027748 test_acc:0.8948378716045705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline --> Assign all observations to = 0 (no crime)\n",
    "\n",
    "model = MyLSTM(**def_params)\n",
    "\n",
    "train_scores_df, test_scores_df, y_test_probs = time_series_cv(x_all,\n",
    "                                                               y_all,\n",
    "                                                               n_splits=n_splits,\n",
    "                                                               model=model,\n",
    "                                                               fit_params=fit_params,\n",
    "                                                               baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.890226</td>\n",
       "      <td>3.791461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905388</td>\n",
       "      <td>3.267798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909121</td>\n",
       "      <td>3.138862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909125</td>\n",
       "      <td>3.138697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907303</td>\n",
       "      <td>3.201634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  log_loss\n",
       "0  0.890226  3.791461\n",
       "1  0.905388  3.267798\n",
       "2  0.909121  3.138862\n",
       "3  0.909125  3.138697\n",
       "4  0.907303  3.201634"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train metrics for baseline\n",
    "train_scores_df.to_csv(\"./results/train_scores_base.csv\", index=False)\n",
    "train_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.920532</td>\n",
       "      <td>2.744733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916590</td>\n",
       "      <td>2.880875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909153</td>\n",
       "      <td>3.137727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899998</td>\n",
       "      <td>3.453963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894838</td>\n",
       "      <td>3.632171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  log_loss\n",
       "0  0.920532  2.744733\n",
       "1  0.916590  2.880875\n",
       "2  0.909153  3.137727\n",
       "3  0.899998  3.453963\n",
       "4  0.894838  3.632171"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test metrics for baseline\n",
    "test_scores_df.to_csv(\"./results/test_scores_base.csv\", index=False)\n",
    "test_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- split 0 ----------\n",
      "[16:57:33] train_index:0~3099 test_index:3100~6199\n",
      "WARNING:tensorflow:From /usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2789 samples, validate on 310 samples\n",
      "Epoch 1/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.7049 - acc: 0.5343 - val_loss: 0.6954 - val_acc: 0.5656\n",
      "Epoch 2/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.7000 - acc: 0.5417 - val_loss: 0.6920 - val_acc: 0.5705\n",
      "Epoch 3/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6971 - acc: 0.5470 - val_loss: 0.6886 - val_acc: 0.5755\n",
      "Epoch 4/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6942 - acc: 0.5519 - val_loss: 0.6852 - val_acc: 0.5804\n",
      "Epoch 5/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6911 - acc: 0.5580 - val_loss: 0.6819 - val_acc: 0.5901\n",
      "Epoch 6/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6886 - acc: 0.5631 - val_loss: 0.6786 - val_acc: 0.5901\n",
      "Epoch 7/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6857 - acc: 0.5676 - val_loss: 0.6753 - val_acc: 0.5933\n",
      "Epoch 8/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6830 - acc: 0.5722 - val_loss: 0.6720 - val_acc: 0.5983\n",
      "Epoch 9/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6801 - acc: 0.5775 - val_loss: 0.6688 - val_acc: 0.5983\n",
      "Epoch 10/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6774 - acc: 0.5821 - val_loss: 0.6656 - val_acc: 0.6079\n",
      "Epoch 11/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6745 - acc: 0.5873 - val_loss: 0.6624 - val_acc: 0.6128\n",
      "Epoch 12/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6719 - acc: 0.5927 - val_loss: 0.6592 - val_acc: 0.6271\n",
      "Epoch 13/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6691 - acc: 0.5971 - val_loss: 0.6560 - val_acc: 0.6313\n",
      "Epoch 14/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6669 - acc: 0.6011 - val_loss: 0.6529 - val_acc: 0.6313\n",
      "Epoch 15/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6638 - acc: 0.6062 - val_loss: 0.6498 - val_acc: 0.6313\n",
      "Epoch 16/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6614 - acc: 0.6105 - val_loss: 0.6467 - val_acc: 0.6463\n",
      "Epoch 17/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6586 - acc: 0.6159 - val_loss: 0.6436 - val_acc: 0.6463\n",
      "Epoch 18/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6562 - acc: 0.6197 - val_loss: 0.6406 - val_acc: 0.6611\n",
      "Epoch 19/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6536 - acc: 0.6247 - val_loss: 0.6376 - val_acc: 0.6650\n",
      "Epoch 20/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6511 - acc: 0.6288 - val_loss: 0.6346 - val_acc: 0.6681\n",
      "Epoch 21/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6486 - acc: 0.6331 - val_loss: 0.6316 - val_acc: 0.6765\n",
      "Epoch 22/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6462 - acc: 0.6375 - val_loss: 0.6286 - val_acc: 0.6843\n",
      "Epoch 23/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6436 - acc: 0.6418 - val_loss: 0.6257 - val_acc: 0.6891\n",
      "Epoch 24/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6411 - acc: 0.6460 - val_loss: 0.6227 - val_acc: 0.6891\n",
      "Epoch 25/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6385 - acc: 0.6511 - val_loss: 0.6198 - val_acc: 0.6891\n",
      "Epoch 26/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6361 - acc: 0.6557 - val_loss: 0.6169 - val_acc: 0.6937\n",
      "Epoch 27/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6336 - acc: 0.6593 - val_loss: 0.6141 - val_acc: 0.7035\n",
      "Epoch 28/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.6313 - acc: 0.6636 - val_loss: 0.6112 - val_acc: 0.7035\n",
      "Epoch 29/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.6288 - acc: 0.6672 - val_loss: 0.6084 - val_acc: 0.7035\n",
      "Epoch 30/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6266 - acc: 0.6718 - val_loss: 0.6056 - val_acc: 0.7085\n",
      "Epoch 31/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6240 - acc: 0.6762 - val_loss: 0.6028 - val_acc: 0.7177\n",
      "Epoch 32/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6219 - acc: 0.6796 - val_loss: 0.6000 - val_acc: 0.7227\n",
      "Epoch 33/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6194 - acc: 0.6841 - val_loss: 0.5972 - val_acc: 0.7368\n",
      "Epoch 34/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6174 - acc: 0.6879 - val_loss: 0.5945 - val_acc: 0.7418\n",
      "Epoch 35/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6151 - acc: 0.6915 - val_loss: 0.5918 - val_acc: 0.7418\n",
      "Epoch 36/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6125 - acc: 0.6957 - val_loss: 0.5891 - val_acc: 0.7516\n",
      "Epoch 37/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6104 - acc: 0.7000 - val_loss: 0.5864 - val_acc: 0.7516\n",
      "Epoch 38/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6083 - acc: 0.7034 - val_loss: 0.5837 - val_acc: 0.7564\n",
      "Epoch 39/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6060 - acc: 0.7072 - val_loss: 0.5810 - val_acc: 0.7609\n",
      "Epoch 40/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6040 - acc: 0.7102 - val_loss: 0.5784 - val_acc: 0.7706\n",
      "Epoch 41/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.6014 - acc: 0.7143 - val_loss: 0.5758 - val_acc: 0.7706\n",
      "Epoch 42/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5992 - acc: 0.7182 - val_loss: 0.5732 - val_acc: 0.7805\n",
      "Epoch 43/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5973 - acc: 0.7216 - val_loss: 0.5706 - val_acc: 0.7894\n",
      "Epoch 44/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5953 - acc: 0.7251 - val_loss: 0.5680 - val_acc: 0.7894\n",
      "Epoch 45/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5929 - acc: 0.7291 - val_loss: 0.5655 - val_acc: 0.7944\n",
      "Epoch 46/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5908 - acc: 0.7330 - val_loss: 0.5629 - val_acc: 0.7995\n",
      "Epoch 47/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5888 - acc: 0.7360 - val_loss: 0.5604 - val_acc: 0.8044\n",
      "Epoch 48/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5866 - acc: 0.7398 - val_loss: 0.5579 - val_acc: 0.8044\n",
      "Epoch 49/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5844 - acc: 0.7432 - val_loss: 0.5554 - val_acc: 0.8044\n",
      "Epoch 50/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5825 - acc: 0.7461 - val_loss: 0.5530 - val_acc: 0.8044\n",
      "Epoch 51/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5803 - acc: 0.7494 - val_loss: 0.5505 - val_acc: 0.8044\n",
      "Epoch 52/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5783 - acc: 0.7528 - val_loss: 0.5481 - val_acc: 0.8044\n",
      "Epoch 53/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5764 - acc: 0.7554 - val_loss: 0.5456 - val_acc: 0.8093\n",
      "Epoch 54/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5745 - acc: 0.7589 - val_loss: 0.5432 - val_acc: 0.8287\n",
      "Epoch 55/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5723 - acc: 0.7623 - val_loss: 0.5408 - val_acc: 0.8287\n",
      "Epoch 56/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5701 - acc: 0.7654 - val_loss: 0.5385 - val_acc: 0.8287\n",
      "Epoch 57/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5686 - acc: 0.7687 - val_loss: 0.5361 - val_acc: 0.8287\n",
      "Epoch 58/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5666 - acc: 0.7716 - val_loss: 0.5338 - val_acc: 0.8333\n",
      "Epoch 59/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5646 - acc: 0.7744 - val_loss: 0.5314 - val_acc: 0.8333\n",
      "Epoch 60/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5625 - acc: 0.7779 - val_loss: 0.5291 - val_acc: 0.8380\n",
      "Epoch 61/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5609 - acc: 0.7804 - val_loss: 0.5268 - val_acc: 0.8431\n",
      "Epoch 62/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5593 - acc: 0.7834 - val_loss: 0.5245 - val_acc: 0.8431\n",
      "Epoch 63/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5575 - acc: 0.7868 - val_loss: 0.5223 - val_acc: 0.8431\n",
      "Epoch 64/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5551 - acc: 0.7894 - val_loss: 0.5200 - val_acc: 0.8431\n",
      "Epoch 65/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5536 - acc: 0.7922 - val_loss: 0.5178 - val_acc: 0.8481\n",
      "Epoch 66/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5517 - acc: 0.7947 - val_loss: 0.5155 - val_acc: 0.8481\n",
      "Epoch 67/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5501 - acc: 0.7982 - val_loss: 0.5133 - val_acc: 0.8531\n",
      "Epoch 68/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5481 - acc: 0.7998 - val_loss: 0.5111 - val_acc: 0.8519\n",
      "Epoch 69/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5463 - acc: 0.8028 - val_loss: 0.5090 - val_acc: 0.8616\n",
      "Epoch 70/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5448 - acc: 0.8056 - val_loss: 0.5068 - val_acc: 0.8666\n",
      "Epoch 71/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5430 - acc: 0.8085 - val_loss: 0.5046 - val_acc: 0.8807\n",
      "Epoch 72/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5412 - acc: 0.8111 - val_loss: 0.5025 - val_acc: 0.8807\n",
      "Epoch 73/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5388 - acc: 0.8140 - val_loss: 0.5004 - val_acc: 0.8807\n",
      "Epoch 74/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5374 - acc: 0.8160 - val_loss: 0.4982 - val_acc: 0.8807\n",
      "Epoch 75/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5356 - acc: 0.8185 - val_loss: 0.4961 - val_acc: 0.8807\n",
      "Epoch 76/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5343 - acc: 0.8205 - val_loss: 0.4941 - val_acc: 0.8906\n",
      "Epoch 77/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5325 - acc: 0.8228 - val_loss: 0.4920 - val_acc: 0.8906\n",
      "Epoch 78/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5308 - acc: 0.8253 - val_loss: 0.4899 - val_acc: 0.8956\n",
      "Epoch 79/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5290 - acc: 0.8280 - val_loss: 0.4879 - val_acc: 0.8998\n",
      "Epoch 80/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5270 - acc: 0.8298 - val_loss: 0.4858 - val_acc: 0.9043\n",
      "Epoch 81/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5257 - acc: 0.8316 - val_loss: 0.4838 - val_acc: 0.9142\n",
      "Epoch 82/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5243 - acc: 0.8342 - val_loss: 0.4818 - val_acc: 0.9187\n",
      "Epoch 83/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5227 - acc: 0.8359 - val_loss: 0.4798 - val_acc: 0.9187\n",
      "Epoch 84/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5211 - acc: 0.8374 - val_loss: 0.4778 - val_acc: 0.9187\n",
      "Epoch 85/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5189 - acc: 0.8396 - val_loss: 0.4759 - val_acc: 0.9187\n",
      "Epoch 86/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5175 - acc: 0.8419 - val_loss: 0.4739 - val_acc: 0.9187\n",
      "Epoch 87/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5156 - acc: 0.8440 - val_loss: 0.4719 - val_acc: 0.9187\n",
      "Epoch 88/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5144 - acc: 0.8450 - val_loss: 0.4700 - val_acc: 0.9187\n",
      "Epoch 89/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5131 - acc: 0.8464 - val_loss: 0.4681 - val_acc: 0.9236\n",
      "Epoch 90/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5114 - acc: 0.8485 - val_loss: 0.4662 - val_acc: 0.9236\n",
      "Epoch 91/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5094 - acc: 0.8499 - val_loss: 0.4643 - val_acc: 0.9236\n",
      "Epoch 92/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5084 - acc: 0.8509 - val_loss: 0.4624 - val_acc: 0.9236\n",
      "Epoch 93/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5067 - acc: 0.8522 - val_loss: 0.4605 - val_acc: 0.9332\n",
      "Epoch 94/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5056 - acc: 0.8536 - val_loss: 0.4587 - val_acc: 0.9332\n",
      "Epoch 95/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5039 - acc: 0.8549 - val_loss: 0.4568 - val_acc: 0.9332\n",
      "Epoch 96/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5022 - acc: 0.8561 - val_loss: 0.4550 - val_acc: 0.9332\n",
      "Epoch 97/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.5010 - acc: 0.8571 - val_loss: 0.4531 - val_acc: 0.9332\n",
      "Epoch 98/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4995 - acc: 0.8586 - val_loss: 0.4513 - val_acc: 0.9378\n",
      "Epoch 99/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4979 - acc: 0.8596 - val_loss: 0.4495 - val_acc: 0.9378\n",
      "Epoch 100/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4965 - acc: 0.8610 - val_loss: 0.4477 - val_acc: 0.9378\n",
      "Epoch 101/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4955 - acc: 0.8616 - val_loss: 0.4460 - val_acc: 0.9378\n",
      "Epoch 102/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4946 - acc: 0.8621 - val_loss: 0.4442 - val_acc: 0.9378\n",
      "Epoch 103/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4923 - acc: 0.8640 - val_loss: 0.4424 - val_acc: 0.9378\n",
      "Epoch 104/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4907 - acc: 0.8645 - val_loss: 0.4407 - val_acc: 0.9378\n",
      "Epoch 105/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4896 - acc: 0.8654 - val_loss: 0.4389 - val_acc: 0.9378\n",
      "Epoch 106/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4877 - acc: 0.8662 - val_loss: 0.4372 - val_acc: 0.9378\n",
      "Epoch 107/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4867 - acc: 0.8672 - val_loss: 0.4355 - val_acc: 0.9378\n",
      "Epoch 108/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4850 - acc: 0.8678 - val_loss: 0.4338 - val_acc: 0.9378\n",
      "Epoch 109/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4837 - acc: 0.8690 - val_loss: 0.4321 - val_acc: 0.9378\n",
      "Epoch 110/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4827 - acc: 0.8692 - val_loss: 0.4304 - val_acc: 0.9378\n",
      "Epoch 111/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4818 - acc: 0.8698 - val_loss: 0.4287 - val_acc: 0.9378\n",
      "Epoch 112/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4801 - acc: 0.8706 - val_loss: 0.4271 - val_acc: 0.9378\n",
      "Epoch 113/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4787 - acc: 0.8711 - val_loss: 0.4254 - val_acc: 0.9378\n",
      "Epoch 114/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4770 - acc: 0.8719 - val_loss: 0.4238 - val_acc: 0.9378\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4759 - acc: 0.8723 - val_loss: 0.4222 - val_acc: 0.9378\n",
      "Epoch 116/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4743 - acc: 0.8731 - val_loss: 0.4205 - val_acc: 0.9426\n",
      "Epoch 117/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4742 - acc: 0.8733 - val_loss: 0.4189 - val_acc: 0.9475\n",
      "Epoch 118/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4720 - acc: 0.8742 - val_loss: 0.4173 - val_acc: 0.9475\n",
      "Epoch 119/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4717 - acc: 0.8745 - val_loss: 0.4157 - val_acc: 0.9475\n",
      "Epoch 120/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4699 - acc: 0.8750 - val_loss: 0.4142 - val_acc: 0.9475\n",
      "Epoch 121/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4688 - acc: 0.8755 - val_loss: 0.4126 - val_acc: 0.9475\n",
      "Epoch 122/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4676 - acc: 0.8758 - val_loss: 0.4110 - val_acc: 0.9475\n",
      "Epoch 123/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4664 - acc: 0.8764 - val_loss: 0.4095 - val_acc: 0.9475\n",
      "Epoch 124/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4649 - acc: 0.8765 - val_loss: 0.4079 - val_acc: 0.9475\n",
      "Epoch 125/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4642 - acc: 0.8768 - val_loss: 0.4064 - val_acc: 0.9475\n",
      "Epoch 126/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4622 - acc: 0.8773 - val_loss: 0.4049 - val_acc: 0.9475\n",
      "Epoch 127/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4615 - acc: 0.8778 - val_loss: 0.4034 - val_acc: 0.9475\n",
      "Epoch 128/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4601 - acc: 0.8779 - val_loss: 0.4019 - val_acc: 0.9475\n",
      "Epoch 129/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4593 - acc: 0.8782 - val_loss: 0.4004 - val_acc: 0.9475\n",
      "Epoch 130/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4578 - acc: 0.8786 - val_loss: 0.3989 - val_acc: 0.9475\n",
      "Epoch 131/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4573 - acc: 0.8790 - val_loss: 0.3974 - val_acc: 0.9475\n",
      "Epoch 132/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4560 - acc: 0.8793 - val_loss: 0.3960 - val_acc: 0.9475\n",
      "Epoch 133/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4542 - acc: 0.8794 - val_loss: 0.3945 - val_acc: 0.9475\n",
      "Epoch 134/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4534 - acc: 0.8799 - val_loss: 0.3930 - val_acc: 0.9475\n",
      "Epoch 135/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4519 - acc: 0.8800 - val_loss: 0.3916 - val_acc: 0.9475\n",
      "Epoch 136/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4515 - acc: 0.8803 - val_loss: 0.3902 - val_acc: 0.9475\n",
      "Epoch 137/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4500 - acc: 0.8804 - val_loss: 0.3888 - val_acc: 0.9475\n",
      "Epoch 138/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4492 - acc: 0.8807 - val_loss: 0.3873 - val_acc: 0.9475\n",
      "Epoch 139/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4480 - acc: 0.8809 - val_loss: 0.3859 - val_acc: 0.9475\n",
      "Epoch 140/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4471 - acc: 0.8811 - val_loss: 0.3845 - val_acc: 0.9475\n",
      "Epoch 141/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4457 - acc: 0.8816 - val_loss: 0.3832 - val_acc: 0.9475\n",
      "Epoch 142/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4444 - acc: 0.8816 - val_loss: 0.3818 - val_acc: 0.9475\n",
      "Epoch 143/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4437 - acc: 0.8817 - val_loss: 0.3804 - val_acc: 0.9475\n",
      "Epoch 144/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4427 - acc: 0.8819 - val_loss: 0.3791 - val_acc: 0.9475\n",
      "Epoch 145/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4420 - acc: 0.8821 - val_loss: 0.3777 - val_acc: 0.9475\n",
      "Epoch 146/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4403 - acc: 0.8824 - val_loss: 0.3764 - val_acc: 0.9475\n",
      "Epoch 147/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4395 - acc: 0.8828 - val_loss: 0.3750 - val_acc: 0.9475\n",
      "Epoch 148/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4387 - acc: 0.8829 - val_loss: 0.3737 - val_acc: 0.9475\n",
      "Epoch 149/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4375 - acc: 0.8830 - val_loss: 0.3724 - val_acc: 0.9475\n",
      "Epoch 150/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4365 - acc: 0.8832 - val_loss: 0.3711 - val_acc: 0.9475\n",
      "Epoch 151/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4356 - acc: 0.8833 - val_loss: 0.3698 - val_acc: 0.9475\n",
      "Epoch 152/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4343 - acc: 0.8835 - val_loss: 0.3685 - val_acc: 0.9475\n",
      "Epoch 153/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4341 - acc: 0.8836 - val_loss: 0.3672 - val_acc: 0.9475\n",
      "Epoch 154/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4329 - acc: 0.8838 - val_loss: 0.3659 - val_acc: 0.9525\n",
      "Epoch 155/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4318 - acc: 0.8839 - val_loss: 0.3646 - val_acc: 0.9525\n",
      "Epoch 156/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4302 - acc: 0.8842 - val_loss: 0.3634 - val_acc: 0.9525\n",
      "Epoch 157/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4300 - acc: 0.8842 - val_loss: 0.3621 - val_acc: 0.9525\n",
      "Epoch 158/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4294 - acc: 0.8844 - val_loss: 0.3609 - val_acc: 0.9525\n",
      "Epoch 159/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4272 - acc: 0.8848 - val_loss: 0.3596 - val_acc: 0.9525\n",
      "Epoch 160/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4272 - acc: 0.8846 - val_loss: 0.3584 - val_acc: 0.9525\n",
      "Epoch 161/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4260 - acc: 0.8848 - val_loss: 0.3572 - val_acc: 0.9525\n",
      "Epoch 162/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4254 - acc: 0.8850 - val_loss: 0.3560 - val_acc: 0.9525\n",
      "Epoch 163/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4239 - acc: 0.8851 - val_loss: 0.3548 - val_acc: 0.9525\n",
      "Epoch 164/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4232 - acc: 0.8852 - val_loss: 0.3536 - val_acc: 0.9525\n",
      "Epoch 165/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4224 - acc: 0.8853 - val_loss: 0.3524 - val_acc: 0.9525\n",
      "Epoch 166/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4216 - acc: 0.8854 - val_loss: 0.3512 - val_acc: 0.9525\n",
      "Epoch 167/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4204 - acc: 0.8854 - val_loss: 0.3500 - val_acc: 0.9525\n",
      "Epoch 168/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4200 - acc: 0.8855 - val_loss: 0.3488 - val_acc: 0.9525\n",
      "Epoch 169/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4190 - acc: 0.8856 - val_loss: 0.3477 - val_acc: 0.9525\n",
      "Epoch 170/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4181 - acc: 0.8855 - val_loss: 0.3465 - val_acc: 0.9525\n",
      "Epoch 171/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4176 - acc: 0.8856 - val_loss: 0.3454 - val_acc: 0.9525\n",
      "Epoch 172/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4162 - acc: 0.8858 - val_loss: 0.3442 - val_acc: 0.9525\n",
      "Epoch 173/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4156 - acc: 0.8857 - val_loss: 0.3431 - val_acc: 0.9525\n",
      "Epoch 174/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4146 - acc: 0.8859 - val_loss: 0.3420 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4142 - acc: 0.8859 - val_loss: 0.3409 - val_acc: 0.9525\n",
      "Epoch 176/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4128 - acc: 0.8859 - val_loss: 0.3397 - val_acc: 0.9525\n",
      "Epoch 177/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4119 - acc: 0.8861 - val_loss: 0.3386 - val_acc: 0.9525\n",
      "Epoch 178/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4115 - acc: 0.8860 - val_loss: 0.3375 - val_acc: 0.9525\n",
      "Epoch 179/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4109 - acc: 0.8861 - val_loss: 0.3364 - val_acc: 0.9525\n",
      "Epoch 180/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4099 - acc: 0.8862 - val_loss: 0.3354 - val_acc: 0.9525\n",
      "Epoch 181/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4089 - acc: 0.8863 - val_loss: 0.3343 - val_acc: 0.9525\n",
      "Epoch 182/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4079 - acc: 0.8863 - val_loss: 0.3332 - val_acc: 0.9525\n",
      "Epoch 183/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4074 - acc: 0.8862 - val_loss: 0.3321 - val_acc: 0.9525\n",
      "Epoch 184/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4070 - acc: 0.8863 - val_loss: 0.3311 - val_acc: 0.9525\n",
      "Epoch 185/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4058 - acc: 0.8863 - val_loss: 0.3300 - val_acc: 0.9525\n",
      "Epoch 186/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4057 - acc: 0.8864 - val_loss: 0.3290 - val_acc: 0.9525\n",
      "Epoch 187/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4042 - acc: 0.8864 - val_loss: 0.3279 - val_acc: 0.9525\n",
      "Epoch 188/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4039 - acc: 0.8864 - val_loss: 0.3269 - val_acc: 0.9525\n",
      "Epoch 189/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4033 - acc: 0.8864 - val_loss: 0.3259 - val_acc: 0.9525\n",
      "Epoch 190/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4016 - acc: 0.8864 - val_loss: 0.3249 - val_acc: 0.9525\n",
      "Epoch 191/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4011 - acc: 0.8865 - val_loss: 0.3239 - val_acc: 0.9525\n",
      "Epoch 192/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4012 - acc: 0.8865 - val_loss: 0.3229 - val_acc: 0.9525\n",
      "Epoch 193/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.4000 - acc: 0.8865 - val_loss: 0.3219 - val_acc: 0.9525\n",
      "Epoch 194/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3988 - acc: 0.8864 - val_loss: 0.3209 - val_acc: 0.9525\n",
      "Epoch 195/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3985 - acc: 0.8866 - val_loss: 0.3199 - val_acc: 0.9525\n",
      "Epoch 196/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3978 - acc: 0.8866 - val_loss: 0.3189 - val_acc: 0.9525\n",
      "Epoch 197/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3972 - acc: 0.8866 - val_loss: 0.3179 - val_acc: 0.9525\n",
      "Epoch 198/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3964 - acc: 0.8866 - val_loss: 0.3170 - val_acc: 0.9525\n",
      "Epoch 199/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3955 - acc: 0.8865 - val_loss: 0.3160 - val_acc: 0.9525\n",
      "Epoch 200/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3946 - acc: 0.8867 - val_loss: 0.3150 - val_acc: 0.9525\n",
      "Epoch 201/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3946 - acc: 0.8867 - val_loss: 0.3141 - val_acc: 0.9525\n",
      "Epoch 202/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3935 - acc: 0.8867 - val_loss: 0.3132 - val_acc: 0.9525\n",
      "Epoch 203/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3924 - acc: 0.8867 - val_loss: 0.3122 - val_acc: 0.9525\n",
      "Epoch 204/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3922 - acc: 0.8867 - val_loss: 0.3113 - val_acc: 0.9525\n",
      "Epoch 205/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3914 - acc: 0.8867 - val_loss: 0.3104 - val_acc: 0.9525\n",
      "Epoch 206/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3910 - acc: 0.8867 - val_loss: 0.3095 - val_acc: 0.9525\n",
      "Epoch 207/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3902 - acc: 0.8867 - val_loss: 0.3085 - val_acc: 0.9525\n",
      "Epoch 208/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3898 - acc: 0.8867 - val_loss: 0.3076 - val_acc: 0.9525\n",
      "Epoch 209/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3891 - acc: 0.8867 - val_loss: 0.3067 - val_acc: 0.9525\n",
      "Epoch 210/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3885 - acc: 0.8867 - val_loss: 0.3058 - val_acc: 0.9525\n",
      "Epoch 211/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3878 - acc: 0.8867 - val_loss: 0.3049 - val_acc: 0.9525\n",
      "Epoch 212/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3874 - acc: 0.8865 - val_loss: 0.3041 - val_acc: 0.9525\n",
      "Epoch 213/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.3868 - acc: 0.8866 - val_loss: 0.3032 - val_acc: 0.9525\n",
      "Epoch 214/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3861 - acc: 0.8867 - val_loss: 0.3023 - val_acc: 0.9525\n",
      "Epoch 215/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3852 - acc: 0.8867 - val_loss: 0.3014 - val_acc: 0.9525\n",
      "Epoch 216/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3851 - acc: 0.8867 - val_loss: 0.3006 - val_acc: 0.9525\n",
      "Epoch 217/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3842 - acc: 0.8867 - val_loss: 0.2997 - val_acc: 0.9525\n",
      "Epoch 218/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3834 - acc: 0.8867 - val_loss: 0.2989 - val_acc: 0.9525\n",
      "Epoch 219/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3829 - acc: 0.8869 - val_loss: 0.2980 - val_acc: 0.9525\n",
      "Epoch 220/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3821 - acc: 0.8868 - val_loss: 0.2972 - val_acc: 0.9525\n",
      "Epoch 221/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3819 - acc: 0.8868 - val_loss: 0.2964 - val_acc: 0.9525\n",
      "Epoch 222/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3818 - acc: 0.8867 - val_loss: 0.2955 - val_acc: 0.9525\n",
      "Epoch 223/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3810 - acc: 0.8867 - val_loss: 0.2947 - val_acc: 0.9525\n",
      "Epoch 224/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3799 - acc: 0.8868 - val_loss: 0.2939 - val_acc: 0.9525\n",
      "Epoch 225/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3792 - acc: 0.8868 - val_loss: 0.2931 - val_acc: 0.9525\n",
      "Epoch 226/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3789 - acc: 0.8868 - val_loss: 0.2923 - val_acc: 0.9525\n",
      "Epoch 227/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3781 - acc: 0.8867 - val_loss: 0.2915 - val_acc: 0.9525\n",
      "Epoch 228/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3779 - acc: 0.8868 - val_loss: 0.2907 - val_acc: 0.9525\n",
      "Epoch 229/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3776 - acc: 0.8867 - val_loss: 0.2899 - val_acc: 0.9525\n",
      "Epoch 230/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3768 - acc: 0.8866 - val_loss: 0.2891 - val_acc: 0.9525\n",
      "Epoch 231/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3762 - acc: 0.8867 - val_loss: 0.2883 - val_acc: 0.9525\n",
      "Epoch 232/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3756 - acc: 0.8868 - val_loss: 0.2875 - val_acc: 0.9525\n",
      "Epoch 233/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3754 - acc: 0.8867 - val_loss: 0.2868 - val_acc: 0.9525\n",
      "Epoch 234/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3750 - acc: 0.8868 - val_loss: 0.2860 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3744 - acc: 0.8867 - val_loss: 0.2852 - val_acc: 0.9525\n",
      "Epoch 236/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3739 - acc: 0.8868 - val_loss: 0.2845 - val_acc: 0.9525\n",
      "Epoch 237/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3733 - acc: 0.8868 - val_loss: 0.2837 - val_acc: 0.9525\n",
      "Epoch 238/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3724 - acc: 0.8867 - val_loss: 0.2830 - val_acc: 0.9525\n",
      "Epoch 239/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3718 - acc: 0.8867 - val_loss: 0.2822 - val_acc: 0.9525\n",
      "Epoch 240/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3714 - acc: 0.8868 - val_loss: 0.2815 - val_acc: 0.9525\n",
      "Epoch 241/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3711 - acc: 0.8868 - val_loss: 0.2808 - val_acc: 0.9525\n",
      "Epoch 242/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3708 - acc: 0.8867 - val_loss: 0.2801 - val_acc: 0.9525\n",
      "Epoch 243/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3697 - acc: 0.8868 - val_loss: 0.2793 - val_acc: 0.9525\n",
      "Epoch 244/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3700 - acc: 0.8868 - val_loss: 0.2786 - val_acc: 0.9525\n",
      "Epoch 245/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3691 - acc: 0.8867 - val_loss: 0.2779 - val_acc: 0.9525\n",
      "Epoch 246/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3689 - acc: 0.8867 - val_loss: 0.2772 - val_acc: 0.9525\n",
      "Epoch 247/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3683 - acc: 0.8869 - val_loss: 0.2765 - val_acc: 0.9525\n",
      "Epoch 248/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3674 - acc: 0.8868 - val_loss: 0.2758 - val_acc: 0.9525\n",
      "Epoch 249/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3672 - acc: 0.8868 - val_loss: 0.2751 - val_acc: 0.9525\n",
      "Epoch 250/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3672 - acc: 0.8868 - val_loss: 0.2744 - val_acc: 0.9525\n",
      "Epoch 251/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3663 - acc: 0.8867 - val_loss: 0.2738 - val_acc: 0.9525\n",
      "Epoch 252/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3662 - acc: 0.8867 - val_loss: 0.2731 - val_acc: 0.9525\n",
      "Epoch 253/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3658 - acc: 0.8867 - val_loss: 0.2724 - val_acc: 0.9525\n",
      "Epoch 254/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3657 - acc: 0.8867 - val_loss: 0.2717 - val_acc: 0.9525\n",
      "Epoch 255/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3649 - acc: 0.8868 - val_loss: 0.2711 - val_acc: 0.9525\n",
      "Epoch 256/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3643 - acc: 0.8868 - val_loss: 0.2704 - val_acc: 0.9525\n",
      "Epoch 257/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3641 - acc: 0.8867 - val_loss: 0.2697 - val_acc: 0.9525\n",
      "Epoch 258/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3636 - acc: 0.8868 - val_loss: 0.2691 - val_acc: 0.9525\n",
      "Epoch 259/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3625 - acc: 0.8867 - val_loss: 0.2684 - val_acc: 0.9525\n",
      "Epoch 260/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3628 - acc: 0.8868 - val_loss: 0.2678 - val_acc: 0.9525\n",
      "Epoch 261/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3617 - acc: 0.8867 - val_loss: 0.2672 - val_acc: 0.9525\n",
      "Epoch 262/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3613 - acc: 0.8867 - val_loss: 0.2665 - val_acc: 0.9525\n",
      "Epoch 263/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3613 - acc: 0.8868 - val_loss: 0.2659 - val_acc: 0.9525\n",
      "Epoch 264/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3610 - acc: 0.8867 - val_loss: 0.2653 - val_acc: 0.9525\n",
      "Epoch 265/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3605 - acc: 0.8867 - val_loss: 0.2647 - val_acc: 0.9525\n",
      "Epoch 266/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3599 - acc: 0.8867 - val_loss: 0.2640 - val_acc: 0.9525\n",
      "Epoch 267/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3596 - acc: 0.8867 - val_loss: 0.2634 - val_acc: 0.9525\n",
      "Epoch 268/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3592 - acc: 0.8867 - val_loss: 0.2628 - val_acc: 0.9525\n",
      "Epoch 269/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3591 - acc: 0.8867 - val_loss: 0.2622 - val_acc: 0.9525\n",
      "Epoch 270/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3591 - acc: 0.8868 - val_loss: 0.2616 - val_acc: 0.9525\n",
      "Epoch 271/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3580 - acc: 0.8867 - val_loss: 0.2610 - val_acc: 0.9525\n",
      "Epoch 272/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3580 - acc: 0.8868 - val_loss: 0.2604 - val_acc: 0.9525\n",
      "Epoch 273/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3572 - acc: 0.8868 - val_loss: 0.2598 - val_acc: 0.9525\n",
      "Epoch 274/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3572 - acc: 0.8867 - val_loss: 0.2592 - val_acc: 0.9525\n",
      "Epoch 275/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3566 - acc: 0.8868 - val_loss: 0.2587 - val_acc: 0.9525\n",
      "Epoch 276/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3562 - acc: 0.8867 - val_loss: 0.2581 - val_acc: 0.9525\n",
      "Epoch 277/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3558 - acc: 0.8868 - val_loss: 0.2575 - val_acc: 0.9525\n",
      "Epoch 278/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3554 - acc: 0.8867 - val_loss: 0.2569 - val_acc: 0.9525\n",
      "Epoch 279/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3552 - acc: 0.8868 - val_loss: 0.2564 - val_acc: 0.9525\n",
      "Epoch 280/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3548 - acc: 0.8867 - val_loss: 0.2558 - val_acc: 0.9525\n",
      "Epoch 281/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3545 - acc: 0.8867 - val_loss: 0.2553 - val_acc: 0.9525\n",
      "Epoch 282/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3544 - acc: 0.8868 - val_loss: 0.2547 - val_acc: 0.9525\n",
      "Epoch 283/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3542 - acc: 0.8867 - val_loss: 0.2542 - val_acc: 0.9525\n",
      "Epoch 284/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3535 - acc: 0.8868 - val_loss: 0.2536 - val_acc: 0.9525\n",
      "Epoch 285/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3533 - acc: 0.8867 - val_loss: 0.2531 - val_acc: 0.9525\n",
      "Epoch 286/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3529 - acc: 0.8868 - val_loss: 0.2526 - val_acc: 0.9525\n",
      "Epoch 287/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3520 - acc: 0.8868 - val_loss: 0.2520 - val_acc: 0.9525\n",
      "Epoch 288/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3524 - acc: 0.8867 - val_loss: 0.2515 - val_acc: 0.9525\n",
      "Epoch 289/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3526 - acc: 0.8868 - val_loss: 0.2510 - val_acc: 0.9525\n",
      "Epoch 290/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3512 - acc: 0.8867 - val_loss: 0.2504 - val_acc: 0.9525\n",
      "Epoch 291/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3517 - acc: 0.8868 - val_loss: 0.2499 - val_acc: 0.9525\n",
      "Epoch 292/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3509 - acc: 0.8867 - val_loss: 0.2494 - val_acc: 0.9525\n",
      "Epoch 293/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3506 - acc: 0.8867 - val_loss: 0.2489 - val_acc: 0.9525\n",
      "Epoch 294/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3501 - acc: 0.8868 - val_loss: 0.2484 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3500 - acc: 0.8867 - val_loss: 0.2479 - val_acc: 0.9525\n",
      "Epoch 296/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3495 - acc: 0.8867 - val_loss: 0.2474 - val_acc: 0.9525\n",
      "Epoch 297/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3492 - acc: 0.8868 - val_loss: 0.2469 - val_acc: 0.9525\n",
      "Epoch 298/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3488 - acc: 0.8867 - val_loss: 0.2464 - val_acc: 0.9525\n",
      "Epoch 299/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3486 - acc: 0.8868 - val_loss: 0.2459 - val_acc: 0.9525\n",
      "Epoch 300/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3485 - acc: 0.8868 - val_loss: 0.2454 - val_acc: 0.9525\n",
      "Epoch 301/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3483 - acc: 0.8868 - val_loss: 0.2449 - val_acc: 0.9525\n",
      "Epoch 302/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3476 - acc: 0.8868 - val_loss: 0.2445 - val_acc: 0.9525\n",
      "Epoch 303/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3481 - acc: 0.8868 - val_loss: 0.2440 - val_acc: 0.9525\n",
      "Epoch 304/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3471 - acc: 0.8868 - val_loss: 0.2435 - val_acc: 0.9525\n",
      "Epoch 305/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3470 - acc: 0.8867 - val_loss: 0.2431 - val_acc: 0.9525\n",
      "Epoch 306/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3465 - acc: 0.8868 - val_loss: 0.2426 - val_acc: 0.9525\n",
      "Epoch 307/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3468 - acc: 0.8867 - val_loss: 0.2421 - val_acc: 0.9525\n",
      "Epoch 308/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3465 - acc: 0.8867 - val_loss: 0.2417 - val_acc: 0.9525\n",
      "Epoch 309/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3459 - acc: 0.8868 - val_loss: 0.2412 - val_acc: 0.9525\n",
      "Epoch 310/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3458 - acc: 0.8868 - val_loss: 0.2408 - val_acc: 0.9525\n",
      "Epoch 311/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3455 - acc: 0.8867 - val_loss: 0.2403 - val_acc: 0.9525\n",
      "Epoch 312/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3450 - acc: 0.8868 - val_loss: 0.2399 - val_acc: 0.9525\n",
      "Epoch 313/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3452 - acc: 0.8867 - val_loss: 0.2394 - val_acc: 0.9525\n",
      "Epoch 314/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.3446 - acc: 0.8867 - val_loss: 0.2390 - val_acc: 0.9525\n",
      "Epoch 315/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3446 - acc: 0.8867 - val_loss: 0.2386 - val_acc: 0.9525\n",
      "Epoch 316/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3439 - acc: 0.8868 - val_loss: 0.2381 - val_acc: 0.9525\n",
      "Epoch 317/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3437 - acc: 0.8867 - val_loss: 0.2377 - val_acc: 0.9525\n",
      "Epoch 318/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3436 - acc: 0.8868 - val_loss: 0.2373 - val_acc: 0.9525\n",
      "Epoch 319/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3434 - acc: 0.8868 - val_loss: 0.2369 - val_acc: 0.9525\n",
      "Epoch 320/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3435 - acc: 0.8868 - val_loss: 0.2364 - val_acc: 0.9525\n",
      "Epoch 321/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3429 - acc: 0.8867 - val_loss: 0.2360 - val_acc: 0.9525\n",
      "Epoch 322/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3425 - acc: 0.8868 - val_loss: 0.2356 - val_acc: 0.9525\n",
      "Epoch 323/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3424 - acc: 0.8868 - val_loss: 0.2352 - val_acc: 0.9525\n",
      "Epoch 324/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3418 - acc: 0.8868 - val_loss: 0.2348 - val_acc: 0.9525\n",
      "Epoch 325/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3418 - acc: 0.8868 - val_loss: 0.2344 - val_acc: 0.9525\n",
      "Epoch 326/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3414 - acc: 0.8867 - val_loss: 0.2340 - val_acc: 0.9525\n",
      "Epoch 327/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3417 - acc: 0.8867 - val_loss: 0.2336 - val_acc: 0.9525\n",
      "Epoch 328/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3415 - acc: 0.8867 - val_loss: 0.2332 - val_acc: 0.9525\n",
      "Epoch 329/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3415 - acc: 0.8868 - val_loss: 0.2328 - val_acc: 0.9525\n",
      "Epoch 330/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3408 - acc: 0.8868 - val_loss: 0.2324 - val_acc: 0.9525\n",
      "Epoch 331/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3406 - acc: 0.8868 - val_loss: 0.2320 - val_acc: 0.9525\n",
      "Epoch 332/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3402 - acc: 0.8868 - val_loss: 0.2316 - val_acc: 0.9525\n",
      "Epoch 333/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3401 - acc: 0.8867 - val_loss: 0.2313 - val_acc: 0.9525\n",
      "Epoch 334/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3398 - acc: 0.8868 - val_loss: 0.2309 - val_acc: 0.9525\n",
      "Epoch 335/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3397 - acc: 0.8868 - val_loss: 0.2305 - val_acc: 0.9525\n",
      "Epoch 336/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3391 - acc: 0.8867 - val_loss: 0.2301 - val_acc: 0.9525\n",
      "Epoch 337/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3393 - acc: 0.8867 - val_loss: 0.2298 - val_acc: 0.9525\n",
      "Epoch 338/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3393 - acc: 0.8868 - val_loss: 0.2294 - val_acc: 0.9525\n",
      "Epoch 339/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3389 - acc: 0.8867 - val_loss: 0.2290 - val_acc: 0.9525\n",
      "Epoch 340/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3386 - acc: 0.8868 - val_loss: 0.2287 - val_acc: 0.9525\n",
      "Epoch 341/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3381 - acc: 0.8868 - val_loss: 0.2283 - val_acc: 0.9525\n",
      "Epoch 342/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3382 - acc: 0.8868 - val_loss: 0.2280 - val_acc: 0.9525\n",
      "Epoch 343/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3380 - acc: 0.8867 - val_loss: 0.2276 - val_acc: 0.9525\n",
      "Epoch 344/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3381 - acc: 0.8868 - val_loss: 0.2273 - val_acc: 0.9525\n",
      "Epoch 345/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3377 - acc: 0.8868 - val_loss: 0.2269 - val_acc: 0.9525\n",
      "Epoch 346/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3376 - acc: 0.8868 - val_loss: 0.2266 - val_acc: 0.9525\n",
      "Epoch 347/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3374 - acc: 0.8868 - val_loss: 0.2262 - val_acc: 0.9525\n",
      "Epoch 348/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3368 - acc: 0.8867 - val_loss: 0.2259 - val_acc: 0.9525\n",
      "Epoch 349/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3369 - acc: 0.8868 - val_loss: 0.2256 - val_acc: 0.9525\n",
      "Epoch 350/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3366 - acc: 0.8867 - val_loss: 0.2253 - val_acc: 0.9525\n",
      "Epoch 351/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3367 - acc: 0.8868 - val_loss: 0.2249 - val_acc: 0.9525\n",
      "Epoch 352/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3364 - acc: 0.8867 - val_loss: 0.2246 - val_acc: 0.9525\n",
      "Epoch 353/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3362 - acc: 0.8868 - val_loss: 0.2243 - val_acc: 0.9525\n",
      "Epoch 354/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3359 - acc: 0.8867 - val_loss: 0.2240 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3360 - acc: 0.8867 - val_loss: 0.2236 - val_acc: 0.9525\n",
      "Epoch 356/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3357 - acc: 0.8868 - val_loss: 0.2233 - val_acc: 0.9525\n",
      "Epoch 357/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3355 - acc: 0.8868 - val_loss: 0.2230 - val_acc: 0.9525\n",
      "Epoch 358/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3352 - acc: 0.8867 - val_loss: 0.2227 - val_acc: 0.9525\n",
      "Epoch 359/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3354 - acc: 0.8868 - val_loss: 0.2224 - val_acc: 0.9525\n",
      "Epoch 360/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3351 - acc: 0.8867 - val_loss: 0.2221 - val_acc: 0.9525\n",
      "Epoch 361/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3349 - acc: 0.8868 - val_loss: 0.2218 - val_acc: 0.9525\n",
      "Epoch 362/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3349 - acc: 0.8867 - val_loss: 0.2215 - val_acc: 0.9525\n",
      "Epoch 363/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3346 - acc: 0.8868 - val_loss: 0.2212 - val_acc: 0.9525\n",
      "Epoch 364/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3345 - acc: 0.8867 - val_loss: 0.2209 - val_acc: 0.9525\n",
      "Epoch 365/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3340 - acc: 0.8868 - val_loss: 0.2206 - val_acc: 0.9525\n",
      "Epoch 366/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3341 - acc: 0.8868 - val_loss: 0.2203 - val_acc: 0.9525\n",
      "Epoch 367/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3335 - acc: 0.8867 - val_loss: 0.2200 - val_acc: 0.9525\n",
      "Epoch 368/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3339 - acc: 0.8867 - val_loss: 0.2197 - val_acc: 0.9525\n",
      "Epoch 369/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3335 - acc: 0.8867 - val_loss: 0.2194 - val_acc: 0.9525\n",
      "Epoch 370/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3338 - acc: 0.8868 - val_loss: 0.2192 - val_acc: 0.9525\n",
      "Epoch 371/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3331 - acc: 0.8868 - val_loss: 0.2189 - val_acc: 0.9525\n",
      "Epoch 372/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3331 - acc: 0.8868 - val_loss: 0.2186 - val_acc: 0.9525\n",
      "Epoch 373/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3326 - acc: 0.8868 - val_loss: 0.2183 - val_acc: 0.9525\n",
      "Epoch 374/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3331 - acc: 0.8868 - val_loss: 0.2180 - val_acc: 0.9525\n",
      "Epoch 375/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3327 - acc: 0.8868 - val_loss: 0.2177 - val_acc: 0.9525\n",
      "Epoch 376/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3325 - acc: 0.8868 - val_loss: 0.2175 - val_acc: 0.9525\n",
      "Epoch 377/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3323 - acc: 0.8868 - val_loss: 0.2172 - val_acc: 0.9525\n",
      "Epoch 378/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3322 - acc: 0.8867 - val_loss: 0.2169 - val_acc: 0.9525\n",
      "Epoch 379/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3324 - acc: 0.8867 - val_loss: 0.2167 - val_acc: 0.9525\n",
      "Epoch 380/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3323 - acc: 0.8868 - val_loss: 0.2164 - val_acc: 0.9525\n",
      "Epoch 381/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3318 - acc: 0.8868 - val_loss: 0.2161 - val_acc: 0.9525\n",
      "Epoch 382/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3318 - acc: 0.8867 - val_loss: 0.2159 - val_acc: 0.9525\n",
      "Epoch 383/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3318 - acc: 0.8868 - val_loss: 0.2156 - val_acc: 0.9525\n",
      "Epoch 384/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3314 - acc: 0.8867 - val_loss: 0.2154 - val_acc: 0.9525\n",
      "Epoch 385/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3314 - acc: 0.8868 - val_loss: 0.2151 - val_acc: 0.9525\n",
      "Epoch 386/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3314 - acc: 0.8868 - val_loss: 0.2149 - val_acc: 0.9525\n",
      "Epoch 387/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3310 - acc: 0.8867 - val_loss: 0.2146 - val_acc: 0.9525\n",
      "Epoch 388/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3312 - acc: 0.8867 - val_loss: 0.2144 - val_acc: 0.9525\n",
      "Epoch 389/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3311 - acc: 0.8868 - val_loss: 0.2142 - val_acc: 0.9525\n",
      "Epoch 390/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3307 - acc: 0.8867 - val_loss: 0.2139 - val_acc: 0.9525\n",
      "Epoch 391/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3310 - acc: 0.8867 - val_loss: 0.2137 - val_acc: 0.9525\n",
      "Epoch 392/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3305 - acc: 0.8868 - val_loss: 0.2134 - val_acc: 0.9525\n",
      "Epoch 393/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3305 - acc: 0.8867 - val_loss: 0.2132 - val_acc: 0.9525\n",
      "Epoch 394/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3303 - acc: 0.8868 - val_loss: 0.2130 - val_acc: 0.9525\n",
      "Epoch 395/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3301 - acc: 0.8867 - val_loss: 0.2127 - val_acc: 0.9525\n",
      "Epoch 396/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3303 - acc: 0.8867 - val_loss: 0.2125 - val_acc: 0.9525\n",
      "Epoch 397/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3302 - acc: 0.8868 - val_loss: 0.2123 - val_acc: 0.9525\n",
      "Epoch 398/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3296 - acc: 0.8868 - val_loss: 0.2121 - val_acc: 0.9525\n",
      "Epoch 399/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3302 - acc: 0.8868 - val_loss: 0.2119 - val_acc: 0.9525\n",
      "Epoch 400/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3297 - acc: 0.8868 - val_loss: 0.2117 - val_acc: 0.9525\n",
      "Epoch 401/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3293 - acc: 0.8867 - val_loss: 0.2114 - val_acc: 0.9525\n",
      "Epoch 402/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3295 - acc: 0.8867 - val_loss: 0.2112 - val_acc: 0.9525\n",
      "Epoch 403/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3294 - acc: 0.8868 - val_loss: 0.2110 - val_acc: 0.9525\n",
      "Epoch 404/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3290 - acc: 0.8868 - val_loss: 0.2108 - val_acc: 0.9525\n",
      "Epoch 405/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3294 - acc: 0.8867 - val_loss: 0.2106 - val_acc: 0.9525\n",
      "Epoch 406/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3292 - acc: 0.8868 - val_loss: 0.2104 - val_acc: 0.9525\n",
      "Epoch 407/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3288 - acc: 0.8868 - val_loss: 0.2102 - val_acc: 0.9525\n",
      "Epoch 408/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3291 - acc: 0.8868 - val_loss: 0.2100 - val_acc: 0.9525\n",
      "Epoch 409/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3289 - acc: 0.8868 - val_loss: 0.2098 - val_acc: 0.9525\n",
      "Epoch 410/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3284 - acc: 0.8868 - val_loss: 0.2096 - val_acc: 0.9525\n",
      "Epoch 411/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3285 - acc: 0.8867 - val_loss: 0.2094 - val_acc: 0.9525\n",
      "Epoch 412/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3284 - acc: 0.8867 - val_loss: 0.2092 - val_acc: 0.9525\n",
      "Epoch 413/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3284 - acc: 0.8868 - val_loss: 0.2090 - val_acc: 0.9525\n",
      "Epoch 414/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3284 - acc: 0.8867 - val_loss: 0.2088 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3281 - acc: 0.8868 - val_loss: 0.2086 - val_acc: 0.9525\n",
      "Epoch 416/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3281 - acc: 0.8867 - val_loss: 0.2084 - val_acc: 0.9525\n",
      "Epoch 417/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3279 - acc: 0.8868 - val_loss: 0.2082 - val_acc: 0.9525\n",
      "Epoch 418/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3280 - acc: 0.8868 - val_loss: 0.2080 - val_acc: 0.9525\n",
      "Epoch 419/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3281 - acc: 0.8867 - val_loss: 0.2078 - val_acc: 0.9525\n",
      "Epoch 420/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3281 - acc: 0.8867 - val_loss: 0.2076 - val_acc: 0.9525\n",
      "Epoch 421/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3279 - acc: 0.8868 - val_loss: 0.2075 - val_acc: 0.9525\n",
      "Epoch 422/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3280 - acc: 0.8867 - val_loss: 0.2073 - val_acc: 0.9525\n",
      "Epoch 423/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3276 - acc: 0.8867 - val_loss: 0.2071 - val_acc: 0.9525\n",
      "Epoch 424/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3274 - acc: 0.8868 - val_loss: 0.2069 - val_acc: 0.9525\n",
      "Epoch 425/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3274 - acc: 0.8868 - val_loss: 0.2067 - val_acc: 0.9525\n",
      "Epoch 426/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3274 - acc: 0.8868 - val_loss: 0.2066 - val_acc: 0.9525\n",
      "Epoch 427/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3273 - acc: 0.8867 - val_loss: 0.2064 - val_acc: 0.9525\n",
      "Epoch 428/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3274 - acc: 0.8868 - val_loss: 0.2062 - val_acc: 0.9525\n",
      "Epoch 429/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3268 - acc: 0.8867 - val_loss: 0.2061 - val_acc: 0.9525\n",
      "Epoch 430/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3270 - acc: 0.8868 - val_loss: 0.2059 - val_acc: 0.9525\n",
      "Epoch 431/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3270 - acc: 0.8867 - val_loss: 0.2057 - val_acc: 0.9525\n",
      "Epoch 432/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3271 - acc: 0.8867 - val_loss: 0.2056 - val_acc: 0.9525\n",
      "Epoch 433/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3265 - acc: 0.8867 - val_loss: 0.2054 - val_acc: 0.9525\n",
      "Epoch 434/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3267 - acc: 0.8867 - val_loss: 0.2052 - val_acc: 0.9525\n",
      "Epoch 435/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3266 - acc: 0.8868 - val_loss: 0.2051 - val_acc: 0.9525\n",
      "Epoch 436/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3263 - acc: 0.8868 - val_loss: 0.2049 - val_acc: 0.9525\n",
      "Epoch 437/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3265 - acc: 0.8867 - val_loss: 0.2048 - val_acc: 0.9525\n",
      "Epoch 438/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3264 - acc: 0.8868 - val_loss: 0.2046 - val_acc: 0.9525\n",
      "Epoch 439/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3261 - acc: 0.8868 - val_loss: 0.2045 - val_acc: 0.9525\n",
      "Epoch 440/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3263 - acc: 0.8868 - val_loss: 0.2043 - val_acc: 0.9525\n",
      "Epoch 441/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3263 - acc: 0.8868 - val_loss: 0.2042 - val_acc: 0.9525\n",
      "Epoch 442/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3263 - acc: 0.8868 - val_loss: 0.2040 - val_acc: 0.9525\n",
      "Epoch 443/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3258 - acc: 0.8868 - val_loss: 0.2038 - val_acc: 0.9525\n",
      "Epoch 444/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3261 - acc: 0.8868 - val_loss: 0.2037 - val_acc: 0.9525\n",
      "Epoch 445/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3259 - acc: 0.8868 - val_loss: 0.2035 - val_acc: 0.9525\n",
      "Epoch 446/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3257 - acc: 0.8868 - val_loss: 0.2034 - val_acc: 0.9525\n",
      "Epoch 447/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3260 - acc: 0.8868 - val_loss: 0.2032 - val_acc: 0.9525\n",
      "Epoch 448/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3256 - acc: 0.8868 - val_loss: 0.2031 - val_acc: 0.9525\n",
      "Epoch 449/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3258 - acc: 0.8868 - val_loss: 0.2030 - val_acc: 0.9525\n",
      "Epoch 450/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3258 - acc: 0.8868 - val_loss: 0.2028 - val_acc: 0.9525\n",
      "Epoch 451/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3256 - acc: 0.8868 - val_loss: 0.2027 - val_acc: 0.9525\n",
      "Epoch 452/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3254 - acc: 0.8867 - val_loss: 0.2025 - val_acc: 0.9525\n",
      "Epoch 453/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3254 - acc: 0.8868 - val_loss: 0.2024 - val_acc: 0.9525\n",
      "Epoch 454/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3257 - acc: 0.8868 - val_loss: 0.2023 - val_acc: 0.9525\n",
      "Epoch 455/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3256 - acc: 0.8868 - val_loss: 0.2021 - val_acc: 0.9525\n",
      "Epoch 456/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3256 - acc: 0.8867 - val_loss: 0.2020 - val_acc: 0.9525\n",
      "Epoch 457/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3251 - acc: 0.8868 - val_loss: 0.2019 - val_acc: 0.9525\n",
      "Epoch 458/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3255 - acc: 0.8867 - val_loss: 0.2017 - val_acc: 0.9525\n",
      "Epoch 459/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3251 - acc: 0.8867 - val_loss: 0.2016 - val_acc: 0.9525\n",
      "Epoch 460/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3251 - acc: 0.8867 - val_loss: 0.2015 - val_acc: 0.9525\n",
      "Epoch 461/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3249 - acc: 0.8868 - val_loss: 0.2014 - val_acc: 0.9525\n",
      "Epoch 462/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3250 - acc: 0.8868 - val_loss: 0.2012 - val_acc: 0.9525\n",
      "Epoch 463/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3249 - acc: 0.8868 - val_loss: 0.2011 - val_acc: 0.9525\n",
      "Epoch 464/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3251 - acc: 0.8867 - val_loss: 0.2010 - val_acc: 0.9525\n",
      "Epoch 465/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3248 - acc: 0.8868 - val_loss: 0.2009 - val_acc: 0.9525\n",
      "Epoch 466/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3247 - acc: 0.8868 - val_loss: 0.2008 - val_acc: 0.9525\n",
      "Epoch 467/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3248 - acc: 0.8868 - val_loss: 0.2006 - val_acc: 0.9525\n",
      "Epoch 468/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3246 - acc: 0.8867 - val_loss: 0.2005 - val_acc: 0.9525\n",
      "Epoch 469/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3247 - acc: 0.8867 - val_loss: 0.2004 - val_acc: 0.9525\n",
      "Epoch 470/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3245 - acc: 0.8867 - val_loss: 0.2003 - val_acc: 0.9525\n",
      "Epoch 471/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3247 - acc: 0.8868 - val_loss: 0.2002 - val_acc: 0.9525\n",
      "Epoch 472/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3244 - acc: 0.8868 - val_loss: 0.2001 - val_acc: 0.9525\n",
      "Epoch 473/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3245 - acc: 0.8868 - val_loss: 0.1999 - val_acc: 0.9525\n",
      "Epoch 474/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3245 - acc: 0.8867 - val_loss: 0.1998 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3245 - acc: 0.8868 - val_loss: 0.1997 - val_acc: 0.9525\n",
      "Epoch 476/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8868 - val_loss: 0.1996 - val_acc: 0.9525\n",
      "Epoch 477/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3244 - acc: 0.8868 - val_loss: 0.1995 - val_acc: 0.9525\n",
      "Epoch 478/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3244 - acc: 0.8868 - val_loss: 0.1994 - val_acc: 0.9525\n",
      "Epoch 479/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3243 - acc: 0.8868 - val_loss: 0.1993 - val_acc: 0.9525\n",
      "Epoch 480/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8868 - val_loss: 0.1992 - val_acc: 0.9525\n",
      "Epoch 481/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3241 - acc: 0.8867 - val_loss: 0.1991 - val_acc: 0.9525\n",
      "Epoch 482/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3242 - acc: 0.8868 - val_loss: 0.1990 - val_acc: 0.9525\n",
      "Epoch 483/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3241 - acc: 0.8868 - val_loss: 0.1989 - val_acc: 0.9525\n",
      "Epoch 484/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8867 - val_loss: 0.1988 - val_acc: 0.9525\n",
      "Epoch 485/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3241 - acc: 0.8867 - val_loss: 0.1987 - val_acc: 0.9525\n",
      "Epoch 486/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3237 - acc: 0.8868 - val_loss: 0.1986 - val_acc: 0.9525\n",
      "Epoch 487/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3239 - acc: 0.8868 - val_loss: 0.1985 - val_acc: 0.9525\n",
      "Epoch 488/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8868 - val_loss: 0.1984 - val_acc: 0.9525\n",
      "Epoch 489/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3239 - acc: 0.8868 - val_loss: 0.1983 - val_acc: 0.9525\n",
      "Epoch 490/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3241 - acc: 0.8868 - val_loss: 0.1982 - val_acc: 0.9525\n",
      "Epoch 491/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3237 - acc: 0.8868 - val_loss: 0.1981 - val_acc: 0.9525\n",
      "Epoch 492/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8868 - val_loss: 0.1980 - val_acc: 0.9525\n",
      "Epoch 493/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3234 - acc: 0.8868 - val_loss: 0.1979 - val_acc: 0.9525\n",
      "Epoch 494/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3240 - acc: 0.8868 - val_loss: 0.1978 - val_acc: 0.9525\n",
      "Epoch 495/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3236 - acc: 0.8868 - val_loss: 0.1977 - val_acc: 0.9525\n",
      "Epoch 496/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3237 - acc: 0.8868 - val_loss: 0.1976 - val_acc: 0.9525\n",
      "Epoch 497/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3237 - acc: 0.8868 - val_loss: 0.1975 - val_acc: 0.9525\n",
      "Epoch 498/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3232 - acc: 0.8868 - val_loss: 0.1975 - val_acc: 0.9525\n",
      "Epoch 499/500\n",
      "2789/2789 [==============================] - 5s 2ms/step - loss: 0.3236 - acc: 0.8867 - val_loss: 0.1974 - val_acc: 0.9525\n",
      "Epoch 500/500\n",
      "2789/2789 [==============================] - 6s 2ms/step - loss: 0.3236 - acc: 0.8868 - val_loss: 0.1973 - val_acc: 0.9525\n",
      "[17:40:07] train_log_loss:0.30852103374589035 test_log_loss:0.26074785877008777\n",
      "[17:40:07] train_acc:0.8934263327293337 test_acc:0.9186089805644501\n",
      "\n",
      "---------- split 1 ----------\n",
      "[17:40:07] train_index:0~6199 test_index:6200~9299\n",
      "Train on 5579 samples, validate on 620 samples\n",
      "Epoch 1/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.7030 - acc: 0.5211 - val_loss: 0.6764 - val_acc: 0.5762\n",
      "Epoch 2/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.6685 - acc: 0.5898 - val_loss: 0.6492 - val_acc: 0.6288\n",
      "Epoch 3/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.6466 - acc: 0.6318 - val_loss: 0.6292 - val_acc: 0.6730\n",
      "Epoch 4/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.6292 - acc: 0.6639 - val_loss: 0.6129 - val_acc: 0.7005\n",
      "Epoch 5/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.6149 - acc: 0.6907 - val_loss: 0.5988 - val_acc: 0.7322\n",
      "Epoch 6/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.6026 - acc: 0.7132 - val_loss: 0.5865 - val_acc: 0.7508\n",
      "Epoch 7/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5914 - acc: 0.7330 - val_loss: 0.5753 - val_acc: 0.7699\n",
      "Epoch 8/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5811 - acc: 0.7510 - val_loss: 0.5651 - val_acc: 0.7936\n",
      "Epoch 9/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5720 - acc: 0.7664 - val_loss: 0.5556 - val_acc: 0.8020\n",
      "Epoch 10/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5635 - acc: 0.7809 - val_loss: 0.5469 - val_acc: 0.8114\n",
      "Epoch 11/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5553 - acc: 0.7943 - val_loss: 0.5386 - val_acc: 0.8342\n",
      "Epoch 12/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5477 - acc: 0.8064 - val_loss: 0.5309 - val_acc: 0.8463\n",
      "Epoch 13/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5408 - acc: 0.8171 - val_loss: 0.5235 - val_acc: 0.8561\n",
      "Epoch 14/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5341 - acc: 0.8273 - val_loss: 0.5166 - val_acc: 0.8684\n",
      "Epoch 15/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5277 - acc: 0.8369 - val_loss: 0.5099 - val_acc: 0.8841\n",
      "Epoch 16/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5218 - acc: 0.8445 - val_loss: 0.5036 - val_acc: 0.8841\n",
      "Epoch 17/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5159 - acc: 0.8521 - val_loss: 0.4975 - val_acc: 0.8981\n",
      "Epoch 18/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5101 - acc: 0.8590 - val_loss: 0.4917 - val_acc: 0.9028\n",
      "Epoch 19/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.5050 - acc: 0.8644 - val_loss: 0.4861 - val_acc: 0.9075\n",
      "Epoch 20/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4998 - acc: 0.8696 - val_loss: 0.4807 - val_acc: 0.9170\n",
      "Epoch 21/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4948 - acc: 0.8744 - val_loss: 0.4755 - val_acc: 0.9209\n",
      "Epoch 22/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4904 - acc: 0.8782 - val_loss: 0.4704 - val_acc: 0.9209\n",
      "Epoch 23/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4854 - acc: 0.8815 - val_loss: 0.4655 - val_acc: 0.9209\n",
      "Epoch 24/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4811 - acc: 0.8846 - val_loss: 0.4608 - val_acc: 0.9209\n",
      "Epoch 25/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4767 - acc: 0.8871 - val_loss: 0.4562 - val_acc: 0.9199\n",
      "Epoch 26/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4721 - acc: 0.8895 - val_loss: 0.4518 - val_acc: 0.9199\n",
      "Epoch 27/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4685 - acc: 0.8909 - val_loss: 0.4475 - val_acc: 0.9199\n",
      "Epoch 28/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4644 - acc: 0.8927 - val_loss: 0.4433 - val_acc: 0.9199\n",
      "Epoch 29/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4605 - acc: 0.8940 - val_loss: 0.4392 - val_acc: 0.9199\n",
      "Epoch 30/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4570 - acc: 0.8952 - val_loss: 0.4352 - val_acc: 0.9199\n",
      "Epoch 31/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4534 - acc: 0.8961 - val_loss: 0.4313 - val_acc: 0.9199\n",
      "Epoch 32/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4499 - acc: 0.8970 - val_loss: 0.4275 - val_acc: 0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4461 - acc: 0.8981 - val_loss: 0.4238 - val_acc: 0.9199\n",
      "Epoch 34/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4430 - acc: 0.8989 - val_loss: 0.4202 - val_acc: 0.9192\n",
      "Epoch 35/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4398 - acc: 0.8997 - val_loss: 0.4167 - val_acc: 0.9192\n",
      "Epoch 36/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4363 - acc: 0.9002 - val_loss: 0.4133 - val_acc: 0.9243\n",
      "Epoch 37/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4334 - acc: 0.9009 - val_loss: 0.4100 - val_acc: 0.9243\n",
      "Epoch 38/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4298 - acc: 0.9011 - val_loss: 0.4067 - val_acc: 0.9243\n",
      "Epoch 39/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4271 - acc: 0.9016 - val_loss: 0.4035 - val_acc: 0.9243\n",
      "Epoch 40/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4247 - acc: 0.9019 - val_loss: 0.4003 - val_acc: 0.9243\n",
      "Epoch 41/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4214 - acc: 0.9024 - val_loss: 0.3973 - val_acc: 0.9243\n",
      "Epoch 42/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4191 - acc: 0.9026 - val_loss: 0.3943 - val_acc: 0.9243\n",
      "Epoch 43/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4160 - acc: 0.9029 - val_loss: 0.3913 - val_acc: 0.9243\n",
      "Epoch 44/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4136 - acc: 0.9031 - val_loss: 0.3885 - val_acc: 0.9243\n",
      "Epoch 45/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4105 - acc: 0.9034 - val_loss: 0.3856 - val_acc: 0.9243\n",
      "Epoch 46/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4082 - acc: 0.9035 - val_loss: 0.3829 - val_acc: 0.9243\n",
      "Epoch 47/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4057 - acc: 0.9035 - val_loss: 0.3802 - val_acc: 0.9243\n",
      "Epoch 48/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4036 - acc: 0.9037 - val_loss: 0.3775 - val_acc: 0.9243\n",
      "Epoch 49/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.4012 - acc: 0.9038 - val_loss: 0.3749 - val_acc: 0.9243\n",
      "Epoch 50/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3989 - acc: 0.9038 - val_loss: 0.3724 - val_acc: 0.9243\n",
      "Epoch 51/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3962 - acc: 0.9039 - val_loss: 0.3699 - val_acc: 0.9243\n",
      "Epoch 52/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3943 - acc: 0.9040 - val_loss: 0.3674 - val_acc: 0.9243\n",
      "Epoch 53/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3918 - acc: 0.9039 - val_loss: 0.3650 - val_acc: 0.9243\n",
      "Epoch 54/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3899 - acc: 0.9041 - val_loss: 0.3626 - val_acc: 0.9243\n",
      "Epoch 55/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3879 - acc: 0.9041 - val_loss: 0.3603 - val_acc: 0.9243\n",
      "Epoch 56/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3855 - acc: 0.9041 - val_loss: 0.3581 - val_acc: 0.9243\n",
      "Epoch 57/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3833 - acc: 0.9042 - val_loss: 0.3558 - val_acc: 0.9243\n",
      "Epoch 58/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3817 - acc: 0.9042 - val_loss: 0.3536 - val_acc: 0.9243\n",
      "Epoch 59/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3800 - acc: 0.9042 - val_loss: 0.3515 - val_acc: 0.9243\n",
      "Epoch 60/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3779 - acc: 0.9041 - val_loss: 0.3494 - val_acc: 0.9243\n",
      "Epoch 61/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3759 - acc: 0.9041 - val_loss: 0.3473 - val_acc: 0.9243\n",
      "Epoch 62/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3740 - acc: 0.9043 - val_loss: 0.3453 - val_acc: 0.9243\n",
      "Epoch 63/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3725 - acc: 0.9042 - val_loss: 0.3433 - val_acc: 0.9243\n",
      "Epoch 64/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3701 - acc: 0.9042 - val_loss: 0.3413 - val_acc: 0.9243\n",
      "Epoch 65/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3689 - acc: 0.9043 - val_loss: 0.3394 - val_acc: 0.9243\n",
      "Epoch 66/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3668 - acc: 0.9043 - val_loss: 0.3375 - val_acc: 0.9243\n",
      "Epoch 67/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3653 - acc: 0.9042 - val_loss: 0.3356 - val_acc: 0.9243\n",
      "Epoch 68/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3635 - acc: 0.9043 - val_loss: 0.3338 - val_acc: 0.9243\n",
      "Epoch 69/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3620 - acc: 0.9043 - val_loss: 0.3320 - val_acc: 0.9243\n",
      "Epoch 70/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3605 - acc: 0.9042 - val_loss: 0.3302 - val_acc: 0.9243\n",
      "Epoch 71/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3594 - acc: 0.9045 - val_loss: 0.3285 - val_acc: 0.9243\n",
      "Epoch 72/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3571 - acc: 0.9043 - val_loss: 0.3268 - val_acc: 0.9243\n",
      "Epoch 73/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3561 - acc: 0.9043 - val_loss: 0.3251 - val_acc: 0.9243\n",
      "Epoch 74/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3546 - acc: 0.9042 - val_loss: 0.3235 - val_acc: 0.9243\n",
      "Epoch 75/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3532 - acc: 0.9043 - val_loss: 0.3219 - val_acc: 0.9243\n",
      "Epoch 76/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3519 - acc: 0.9043 - val_loss: 0.3203 - val_acc: 0.9243\n",
      "Epoch 77/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3502 - acc: 0.9043 - val_loss: 0.3187 - val_acc: 0.9243\n",
      "Epoch 78/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3491 - acc: 0.9043 - val_loss: 0.3172 - val_acc: 0.9243\n",
      "Epoch 79/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3478 - acc: 0.9043 - val_loss: 0.3157 - val_acc: 0.9243\n",
      "Epoch 80/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3465 - acc: 0.9043 - val_loss: 0.3142 - val_acc: 0.9243\n",
      "Epoch 81/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3452 - acc: 0.9043 - val_loss: 0.3127 - val_acc: 0.9243\n",
      "Epoch 82/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3437 - acc: 0.9044 - val_loss: 0.3113 - val_acc: 0.9243\n",
      "Epoch 83/500\n",
      "5579/5579 [==============================] - 12s 2ms/step - loss: 0.3422 - acc: 0.9043 - val_loss: 0.3099 - val_acc: 0.9243\n",
      "Epoch 84/500\n",
      "5579/5579 [==============================] - 12s 2ms/step - loss: 0.3414 - acc: 0.9043 - val_loss: 0.3085 - val_acc: 0.9243\n",
      "Epoch 85/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3400 - acc: 0.9043 - val_loss: 0.3072 - val_acc: 0.9243\n",
      "Epoch 86/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.3395 - acc: 0.9042 - val_loss: 0.3058 - val_acc: 0.9243\n",
      "Epoch 87/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3381 - acc: 0.9043 - val_loss: 0.3045 - val_acc: 0.9243\n",
      "Epoch 88/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3367 - acc: 0.9043 - val_loss: 0.3032 - val_acc: 0.9243\n",
      "Epoch 89/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3358 - acc: 0.9043 - val_loss: 0.3020 - val_acc: 0.9243\n",
      "Epoch 90/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.3345 - acc: 0.9043 - val_loss: 0.3007 - val_acc: 0.9243\n",
      "Epoch 91/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.3334 - acc: 0.9043 - val_loss: 0.2995 - val_acc: 0.9243\n",
      "Epoch 92/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3331 - acc: 0.9043 - val_loss: 0.2983 - val_acc: 0.9243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3316 - acc: 0.9044 - val_loss: 0.2971 - val_acc: 0.9243\n",
      "Epoch 94/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3306 - acc: 0.9044 - val_loss: 0.2959 - val_acc: 0.9243\n",
      "Epoch 95/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3294 - acc: 0.9042 - val_loss: 0.2948 - val_acc: 0.9243\n",
      "Epoch 96/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3288 - acc: 0.9043 - val_loss: 0.2937 - val_acc: 0.9243\n",
      "Epoch 97/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3271 - acc: 0.9043 - val_loss: 0.2926 - val_acc: 0.9243\n",
      "Epoch 98/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3265 - acc: 0.9043 - val_loss: 0.2915 - val_acc: 0.9243\n",
      "Epoch 99/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3257 - acc: 0.9043 - val_loss: 0.2904 - val_acc: 0.9243\n",
      "Epoch 100/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3248 - acc: 0.9044 - val_loss: 0.2894 - val_acc: 0.9243\n",
      "Epoch 101/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3242 - acc: 0.9044 - val_loss: 0.2884 - val_acc: 0.9243\n",
      "Epoch 102/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3233 - acc: 0.9042 - val_loss: 0.2874 - val_acc: 0.9243\n",
      "Epoch 103/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3223 - acc: 0.9042 - val_loss: 0.2864 - val_acc: 0.9243\n",
      "Epoch 104/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3217 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9243\n",
      "Epoch 105/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3206 - acc: 0.9043 - val_loss: 0.2844 - val_acc: 0.9243\n",
      "Epoch 106/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3193 - acc: 0.9043 - val_loss: 0.2835 - val_acc: 0.9243\n",
      "Epoch 107/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3187 - acc: 0.9044 - val_loss: 0.2826 - val_acc: 0.9243\n",
      "Epoch 108/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3182 - acc: 0.9044 - val_loss: 0.2817 - val_acc: 0.9243\n",
      "Epoch 109/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3176 - acc: 0.9044 - val_loss: 0.2808 - val_acc: 0.9243\n",
      "Epoch 110/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3168 - acc: 0.9043 - val_loss: 0.2799 - val_acc: 0.9243\n",
      "Epoch 111/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3158 - acc: 0.9043 - val_loss: 0.2791 - val_acc: 0.9243\n",
      "Epoch 112/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3151 - acc: 0.9043 - val_loss: 0.2782 - val_acc: 0.9243\n",
      "Epoch 113/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.3145 - acc: 0.9043 - val_loss: 0.2774 - val_acc: 0.9243\n",
      "Epoch 114/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.3138 - acc: 0.9043 - val_loss: 0.2766 - val_acc: 0.9243\n",
      "Epoch 115/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3132 - acc: 0.9043 - val_loss: 0.2758 - val_acc: 0.9243\n",
      "Epoch 116/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3124 - acc: 0.9044 - val_loss: 0.2750 - val_acc: 0.9243\n",
      "Epoch 117/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3120 - acc: 0.9043 - val_loss: 0.2742 - val_acc: 0.9243\n",
      "Epoch 118/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3116 - acc: 0.9043 - val_loss: 0.2735 - val_acc: 0.9243\n",
      "Epoch 119/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3108 - acc: 0.9044 - val_loss: 0.2727 - val_acc: 0.9243\n",
      "Epoch 120/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3102 - acc: 0.9043 - val_loss: 0.2720 - val_acc: 0.9243\n",
      "Epoch 121/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3094 - acc: 0.9044 - val_loss: 0.2713 - val_acc: 0.9243\n",
      "Epoch 122/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3088 - acc: 0.9043 - val_loss: 0.2706 - val_acc: 0.9243\n",
      "Epoch 123/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3087 - acc: 0.9042 - val_loss: 0.2699 - val_acc: 0.9243\n",
      "Epoch 124/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3080 - acc: 0.9042 - val_loss: 0.2692 - val_acc: 0.9243\n",
      "Epoch 125/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3074 - acc: 0.9044 - val_loss: 0.2686 - val_acc: 0.9243\n",
      "Epoch 126/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3067 - acc: 0.9043 - val_loss: 0.2679 - val_acc: 0.9243\n",
      "Epoch 127/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3064 - acc: 0.9043 - val_loss: 0.2673 - val_acc: 0.9243\n",
      "Epoch 128/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3058 - acc: 0.9044 - val_loss: 0.2666 - val_acc: 0.9243\n",
      "Epoch 129/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3052 - acc: 0.9043 - val_loss: 0.2660 - val_acc: 0.9243\n",
      "Epoch 130/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3050 - acc: 0.9042 - val_loss: 0.2654 - val_acc: 0.9243\n",
      "Epoch 131/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3042 - acc: 0.9044 - val_loss: 0.2648 - val_acc: 0.9243\n",
      "Epoch 132/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3037 - acc: 0.9044 - val_loss: 0.2642 - val_acc: 0.9243\n",
      "Epoch 133/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3036 - acc: 0.9043 - val_loss: 0.2637 - val_acc: 0.9243\n",
      "Epoch 134/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3029 - acc: 0.9043 - val_loss: 0.2631 - val_acc: 0.9243\n",
      "Epoch 135/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3027 - acc: 0.9044 - val_loss: 0.2625 - val_acc: 0.9243\n",
      "Epoch 136/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3019 - acc: 0.9043 - val_loss: 0.2620 - val_acc: 0.9243\n",
      "Epoch 137/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3016 - acc: 0.9043 - val_loss: 0.2615 - val_acc: 0.9243\n",
      "Epoch 138/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3012 - acc: 0.9044 - val_loss: 0.2609 - val_acc: 0.9243\n",
      "Epoch 139/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3009 - acc: 0.9043 - val_loss: 0.2604 - val_acc: 0.9243\n",
      "Epoch 140/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3008 - acc: 0.9042 - val_loss: 0.2599 - val_acc: 0.9243\n",
      "Epoch 141/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.3001 - acc: 0.9043 - val_loss: 0.2594 - val_acc: 0.9243\n",
      "Epoch 142/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2996 - acc: 0.9043 - val_loss: 0.2590 - val_acc: 0.9243\n",
      "Epoch 143/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2991 - acc: 0.9044 - val_loss: 0.2585 - val_acc: 0.9243\n",
      "Epoch 144/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2989 - acc: 0.9043 - val_loss: 0.2580 - val_acc: 0.9243\n",
      "Epoch 145/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2986 - acc: 0.9042 - val_loss: 0.2576 - val_acc: 0.9243\n",
      "Epoch 146/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2983 - acc: 0.9043 - val_loss: 0.2571 - val_acc: 0.9243\n",
      "Epoch 147/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2977 - acc: 0.9043 - val_loss: 0.2567 - val_acc: 0.9243\n",
      "Epoch 148/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2975 - acc: 0.9043 - val_loss: 0.2563 - val_acc: 0.9243\n",
      "Epoch 149/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2975 - acc: 0.9043 - val_loss: 0.2558 - val_acc: 0.9243\n",
      "Epoch 150/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2969 - acc: 0.9043 - val_loss: 0.2554 - val_acc: 0.9243\n",
      "Epoch 151/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2969 - acc: 0.9043 - val_loss: 0.2550 - val_acc: 0.9243\n",
      "Epoch 152/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2963 - acc: 0.9044 - val_loss: 0.2546 - val_acc: 0.9243\n",
      "Epoch 153/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2958 - acc: 0.9043 - val_loss: 0.2542 - val_acc: 0.9243\n",
      "Epoch 154/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2956 - acc: 0.9043 - val_loss: 0.2539 - val_acc: 0.9243\n",
      "Epoch 155/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2953 - acc: 0.9043 - val_loss: 0.2535 - val_acc: 0.9243\n",
      "Epoch 156/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2950 - acc: 0.9043 - val_loss: 0.2531 - val_acc: 0.9243\n",
      "Epoch 157/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2950 - acc: 0.9043 - val_loss: 0.2528 - val_acc: 0.9243\n",
      "Epoch 158/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2945 - acc: 0.9044 - val_loss: 0.2524 - val_acc: 0.9243\n",
      "Epoch 159/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2946 - acc: 0.9043 - val_loss: 0.2521 - val_acc: 0.9243\n",
      "Epoch 160/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2942 - acc: 0.9043 - val_loss: 0.2518 - val_acc: 0.9243\n",
      "Epoch 161/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2938 - acc: 0.9043 - val_loss: 0.2514 - val_acc: 0.9243\n",
      "Epoch 162/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2936 - acc: 0.9043 - val_loss: 0.2511 - val_acc: 0.9243\n",
      "Epoch 163/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2933 - acc: 0.9044 - val_loss: 0.2508 - val_acc: 0.9243\n",
      "Epoch 164/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2932 - acc: 0.9044 - val_loss: 0.2505 - val_acc: 0.9243\n",
      "Epoch 165/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2928 - acc: 0.9044 - val_loss: 0.2502 - val_acc: 0.9243\n",
      "Epoch 166/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2926 - acc: 0.9043 - val_loss: 0.2499 - val_acc: 0.9243\n",
      "Epoch 167/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2927 - acc: 0.9043 - val_loss: 0.2496 - val_acc: 0.9243\n",
      "Epoch 168/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2924 - acc: 0.9043 - val_loss: 0.2493 - val_acc: 0.9243\n",
      "Epoch 169/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2922 - acc: 0.9043 - val_loss: 0.2491 - val_acc: 0.9243\n",
      "Epoch 170/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2919 - acc: 0.9043 - val_loss: 0.2488 - val_acc: 0.9243\n",
      "Epoch 171/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2916 - acc: 0.9043 - val_loss: 0.2485 - val_acc: 0.9243\n",
      "Epoch 172/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2913 - acc: 0.9044 - val_loss: 0.2483 - val_acc: 0.9243\n",
      "Epoch 173/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2913 - acc: 0.9043 - val_loss: 0.2480 - val_acc: 0.9243\n",
      "Epoch 174/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2911 - acc: 0.9043 - val_loss: 0.2478 - val_acc: 0.9243\n",
      "Epoch 175/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2911 - acc: 0.9044 - val_loss: 0.2475 - val_acc: 0.9243\n",
      "Epoch 176/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2908 - acc: 0.9043 - val_loss: 0.2473 - val_acc: 0.9243\n",
      "Epoch 177/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2907 - acc: 0.9044 - val_loss: 0.2470 - val_acc: 0.9243\n",
      "Epoch 178/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2904 - acc: 0.9044 - val_loss: 0.2468 - val_acc: 0.9243\n",
      "Epoch 179/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2904 - acc: 0.9043 - val_loss: 0.2466 - val_acc: 0.9243\n",
      "Epoch 180/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2902 - acc: 0.9043 - val_loss: 0.2464 - val_acc: 0.9243\n",
      "Epoch 181/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2898 - acc: 0.9043 - val_loss: 0.2462 - val_acc: 0.9243\n",
      "Epoch 182/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2900 - acc: 0.9043 - val_loss: 0.2459 - val_acc: 0.9243\n",
      "Epoch 183/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2896 - acc: 0.9042 - val_loss: 0.2457 - val_acc: 0.9243\n",
      "Epoch 184/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2896 - acc: 0.9043 - val_loss: 0.2455 - val_acc: 0.9243\n",
      "Epoch 185/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2895 - acc: 0.9043 - val_loss: 0.2454 - val_acc: 0.9243\n",
      "Epoch 186/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2892 - acc: 0.9044 - val_loss: 0.2452 - val_acc: 0.9243\n",
      "Epoch 187/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2891 - acc: 0.9043 - val_loss: 0.2450 - val_acc: 0.9243\n",
      "Epoch 188/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2893 - acc: 0.9043 - val_loss: 0.2448 - val_acc: 0.9243\n",
      "Epoch 189/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2890 - acc: 0.9043 - val_loss: 0.2446 - val_acc: 0.9243\n",
      "Epoch 190/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2884 - acc: 0.9043 - val_loss: 0.2445 - val_acc: 0.9243\n",
      "Epoch 191/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2889 - acc: 0.9044 - val_loss: 0.2443 - val_acc: 0.9243\n",
      "Epoch 192/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2883 - acc: 0.9043 - val_loss: 0.2441 - val_acc: 0.9243\n",
      "Epoch 193/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2886 - acc: 0.9043 - val_loss: 0.2440 - val_acc: 0.9243\n",
      "Epoch 194/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2885 - acc: 0.9044 - val_loss: 0.2438 - val_acc: 0.9243\n",
      "Epoch 195/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2884 - acc: 0.9044 - val_loss: 0.2437 - val_acc: 0.9243\n",
      "Epoch 196/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2883 - acc: 0.9043 - val_loss: 0.2435 - val_acc: 0.9243\n",
      "Epoch 197/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2881 - acc: 0.9043 - val_loss: 0.2434 - val_acc: 0.9243\n",
      "Epoch 198/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2881 - acc: 0.9043 - val_loss: 0.2432 - val_acc: 0.9243\n",
      "Epoch 199/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2879 - acc: 0.9043 - val_loss: 0.2431 - val_acc: 0.9243\n",
      "Epoch 200/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2879 - acc: 0.9044 - val_loss: 0.2429 - val_acc: 0.9243\n",
      "Epoch 201/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2877 - acc: 0.9043 - val_loss: 0.2428 - val_acc: 0.9243\n",
      "Epoch 202/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2877 - acc: 0.9043 - val_loss: 0.2427 - val_acc: 0.9243\n",
      "Epoch 203/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2876 - acc: 0.9044 - val_loss: 0.2426 - val_acc: 0.9243\n",
      "Epoch 204/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2873 - acc: 0.9042 - val_loss: 0.2424 - val_acc: 0.9243\n",
      "Epoch 205/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2874 - acc: 0.9043 - val_loss: 0.2423 - val_acc: 0.9243\n",
      "Epoch 206/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2873 - acc: 0.9043 - val_loss: 0.2422 - val_acc: 0.9243\n",
      "Epoch 207/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2873 - acc: 0.9044 - val_loss: 0.2421 - val_acc: 0.9243\n",
      "Epoch 208/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2869 - acc: 0.9043 - val_loss: 0.2420 - val_acc: 0.9243\n",
      "Epoch 209/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2872 - acc: 0.9044 - val_loss: 0.2419 - val_acc: 0.9243\n",
      "Epoch 210/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2872 - acc: 0.9043 - val_loss: 0.2417 - val_acc: 0.9243\n",
      "Epoch 211/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2870 - acc: 0.9043 - val_loss: 0.2416 - val_acc: 0.9243\n",
      "Epoch 212/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2871 - acc: 0.9043 - val_loss: 0.2415 - val_acc: 0.9243\n",
      "Epoch 213/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2871 - acc: 0.9044 - val_loss: 0.2414 - val_acc: 0.9243\n",
      "Epoch 214/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2867 - acc: 0.9043 - val_loss: 0.2413 - val_acc: 0.9243\n",
      "Epoch 215/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2868 - acc: 0.9044 - val_loss: 0.2412 - val_acc: 0.9243\n",
      "Epoch 216/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2867 - acc: 0.9043 - val_loss: 0.2411 - val_acc: 0.9243\n",
      "Epoch 217/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2866 - acc: 0.9044 - val_loss: 0.2411 - val_acc: 0.9243\n",
      "Epoch 218/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2866 - acc: 0.9044 - val_loss: 0.2410 - val_acc: 0.9243\n",
      "Epoch 219/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2865 - acc: 0.9043 - val_loss: 0.2409 - val_acc: 0.9243\n",
      "Epoch 220/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2865 - acc: 0.9044 - val_loss: 0.2408 - val_acc: 0.9243\n",
      "Epoch 221/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2865 - acc: 0.9044 - val_loss: 0.2407 - val_acc: 0.9243\n",
      "Epoch 222/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2864 - acc: 0.9043 - val_loss: 0.2406 - val_acc: 0.9243\n",
      "Epoch 223/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2864 - acc: 0.9044 - val_loss: 0.2406 - val_acc: 0.9243\n",
      "Epoch 224/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2866 - acc: 0.9043 - val_loss: 0.2405 - val_acc: 0.9243\n",
      "Epoch 225/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2862 - acc: 0.9044 - val_loss: 0.2404 - val_acc: 0.9243\n",
      "Epoch 226/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9044 - val_loss: 0.2403 - val_acc: 0.9243\n",
      "Epoch 227/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9043 - val_loss: 0.2403 - val_acc: 0.9243\n",
      "Epoch 228/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2860 - acc: 0.9043 - val_loss: 0.2402 - val_acc: 0.9243\n",
      "Epoch 229/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9043 - val_loss: 0.2401 - val_acc: 0.9243\n",
      "Epoch 230/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2860 - acc: 0.9043 - val_loss: 0.2401 - val_acc: 0.9243\n",
      "Epoch 231/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2860 - acc: 0.9044 - val_loss: 0.2400 - val_acc: 0.9243\n",
      "Epoch 232/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9043 - val_loss: 0.2400 - val_acc: 0.9243\n",
      "Epoch 233/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2859 - acc: 0.9044 - val_loss: 0.2399 - val_acc: 0.9243\n",
      "Epoch 234/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2857 - acc: 0.9044 - val_loss: 0.2398 - val_acc: 0.9243\n",
      "Epoch 235/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2861 - acc: 0.9044 - val_loss: 0.2398 - val_acc: 0.9243\n",
      "Epoch 236/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2860 - acc: 0.9043 - val_loss: 0.2397 - val_acc: 0.9243\n",
      "Epoch 237/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2860 - acc: 0.9043 - val_loss: 0.2397 - val_acc: 0.9243\n",
      "Epoch 238/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2857 - acc: 0.9043 - val_loss: 0.2396 - val_acc: 0.9243\n",
      "Epoch 239/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2859 - acc: 0.9043 - val_loss: 0.2396 - val_acc: 0.9243\n",
      "Epoch 240/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2858 - acc: 0.9044 - val_loss: 0.2395 - val_acc: 0.9243\n",
      "Epoch 241/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2859 - acc: 0.9044 - val_loss: 0.2395 - val_acc: 0.9243\n",
      "Epoch 242/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2859 - acc: 0.9043 - val_loss: 0.2394 - val_acc: 0.9243\n",
      "Epoch 243/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2856 - acc: 0.9043 - val_loss: 0.2394 - val_acc: 0.9243\n",
      "Epoch 244/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9044 - val_loss: 0.2394 - val_acc: 0.9243\n",
      "Epoch 245/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9044 - val_loss: 0.2393 - val_acc: 0.9243\n",
      "Epoch 246/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2393 - val_acc: 0.9243\n",
      "Epoch 247/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2857 - acc: 0.9043 - val_loss: 0.2392 - val_acc: 0.9243\n",
      "Epoch 248/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2392 - val_acc: 0.9243\n",
      "Epoch 249/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2856 - acc: 0.9043 - val_loss: 0.2391 - val_acc: 0.9243\n",
      "Epoch 250/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9044 - val_loss: 0.2391 - val_acc: 0.9243\n",
      "Epoch 251/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9044 - val_loss: 0.2391 - val_acc: 0.9243\n",
      "Epoch 252/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9044 - val_loss: 0.2390 - val_acc: 0.9243\n",
      "Epoch 253/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2390 - val_acc: 0.9243\n",
      "Epoch 254/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2854 - acc: 0.9042 - val_loss: 0.2390 - val_acc: 0.9243\n",
      "Epoch 255/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9044 - val_loss: 0.2389 - val_acc: 0.9243\n",
      "Epoch 256/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2389 - val_acc: 0.9243\n",
      "Epoch 257/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2389 - val_acc: 0.9243\n",
      "Epoch 258/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2854 - acc: 0.9044 - val_loss: 0.2389 - val_acc: 0.9243\n",
      "Epoch 259/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2388 - val_acc: 0.9243\n",
      "Epoch 260/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9044 - val_loss: 0.2388 - val_acc: 0.9243\n",
      "Epoch 261/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2854 - acc: 0.9044 - val_loss: 0.2388 - val_acc: 0.9243\n",
      "Epoch 262/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2387 - val_acc: 0.9243\n",
      "Epoch 263/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2854 - acc: 0.9044 - val_loss: 0.2387 - val_acc: 0.9243\n",
      "Epoch 264/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9043 - val_loss: 0.2387 - val_acc: 0.9243\n",
      "Epoch 265/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2854 - acc: 0.9044 - val_loss: 0.2387 - val_acc: 0.9243\n",
      "Epoch 266/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2387 - val_acc: 0.9243\n",
      "Epoch 267/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2386 - val_acc: 0.9243\n",
      "Epoch 268/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2386 - val_acc: 0.9243\n",
      "Epoch 269/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2386 - val_acc: 0.9243\n",
      "Epoch 270/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9044 - val_loss: 0.2386 - val_acc: 0.9243\n",
      "Epoch 271/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2386 - val_acc: 0.9243\n",
      "Epoch 272/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2385 - val_acc: 0.9243\n",
      "Epoch 273/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2385 - val_acc: 0.9243\n",
      "Epoch 274/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2385 - val_acc: 0.9243\n",
      "Epoch 275/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2385 - val_acc: 0.9243\n",
      "Epoch 276/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2855 - acc: 0.9043 - val_loss: 0.2385 - val_acc: 0.9243\n",
      "Epoch 277/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 278/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 279/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 280/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 281/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 282/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 283/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2384 - val_acc: 0.9243\n",
      "Epoch 284/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 285/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 286/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 287/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 288/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 289/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 290/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2383 - val_acc: 0.9243\n",
      "Epoch 291/500\n",
      "5579/5579 [==============================] - 11s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 292/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 293/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2853 - acc: 0.9044 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 294/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 295/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 296/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 297/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 298/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 299/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 300/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 301/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 302/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 303/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 304/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 305/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 306/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 307/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 308/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2846 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 309/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 310/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 311/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 312/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 313/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 314/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 315/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2381 - val_acc: 0.9243\n",
      "Epoch 316/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 317/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 318/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 319/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 320/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 321/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 322/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 323/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 324/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 325/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 326/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 327/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 328/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 329/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2852 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 330/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 331/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9045 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 332/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 333/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 334/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9045 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 335/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 336/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 337/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 338/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 339/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 340/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 341/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 342/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2380 - val_acc: 0.9243\n",
      "Epoch 343/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 344/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 345/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 346/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9045 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 347/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 348/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 349/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 350/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 351/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 352/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 353/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 354/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 355/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2846 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 356/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 357/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 358/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 359/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 360/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 361/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 362/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 363/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 364/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 365/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 366/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 367/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2846 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 368/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9042 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 369/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 370/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 371/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 372/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 373/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 374/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2847 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 375/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 376/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 377/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2850 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 378/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 379/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2846 - acc: 0.9043 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 380/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2849 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 381/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 382/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2848 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "Epoch 383/500\n",
      "5579/5579 [==============================] - 10s 2ms/step - loss: 0.2851 - acc: 0.9044 - val_loss: 0.2379 - val_acc: 0.9243\n",
      "[18:43:15] train_log_loss:0.2780358832297862 test_log_loss:0.2551246914408546\n",
      "[18:43:15] train_acc:0.9065266937181762 test_acc:0.9165454530410968\n",
      "\n",
      "---------- split 2 ----------\n",
      "[18:43:15] train_index:0~9299 test_index:9300~12399\n",
      "Train on 8369 samples, validate on 930 samples\n",
      "Epoch 1/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.6819 - acc: 0.5599 - val_loss: 0.6564 - val_acc: 0.6379\n",
      "Epoch 2/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.6443 - acc: 0.6447 - val_loss: 0.6281 - val_acc: 0.6868\n",
      "Epoch 3/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.6206 - acc: 0.6952 - val_loss: 0.6073 - val_acc: 0.7458\n",
      "Epoch 4/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.6018 - acc: 0.7318 - val_loss: 0.5903 - val_acc: 0.7776\n",
      "Epoch 5/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5862 - acc: 0.7600 - val_loss: 0.5758 - val_acc: 0.7846\n",
      "Epoch 6/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5731 - acc: 0.7820 - val_loss: 0.5630 - val_acc: 0.7972\n",
      "Epoch 7/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5606 - acc: 0.8009 - val_loss: 0.5514 - val_acc: 0.8318\n",
      "Epoch 8/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5499 - acc: 0.8162 - val_loss: 0.5408 - val_acc: 0.8407\n",
      "Epoch 9/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5399 - acc: 0.8285 - val_loss: 0.5311 - val_acc: 0.8541\n",
      "Epoch 10/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5304 - acc: 0.8401 - val_loss: 0.5220 - val_acc: 0.8587\n",
      "Epoch 11/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5220 - acc: 0.8496 - val_loss: 0.5136 - val_acc: 0.8634\n",
      "Epoch 12/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5140 - acc: 0.8580 - val_loss: 0.5056 - val_acc: 0.8773\n",
      "Epoch 13/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.5060 - acc: 0.8654 - val_loss: 0.4981 - val_acc: 0.8819\n",
      "Epoch 14/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4988 - acc: 0.8718 - val_loss: 0.4909 - val_acc: 0.8915\n",
      "Epoch 15/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4917 - acc: 0.8776 - val_loss: 0.4841 - val_acc: 0.8915\n",
      "Epoch 16/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4854 - acc: 0.8822 - val_loss: 0.4776 - val_acc: 0.8980\n",
      "Epoch 17/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4790 - acc: 0.8864 - val_loss: 0.4713 - val_acc: 0.8980\n",
      "Epoch 18/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4732 - acc: 0.8900 - val_loss: 0.4654 - val_acc: 0.9043\n",
      "Epoch 19/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4673 - acc: 0.8931 - val_loss: 0.4596 - val_acc: 0.9043\n",
      "Epoch 20/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4617 - acc: 0.8959 - val_loss: 0.4541 - val_acc: 0.9043\n",
      "Epoch 21/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4567 - acc: 0.8983 - val_loss: 0.4488 - val_acc: 0.9091\n",
      "Epoch 22/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4511 - acc: 0.9003 - val_loss: 0.4437 - val_acc: 0.9139\n",
      "Epoch 23/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4465 - acc: 0.9020 - val_loss: 0.4387 - val_acc: 0.9139\n",
      "Epoch 24/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4417 - acc: 0.9034 - val_loss: 0.4340 - val_acc: 0.9139\n",
      "Epoch 25/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4368 - acc: 0.9048 - val_loss: 0.4293 - val_acc: 0.9139\n",
      "Epoch 26/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4324 - acc: 0.9057 - val_loss: 0.4248 - val_acc: 0.9139\n",
      "Epoch 27/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4282 - acc: 0.9065 - val_loss: 0.4205 - val_acc: 0.9139\n",
      "Epoch 28/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4239 - acc: 0.9071 - val_loss: 0.4163 - val_acc: 0.9139\n",
      "Epoch 29/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4200 - acc: 0.9076 - val_loss: 0.4122 - val_acc: 0.9139\n",
      "Epoch 30/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4159 - acc: 0.9080 - val_loss: 0.4082 - val_acc: 0.9139\n",
      "Epoch 31/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4121 - acc: 0.9083 - val_loss: 0.4044 - val_acc: 0.9139\n",
      "Epoch 32/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4082 - acc: 0.9086 - val_loss: 0.4006 - val_acc: 0.9139\n",
      "Epoch 33/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4043 - acc: 0.9088 - val_loss: 0.3970 - val_acc: 0.9139\n",
      "Epoch 34/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.4010 - acc: 0.9089 - val_loss: 0.3934 - val_acc: 0.9139\n",
      "Epoch 35/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3977 - acc: 0.9090 - val_loss: 0.3900 - val_acc: 0.9139\n",
      "Epoch 36/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3940 - acc: 0.9091 - val_loss: 0.3866 - val_acc: 0.9139\n",
      "Epoch 37/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3914 - acc: 0.9093 - val_loss: 0.3834 - val_acc: 0.9139\n",
      "Epoch 38/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3881 - acc: 0.9092 - val_loss: 0.3802 - val_acc: 0.9139\n",
      "Epoch 39/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3848 - acc: 0.9092 - val_loss: 0.3771 - val_acc: 0.9139\n",
      "Epoch 40/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3819 - acc: 0.9094 - val_loss: 0.3741 - val_acc: 0.9139\n",
      "Epoch 41/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3789 - acc: 0.9092 - val_loss: 0.3711 - val_acc: 0.9139\n",
      "Epoch 42/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3761 - acc: 0.9093 - val_loss: 0.3682 - val_acc: 0.9139\n",
      "Epoch 43/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3731 - acc: 0.9093 - val_loss: 0.3654 - val_acc: 0.9139\n",
      "Epoch 44/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3707 - acc: 0.9095 - val_loss: 0.3627 - val_acc: 0.9139\n",
      "Epoch 45/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3674 - acc: 0.9095 - val_loss: 0.3601 - val_acc: 0.9139\n",
      "Epoch 46/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3655 - acc: 0.9095 - val_loss: 0.3575 - val_acc: 0.9139\n",
      "Epoch 47/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3628 - acc: 0.9094 - val_loss: 0.3549 - val_acc: 0.9139\n",
      "Epoch 48/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3604 - acc: 0.9094 - val_loss: 0.3525 - val_acc: 0.9139\n",
      "Epoch 49/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3579 - acc: 0.9094 - val_loss: 0.3501 - val_acc: 0.9139\n",
      "Epoch 50/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3557 - acc: 0.9094 - val_loss: 0.3477 - val_acc: 0.9139\n",
      "Epoch 51/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3532 - acc: 0.9095 - val_loss: 0.3454 - val_acc: 0.9139\n",
      "Epoch 52/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3513 - acc: 0.9095 - val_loss: 0.3432 - val_acc: 0.9139\n",
      "Epoch 53/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3493 - acc: 0.9095 - val_loss: 0.3410 - val_acc: 0.9139\n",
      "Epoch 54/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3468 - acc: 0.9095 - val_loss: 0.3389 - val_acc: 0.9139\n",
      "Epoch 55/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3447 - acc: 0.9095 - val_loss: 0.3368 - val_acc: 0.9139\n",
      "Epoch 56/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3427 - acc: 0.9094 - val_loss: 0.3348 - val_acc: 0.9139\n",
      "Epoch 57/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3408 - acc: 0.9094 - val_loss: 0.3328 - val_acc: 0.9139\n",
      "Epoch 58/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3389 - acc: 0.9095 - val_loss: 0.3309 - val_acc: 0.9139\n",
      "Epoch 59/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.3371 - acc: 0.9095 - val_loss: 0.3290 - val_acc: 0.9139\n",
      "Epoch 60/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.3355 - acc: 0.9095 - val_loss: 0.3272 - val_acc: 0.9139\n",
      "Epoch 61/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3334 - acc: 0.9095 - val_loss: 0.3254 - val_acc: 0.9139\n",
      "Epoch 62/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3319 - acc: 0.9094 - val_loss: 0.3237 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3300 - acc: 0.9094 - val_loss: 0.3220 - val_acc: 0.9139\n",
      "Epoch 64/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3286 - acc: 0.9094 - val_loss: 0.3203 - val_acc: 0.9139\n",
      "Epoch 65/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3267 - acc: 0.9094 - val_loss: 0.3187 - val_acc: 0.9139\n",
      "Epoch 66/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3255 - acc: 0.9095 - val_loss: 0.3171 - val_acc: 0.9139\n",
      "Epoch 67/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3239 - acc: 0.9095 - val_loss: 0.3156 - val_acc: 0.9139\n",
      "Epoch 68/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3224 - acc: 0.9094 - val_loss: 0.3141 - val_acc: 0.9139\n",
      "Epoch 69/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3208 - acc: 0.9095 - val_loss: 0.3126 - val_acc: 0.9139\n",
      "Epoch 70/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3198 - acc: 0.9095 - val_loss: 0.3112 - val_acc: 0.9139\n",
      "Epoch 71/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.3183 - acc: 0.9095 - val_loss: 0.3098 - val_acc: 0.9139\n",
      "Epoch 72/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3169 - acc: 0.9095 - val_loss: 0.3084 - val_acc: 0.9139\n",
      "Epoch 73/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3157 - acc: 0.9095 - val_loss: 0.3071 - val_acc: 0.9139\n",
      "Epoch 74/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3143 - acc: 0.9095 - val_loss: 0.3058 - val_acc: 0.9139\n",
      "Epoch 75/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3131 - acc: 0.9094 - val_loss: 0.3046 - val_acc: 0.9139\n",
      "Epoch 76/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3119 - acc: 0.9094 - val_loss: 0.3033 - val_acc: 0.9139\n",
      "Epoch 77/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3107 - acc: 0.9095 - val_loss: 0.3021 - val_acc: 0.9139\n",
      "Epoch 78/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3095 - acc: 0.9095 - val_loss: 0.3010 - val_acc: 0.9139\n",
      "Epoch 79/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3083 - acc: 0.9095 - val_loss: 0.2998 - val_acc: 0.9139\n",
      "Epoch 80/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3071 - acc: 0.9095 - val_loss: 0.2987 - val_acc: 0.9139\n",
      "Epoch 81/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3061 - acc: 0.9095 - val_loss: 0.2977 - val_acc: 0.9139\n",
      "Epoch 82/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3053 - acc: 0.9095 - val_loss: 0.2966 - val_acc: 0.9139\n",
      "Epoch 83/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3041 - acc: 0.9094 - val_loss: 0.2956 - val_acc: 0.9139\n",
      "Epoch 84/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3033 - acc: 0.9095 - val_loss: 0.2946 - val_acc: 0.9139\n",
      "Epoch 85/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3024 - acc: 0.9094 - val_loss: 0.2937 - val_acc: 0.9139\n",
      "Epoch 86/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3013 - acc: 0.9095 - val_loss: 0.2927 - val_acc: 0.9139\n",
      "Epoch 87/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.3007 - acc: 0.9095 - val_loss: 0.2918 - val_acc: 0.9139\n",
      "Epoch 88/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2997 - acc: 0.9095 - val_loss: 0.2909 - val_acc: 0.9139\n",
      "Epoch 89/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2985 - acc: 0.9094 - val_loss: 0.2900 - val_acc: 0.9139\n",
      "Epoch 90/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2979 - acc: 0.9094 - val_loss: 0.2892 - val_acc: 0.9139\n",
      "Epoch 91/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2973 - acc: 0.9094 - val_loss: 0.2884 - val_acc: 0.9139\n",
      "Epoch 92/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2963 - acc: 0.9095 - val_loss: 0.2876 - val_acc: 0.9139\n",
      "Epoch 93/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2956 - acc: 0.9094 - val_loss: 0.2868 - val_acc: 0.9139\n",
      "Epoch 94/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2947 - acc: 0.9094 - val_loss: 0.2861 - val_acc: 0.9139\n",
      "Epoch 95/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2942 - acc: 0.9094 - val_loss: 0.2853 - val_acc: 0.9139\n",
      "Epoch 96/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2935 - acc: 0.9094 - val_loss: 0.2846 - val_acc: 0.9139\n",
      "Epoch 97/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2928 - acc: 0.9095 - val_loss: 0.2839 - val_acc: 0.9139\n",
      "Epoch 98/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2922 - acc: 0.9095 - val_loss: 0.2832 - val_acc: 0.9139\n",
      "Epoch 99/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2914 - acc: 0.9095 - val_loss: 0.2826 - val_acc: 0.9139\n",
      "Epoch 100/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2910 - acc: 0.9095 - val_loss: 0.2819 - val_acc: 0.9139\n",
      "Epoch 101/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2907 - acc: 0.9095 - val_loss: 0.2813 - val_acc: 0.9139\n",
      "Epoch 102/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2897 - acc: 0.9094 - val_loss: 0.2807 - val_acc: 0.9139\n",
      "Epoch 103/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2892 - acc: 0.9095 - val_loss: 0.2801 - val_acc: 0.9139\n",
      "Epoch 104/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2886 - acc: 0.9095 - val_loss: 0.2796 - val_acc: 0.9139\n",
      "Epoch 105/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2880 - acc: 0.9095 - val_loss: 0.2790 - val_acc: 0.9139\n",
      "Epoch 106/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2874 - acc: 0.9094 - val_loss: 0.2785 - val_acc: 0.9139\n",
      "Epoch 107/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2871 - acc: 0.9096 - val_loss: 0.2780 - val_acc: 0.9139\n",
      "Epoch 108/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2867 - acc: 0.9095 - val_loss: 0.2774 - val_acc: 0.9139\n",
      "Epoch 109/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2861 - acc: 0.9094 - val_loss: 0.2770 - val_acc: 0.9139\n",
      "Epoch 110/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2859 - acc: 0.9095 - val_loss: 0.2765 - val_acc: 0.9139\n",
      "Epoch 111/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2853 - acc: 0.9095 - val_loss: 0.2760 - val_acc: 0.9139\n",
      "Epoch 112/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2846 - acc: 0.9093 - val_loss: 0.2756 - val_acc: 0.9139\n",
      "Epoch 113/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2844 - acc: 0.9094 - val_loss: 0.2751 - val_acc: 0.9139\n",
      "Epoch 114/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2837 - acc: 0.9095 - val_loss: 0.2747 - val_acc: 0.9139\n",
      "Epoch 115/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2835 - acc: 0.9095 - val_loss: 0.2743 - val_acc: 0.9139\n",
      "Epoch 116/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2832 - acc: 0.9095 - val_loss: 0.2739 - val_acc: 0.9139\n",
      "Epoch 117/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2829 - acc: 0.9095 - val_loss: 0.2735 - val_acc: 0.9139\n",
      "Epoch 118/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2822 - acc: 0.9095 - val_loss: 0.2732 - val_acc: 0.9139\n",
      "Epoch 119/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2823 - acc: 0.9095 - val_loss: 0.2728 - val_acc: 0.9139\n",
      "Epoch 120/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2818 - acc: 0.9095 - val_loss: 0.2725 - val_acc: 0.9139\n",
      "Epoch 121/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2814 - acc: 0.9095 - val_loss: 0.2721 - val_acc: 0.9139\n",
      "Epoch 122/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2813 - acc: 0.9095 - val_loss: 0.2718 - val_acc: 0.9139\n",
      "Epoch 123/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2809 - acc: 0.9095 - val_loss: 0.2715 - val_acc: 0.9139\n",
      "Epoch 124/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2804 - acc: 0.9095 - val_loss: 0.2712 - val_acc: 0.9139\n",
      "Epoch 125/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2803 - acc: 0.9095 - val_loss: 0.2709 - val_acc: 0.9139\n",
      "Epoch 126/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2801 - acc: 0.9095 - val_loss: 0.2706 - val_acc: 0.9139\n",
      "Epoch 127/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2797 - acc: 0.9095 - val_loss: 0.2703 - val_acc: 0.9139\n",
      "Epoch 128/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2796 - acc: 0.9095 - val_loss: 0.2700 - val_acc: 0.9139\n",
      "Epoch 129/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2791 - acc: 0.9095 - val_loss: 0.2698 - val_acc: 0.9139\n",
      "Epoch 130/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2791 - acc: 0.9095 - val_loss: 0.2695 - val_acc: 0.9139\n",
      "Epoch 131/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2788 - acc: 0.9094 - val_loss: 0.2693 - val_acc: 0.9139\n",
      "Epoch 132/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2786 - acc: 0.9095 - val_loss: 0.2690 - val_acc: 0.9139\n",
      "Epoch 133/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2783 - acc: 0.9094 - val_loss: 0.2688 - val_acc: 0.9139\n",
      "Epoch 134/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2781 - acc: 0.9094 - val_loss: 0.2686 - val_acc: 0.9139\n",
      "Epoch 135/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2780 - acc: 0.9095 - val_loss: 0.2684 - val_acc: 0.9139\n",
      "Epoch 136/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2779 - acc: 0.9094 - val_loss: 0.2682 - val_acc: 0.9139\n",
      "Epoch 137/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2776 - acc: 0.9095 - val_loss: 0.2680 - val_acc: 0.9139\n",
      "Epoch 138/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2774 - acc: 0.9095 - val_loss: 0.2678 - val_acc: 0.9139\n",
      "Epoch 139/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2773 - acc: 0.9094 - val_loss: 0.2676 - val_acc: 0.9139\n",
      "Epoch 140/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2771 - acc: 0.9095 - val_loss: 0.2674 - val_acc: 0.9139\n",
      "Epoch 141/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2768 - acc: 0.9095 - val_loss: 0.2672 - val_acc: 0.9139\n",
      "Epoch 142/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2768 - acc: 0.9094 - val_loss: 0.2671 - val_acc: 0.9139\n",
      "Epoch 143/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2766 - acc: 0.9095 - val_loss: 0.2669 - val_acc: 0.9139\n",
      "Epoch 144/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2765 - acc: 0.9094 - val_loss: 0.2668 - val_acc: 0.9139\n",
      "Epoch 145/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2764 - acc: 0.9094 - val_loss: 0.2666 - val_acc: 0.9139\n",
      "Epoch 146/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2761 - acc: 0.9095 - val_loss: 0.2665 - val_acc: 0.9139\n",
      "Epoch 147/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2762 - acc: 0.9095 - val_loss: 0.2663 - val_acc: 0.9139\n",
      "Epoch 148/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2759 - acc: 0.9094 - val_loss: 0.2662 - val_acc: 0.9139\n",
      "Epoch 149/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2757 - acc: 0.9095 - val_loss: 0.2661 - val_acc: 0.9139\n",
      "Epoch 150/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2756 - acc: 0.9095 - val_loss: 0.2659 - val_acc: 0.9139\n",
      "Epoch 151/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2755 - acc: 0.9095 - val_loss: 0.2658 - val_acc: 0.9139\n",
      "Epoch 152/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2755 - acc: 0.9095 - val_loss: 0.2657 - val_acc: 0.9139\n",
      "Epoch 153/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2754 - acc: 0.9094 - val_loss: 0.2656 - val_acc: 0.9139\n",
      "Epoch 154/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2753 - acc: 0.9095 - val_loss: 0.2655 - val_acc: 0.9139\n",
      "Epoch 155/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2753 - acc: 0.9095 - val_loss: 0.2654 - val_acc: 0.9139\n",
      "Epoch 156/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2753 - acc: 0.9095 - val_loss: 0.2653 - val_acc: 0.9139\n",
      "Epoch 157/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2749 - acc: 0.9095 - val_loss: 0.2652 - val_acc: 0.9139\n",
      "Epoch 158/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2750 - acc: 0.9095 - val_loss: 0.2651 - val_acc: 0.9139\n",
      "Epoch 159/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2748 - acc: 0.9094 - val_loss: 0.2650 - val_acc: 0.9139\n",
      "Epoch 160/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2748 - acc: 0.9095 - val_loss: 0.2649 - val_acc: 0.9139\n",
      "Epoch 161/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2747 - acc: 0.9094 - val_loss: 0.2648 - val_acc: 0.9139\n",
      "Epoch 162/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2747 - acc: 0.9095 - val_loss: 0.2648 - val_acc: 0.9139\n",
      "Epoch 163/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2746 - acc: 0.9095 - val_loss: 0.2647 - val_acc: 0.9139\n",
      "Epoch 164/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2745 - acc: 0.9094 - val_loss: 0.2646 - val_acc: 0.9139\n",
      "Epoch 165/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2743 - acc: 0.9095 - val_loss: 0.2645 - val_acc: 0.9139\n",
      "Epoch 166/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2743 - acc: 0.9095 - val_loss: 0.2645 - val_acc: 0.9139\n",
      "Epoch 167/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2743 - acc: 0.9094 - val_loss: 0.2644 - val_acc: 0.9139\n",
      "Epoch 168/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2743 - acc: 0.9095 - val_loss: 0.2644 - val_acc: 0.9139\n",
      "Epoch 169/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2742 - acc: 0.9095 - val_loss: 0.2643 - val_acc: 0.9139\n",
      "Epoch 170/500\n",
      "8369/8369 [==============================] - 14s 2ms/step - loss: 0.2743 - acc: 0.9095 - val_loss: 0.2642 - val_acc: 0.9139\n",
      "Epoch 171/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2740 - acc: 0.9095 - val_loss: 0.2642 - val_acc: 0.9139\n",
      "Epoch 172/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2741 - acc: 0.9095 - val_loss: 0.2641 - val_acc: 0.9139\n",
      "Epoch 173/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2740 - acc: 0.9095 - val_loss: 0.2641 - val_acc: 0.9139\n",
      "Epoch 174/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2740 - acc: 0.9095 - val_loss: 0.2640 - val_acc: 0.9139\n",
      "Epoch 175/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2740 - acc: 0.9094 - val_loss: 0.2640 - val_acc: 0.9139\n",
      "Epoch 176/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2740 - acc: 0.9095 - val_loss: 0.2639 - val_acc: 0.9139\n",
      "Epoch 177/500\n",
      "8369/8369 [==============================] - 21s 2ms/step - loss: 0.2741 - acc: 0.9095 - val_loss: 0.2639 - val_acc: 0.9139\n",
      "Epoch 178/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2738 - acc: 0.9095 - val_loss: 0.2639 - val_acc: 0.9139\n",
      "Epoch 179/500\n",
      "8369/8369 [==============================] - 23s 3ms/step - loss: 0.2739 - acc: 0.9095 - val_loss: 0.2638 - val_acc: 0.9139\n",
      "Epoch 180/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2738 - acc: 0.9095 - val_loss: 0.2638 - val_acc: 0.9139\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2739 - acc: 0.9095 - val_loss: 0.2637 - val_acc: 0.9139\n",
      "Epoch 182/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2637 - val_acc: 0.9139\n",
      "Epoch 183/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2637 - val_acc: 0.9139\n",
      "Epoch 184/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2738 - acc: 0.9095 - val_loss: 0.2636 - val_acc: 0.9139\n",
      "Epoch 185/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2636 - val_acc: 0.9139\n",
      "Epoch 186/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2738 - acc: 0.9095 - val_loss: 0.2636 - val_acc: 0.9139\n",
      "Epoch 187/500\n",
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2636 - val_acc: 0.9139\n",
      "Epoch 188/500\n",
      "8369/8369 [==============================] - 24s 3ms/step - loss: 0.2736 - acc: 0.9095 - val_loss: 0.2635 - val_acc: 0.9139\n",
      "Epoch 189/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2735 - acc: 0.9094 - val_loss: 0.2635 - val_acc: 0.9139\n",
      "Epoch 190/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9095 - val_loss: 0.2635 - val_acc: 0.9139\n",
      "Epoch 191/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2735 - acc: 0.9095 - val_loss: 0.2635 - val_acc: 0.9139\n",
      "Epoch 192/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2736 - acc: 0.9095 - val_loss: 0.2634 - val_acc: 0.9139\n",
      "Epoch 193/500\n",
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2735 - acc: 0.9095 - val_loss: 0.2634 - val_acc: 0.9139\n",
      "Epoch 194/500\n",
      "8369/8369 [==============================] - 21s 2ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2634 - val_acc: 0.9139\n",
      "Epoch 195/500\n",
      "8369/8369 [==============================] - 33s 4ms/step - loss: 0.2734 - acc: 0.9095 - val_loss: 0.2634 - val_acc: 0.9139\n",
      "Epoch 196/500\n",
      "8369/8369 [==============================] - 47s 6ms/step - loss: 0.2734 - acc: 0.9095 - val_loss: 0.2634 - val_acc: 0.9139\n",
      "Epoch 197/500\n",
      "8369/8369 [==============================] - 28s 3ms/step - loss: 0.2735 - acc: 0.9095 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 198/500\n",
      "8369/8369 [==============================] - 23s 3ms/step - loss: 0.2733 - acc: 0.9094 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 199/500\n",
      "8369/8369 [==============================] - 21s 2ms/step - loss: 0.2734 - acc: 0.9094 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 200/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9094 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 201/500\n",
      "8369/8369 [==============================] - 23s 3ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 202/500\n",
      "8369/8369 [==============================] - 23s 3ms/step - loss: 0.2735 - acc: 0.9095 - val_loss: 0.2633 - val_acc: 0.9139\n",
      "Epoch 203/500\n",
      "8369/8369 [==============================] - 25s 3ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 204/500\n",
      "8369/8369 [==============================] - 21s 3ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 205/500\n",
      "8369/8369 [==============================] - 27s 3ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 206/500\n",
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2735 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 207/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 208/500\n",
      "8369/8369 [==============================] - 27s 3ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 209/500\n",
      "8369/8369 [==============================] - 32s 4ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 210/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2632 - val_acc: 0.9139\n",
      "Epoch 211/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 212/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 213/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 214/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 215/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 216/500\n",
      "8369/8369 [==============================] - 25s 3ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 217/500\n",
      "8369/8369 [==============================] - 27s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 218/500\n",
      "8369/8369 [==============================] - 25s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 219/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 220/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 221/500\n",
      "8369/8369 [==============================] - 26s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 222/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 223/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2730 - acc: 0.9094 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 224/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 225/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2631 - val_acc: 0.9139\n",
      "Epoch 226/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 227/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 228/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 229/500\n",
      "8369/8369 [==============================] - 31s 4ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 230/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 231/500\n",
      "8369/8369 [==============================] - 28s 3ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 232/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 233/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 234/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 235/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 236/500\n",
      "8369/8369 [==============================] - 22s 3ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 237/500\n",
      "8369/8369 [==============================] - 25s 3ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 238/500\n",
      "8369/8369 [==============================] - 24s 3ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 239/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 240/500\n",
      "8369/8369 [==============================] - 21s 3ms/step - loss: 0.2731 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 241/500\n",
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 242/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 243/500\n",
      "8369/8369 [==============================] - 34s 4ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 244/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 245/500\n",
      "8369/8369 [==============================] - 18s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 246/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 247/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 248/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 249/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 250/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 251/500\n",
      "8369/8369 [==============================] - 21s 3ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 252/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 253/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 254/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 255/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 256/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 257/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 258/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 259/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 260/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 261/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2729 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 262/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 263/500\n",
      "8369/8369 [==============================] - 20s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 264/500\n",
      "8369/8369 [==============================] - 21s 3ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 265/500\n",
      "8369/8369 [==============================] - 19s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 266/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 267/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2733 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 268/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 269/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 270/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 271/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 272/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 273/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 274/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 275/500\n",
      "8369/8369 [==============================] - 15s 2ms/step - loss: 0.2731 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 276/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 277/500\n",
      "8369/8369 [==============================] - 16s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 278/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 279/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2729 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 280/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 281/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 282/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 283/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "Epoch 284/500\n",
      "8369/8369 [==============================] - 17s 2ms/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9139\n",
      "[20:01:58] train_log_loss:0.2701041976917868 test_log_loss:0.2693693980625358\n",
      "[20:01:58] train_acc:0.9100559475653571 test_acc:0.9104343005601476\n",
      "\n",
      "---------- split 3 ----------\n",
      "[20:01:58] train_index:0~12399 test_index:12400~15499\n",
      "Train on 11159 samples, validate on 1240 samples\n",
      "Epoch 1/500\n",
      "11159/11159 [==============================] - 31s 3ms/step - loss: 0.6774 - acc: 0.5813 - val_loss: 0.6520 - val_acc: 0.6558\n",
      "Epoch 2/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.6410 - acc: 0.6670 - val_loss: 0.6248 - val_acc: 0.7103\n",
      "Epoch 3/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.6180 - acc: 0.7166 - val_loss: 0.6047 - val_acc: 0.7497\n",
      "Epoch 4/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5999 - acc: 0.7538 - val_loss: 0.5881 - val_acc: 0.7926\n",
      "Epoch 5/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5849 - acc: 0.7812 - val_loss: 0.5738 - val_acc: 0.8194\n",
      "Epoch 6/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5716 - acc: 0.8031 - val_loss: 0.5611 - val_acc: 0.8374\n",
      "Epoch 7/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5597 - acc: 0.8198 - val_loss: 0.5496 - val_acc: 0.8466\n",
      "Epoch 8/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5489 - acc: 0.8339 - val_loss: 0.5391 - val_acc: 0.8603\n",
      "Epoch 9/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5390 - acc: 0.8456 - val_loss: 0.5293 - val_acc: 0.8692\n",
      "Epoch 10/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5295 - acc: 0.8552 - val_loss: 0.5202 - val_acc: 0.8788\n",
      "Epoch 11/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5207 - acc: 0.8629 - val_loss: 0.5116 - val_acc: 0.8834\n",
      "Epoch 12/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.5124 - acc: 0.8695 - val_loss: 0.5034 - val_acc: 0.8834\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.5044 - acc: 0.8747 - val_loss: 0.4957 - val_acc: 0.8834\n",
      "Epoch 14/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4970 - acc: 0.8797 - val_loss: 0.4884 - val_acc: 0.8834\n",
      "Epoch 15/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4902 - acc: 0.8838 - val_loss: 0.4814 - val_acc: 0.8881\n",
      "Epoch 16/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4835 - acc: 0.8879 - val_loss: 0.4746 - val_acc: 0.8928\n",
      "Epoch 17/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4768 - acc: 0.8915 - val_loss: 0.4682 - val_acc: 0.9064\n",
      "Epoch 18/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4707 - acc: 0.8947 - val_loss: 0.4620 - val_acc: 0.9102\n",
      "Epoch 19/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4647 - acc: 0.8974 - val_loss: 0.4560 - val_acc: 0.9102\n",
      "Epoch 20/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4590 - acc: 0.8998 - val_loss: 0.4502 - val_acc: 0.9102\n",
      "Epoch 21/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4531 - acc: 0.9017 - val_loss: 0.4447 - val_acc: 0.9102\n",
      "Epoch 22/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4480 - acc: 0.9033 - val_loss: 0.4393 - val_acc: 0.9102\n",
      "Epoch 23/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4430 - acc: 0.9048 - val_loss: 0.4341 - val_acc: 0.9141\n",
      "Epoch 24/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4376 - acc: 0.9059 - val_loss: 0.4290 - val_acc: 0.9141\n",
      "Epoch 25/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4330 - acc: 0.9066 - val_loss: 0.4241 - val_acc: 0.9141\n",
      "Epoch 26/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4283 - acc: 0.9072 - val_loss: 0.4194 - val_acc: 0.9141\n",
      "Epoch 27/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4239 - acc: 0.9077 - val_loss: 0.4148 - val_acc: 0.9141\n",
      "Epoch 28/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4190 - acc: 0.9082 - val_loss: 0.4103 - val_acc: 0.9141\n",
      "Epoch 29/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4151 - acc: 0.9085 - val_loss: 0.4060 - val_acc: 0.9141\n",
      "Epoch 30/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.4107 - acc: 0.9088 - val_loss: 0.4018 - val_acc: 0.9141\n",
      "Epoch 31/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.4070 - acc: 0.9090 - val_loss: 0.3977 - val_acc: 0.9141\n",
      "Epoch 32/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.4026 - acc: 0.9091 - val_loss: 0.3937 - val_acc: 0.9141\n",
      "Epoch 33/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3987 - acc: 0.9093 - val_loss: 0.3898 - val_acc: 0.9141\n",
      "Epoch 34/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3953 - acc: 0.9093 - val_loss: 0.3861 - val_acc: 0.9141\n",
      "Epoch 35/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.3912 - acc: 0.9094 - val_loss: 0.3824 - val_acc: 0.9141\n",
      "Epoch 36/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3877 - acc: 0.9095 - val_loss: 0.3788 - val_acc: 0.9141\n",
      "Epoch 37/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3846 - acc: 0.9094 - val_loss: 0.3754 - val_acc: 0.9141\n",
      "Epoch 38/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3814 - acc: 0.9094 - val_loss: 0.3720 - val_acc: 0.9141\n",
      "Epoch 39/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3780 - acc: 0.9095 - val_loss: 0.3687 - val_acc: 0.9141\n",
      "Epoch 40/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3747 - acc: 0.9095 - val_loss: 0.3655 - val_acc: 0.9141\n",
      "Epoch 41/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3718 - acc: 0.9095 - val_loss: 0.3624 - val_acc: 0.9141\n",
      "Epoch 42/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3689 - acc: 0.9095 - val_loss: 0.3593 - val_acc: 0.9141\n",
      "Epoch 43/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3655 - acc: 0.9095 - val_loss: 0.3564 - val_acc: 0.9141\n",
      "Epoch 44/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3630 - acc: 0.9096 - val_loss: 0.3535 - val_acc: 0.9141\n",
      "Epoch 45/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.3604 - acc: 0.9096 - val_loss: 0.3507 - val_acc: 0.9141\n",
      "Epoch 46/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3574 - acc: 0.9096 - val_loss: 0.3480 - val_acc: 0.9141\n",
      "Epoch 47/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3548 - acc: 0.9096 - val_loss: 0.3453 - val_acc: 0.9141\n",
      "Epoch 48/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3521 - acc: 0.9096 - val_loss: 0.3427 - val_acc: 0.9141\n",
      "Epoch 49/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3497 - acc: 0.9096 - val_loss: 0.3402 - val_acc: 0.9141\n",
      "Epoch 50/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3475 - acc: 0.9096 - val_loss: 0.3377 - val_acc: 0.9141\n",
      "Epoch 51/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3454 - acc: 0.9095 - val_loss: 0.3353 - val_acc: 0.9141\n",
      "Epoch 52/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3428 - acc: 0.9095 - val_loss: 0.3330 - val_acc: 0.9141\n",
      "Epoch 53/500\n",
      "11159/11159 [==============================] - 27s 2ms/step - loss: 0.3407 - acc: 0.9096 - val_loss: 0.3307 - val_acc: 0.9141\n",
      "Epoch 54/500\n",
      "11159/11159 [==============================] - 27s 2ms/step - loss: 0.3384 - acc: 0.9095 - val_loss: 0.3285 - val_acc: 0.9141\n",
      "Epoch 55/500\n",
      "11159/11159 [==============================] - 27s 2ms/step - loss: 0.3365 - acc: 0.9096 - val_loss: 0.3264 - val_acc: 0.9141\n",
      "Epoch 56/500\n",
      "11159/11159 [==============================] - 30s 3ms/step - loss: 0.3344 - acc: 0.9096 - val_loss: 0.3243 - val_acc: 0.9141\n",
      "Epoch 57/500\n",
      "11159/11159 [==============================] - 31s 3ms/step - loss: 0.3325 - acc: 0.9096 - val_loss: 0.3223 - val_acc: 0.9141\n",
      "Epoch 58/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.3304 - acc: 0.9096 - val_loss: 0.3203 - val_acc: 0.9141\n",
      "Epoch 59/500\n",
      "11159/11159 [==============================] - 29s 3ms/step - loss: 0.3282 - acc: 0.9096 - val_loss: 0.3184 - val_acc: 0.9141\n",
      "Epoch 60/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.3269 - acc: 0.9095 - val_loss: 0.3165 - val_acc: 0.9141\n",
      "Epoch 61/500\n",
      "11159/11159 [==============================] - 29s 3ms/step - loss: 0.3249 - acc: 0.9096 - val_loss: 0.3147 - val_acc: 0.9141\n",
      "Epoch 62/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.3231 - acc: 0.9096 - val_loss: 0.3129 - val_acc: 0.9141\n",
      "Epoch 63/500\n",
      "11159/11159 [==============================] - 29s 3ms/step - loss: 0.3214 - acc: 0.9096 - val_loss: 0.3112 - val_acc: 0.9141\n",
      "Epoch 64/500\n",
      "11159/11159 [==============================] - 30s 3ms/step - loss: 0.3197 - acc: 0.9095 - val_loss: 0.3095 - val_acc: 0.9141\n",
      "Epoch 65/500\n",
      "11159/11159 [==============================] - 29s 3ms/step - loss: 0.3181 - acc: 0.9096 - val_loss: 0.3079 - val_acc: 0.9141\n",
      "Epoch 66/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.3164 - acc: 0.9096 - val_loss: 0.3063 - val_acc: 0.9141\n",
      "Epoch 67/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.3153 - acc: 0.9096 - val_loss: 0.3048 - val_acc: 0.9141\n",
      "Epoch 68/500\n",
      "11159/11159 [==============================] - 29s 3ms/step - loss: 0.3139 - acc: 0.9096 - val_loss: 0.3033 - val_acc: 0.9141\n",
      "Epoch 69/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.3126 - acc: 0.9095 - val_loss: 0.3018 - val_acc: 0.9141\n",
      "Epoch 70/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.3110 - acc: 0.9096 - val_loss: 0.3004 - val_acc: 0.9141\n",
      "Epoch 71/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.3097 - acc: 0.9096 - val_loss: 0.2990 - val_acc: 0.9141\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.3083 - acc: 0.9096 - val_loss: 0.2977 - val_acc: 0.9141\n",
      "Epoch 73/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.3072 - acc: 0.9096 - val_loss: 0.2964 - val_acc: 0.9141\n",
      "Epoch 74/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.3056 - acc: 0.9095 - val_loss: 0.2952 - val_acc: 0.9141\n",
      "Epoch 75/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.3046 - acc: 0.9096 - val_loss: 0.2940 - val_acc: 0.9141\n",
      "Epoch 76/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.3035 - acc: 0.9096 - val_loss: 0.2928 - val_acc: 0.9141\n",
      "Epoch 77/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.3026 - acc: 0.9096 - val_loss: 0.2916 - val_acc: 0.9141\n",
      "Epoch 78/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.3013 - acc: 0.9096 - val_loss: 0.2905 - val_acc: 0.9141\n",
      "Epoch 79/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.3002 - acc: 0.9096 - val_loss: 0.2895 - val_acc: 0.9141\n",
      "Epoch 80/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2995 - acc: 0.9096 - val_loss: 0.2884 - val_acc: 0.9141\n",
      "Epoch 81/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.2985 - acc: 0.9096 - val_loss: 0.2874 - val_acc: 0.9141\n",
      "Epoch 82/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2974 - acc: 0.9096 - val_loss: 0.2864 - val_acc: 0.9141\n",
      "Epoch 83/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2963 - acc: 0.9096 - val_loss: 0.2855 - val_acc: 0.9141\n",
      "Epoch 84/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2955 - acc: 0.9096 - val_loss: 0.2846 - val_acc: 0.9141\n",
      "Epoch 85/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2949 - acc: 0.9096 - val_loss: 0.2837 - val_acc: 0.9141\n",
      "Epoch 86/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2940 - acc: 0.9096 - val_loss: 0.2828 - val_acc: 0.9141\n",
      "Epoch 87/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2931 - acc: 0.9095 - val_loss: 0.2820 - val_acc: 0.9141\n",
      "Epoch 88/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2925 - acc: 0.9096 - val_loss: 0.2812 - val_acc: 0.9141\n",
      "Epoch 89/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2918 - acc: 0.9096 - val_loss: 0.2804 - val_acc: 0.9141\n",
      "Epoch 90/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2909 - acc: 0.9096 - val_loss: 0.2797 - val_acc: 0.9141\n",
      "Epoch 91/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2902 - acc: 0.9096 - val_loss: 0.2789 - val_acc: 0.9141\n",
      "Epoch 92/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2894 - acc: 0.9096 - val_loss: 0.2782 - val_acc: 0.9141\n",
      "Epoch 93/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2889 - acc: 0.9096 - val_loss: 0.2775 - val_acc: 0.9141\n",
      "Epoch 94/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2882 - acc: 0.9096 - val_loss: 0.2769 - val_acc: 0.9141\n",
      "Epoch 95/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2875 - acc: 0.9096 - val_loss: 0.2762 - val_acc: 0.9141\n",
      "Epoch 96/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2869 - acc: 0.9096 - val_loss: 0.2756 - val_acc: 0.9141\n",
      "Epoch 97/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2863 - acc: 0.9096 - val_loss: 0.2750 - val_acc: 0.9141\n",
      "Epoch 98/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2858 - acc: 0.9095 - val_loss: 0.2745 - val_acc: 0.9141\n",
      "Epoch 99/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2854 - acc: 0.9096 - val_loss: 0.2739 - val_acc: 0.9141\n",
      "Epoch 100/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2847 - acc: 0.9096 - val_loss: 0.2734 - val_acc: 0.9141\n",
      "Epoch 101/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2842 - acc: 0.9096 - val_loss: 0.2728 - val_acc: 0.9141\n",
      "Epoch 102/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2839 - acc: 0.9095 - val_loss: 0.2723 - val_acc: 0.9141\n",
      "Epoch 103/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2833 - acc: 0.9096 - val_loss: 0.2719 - val_acc: 0.9141\n",
      "Epoch 104/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.2828 - acc: 0.9096 - val_loss: 0.2714 - val_acc: 0.9141\n",
      "Epoch 105/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2823 - acc: 0.9095 - val_loss: 0.2710 - val_acc: 0.9141\n",
      "Epoch 106/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2822 - acc: 0.9095 - val_loss: 0.2705 - val_acc: 0.9141\n",
      "Epoch 107/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2818 - acc: 0.9095 - val_loss: 0.2701 - val_acc: 0.9141\n",
      "Epoch 108/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2813 - acc: 0.9096 - val_loss: 0.2697 - val_acc: 0.9141\n",
      "Epoch 109/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2810 - acc: 0.9096 - val_loss: 0.2693 - val_acc: 0.9141\n",
      "Epoch 110/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2805 - acc: 0.9096 - val_loss: 0.2690 - val_acc: 0.9141\n",
      "Epoch 111/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2803 - acc: 0.9096 - val_loss: 0.2686 - val_acc: 0.9141\n",
      "Epoch 112/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2800 - acc: 0.9096 - val_loss: 0.2683 - val_acc: 0.9141\n",
      "Epoch 113/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2795 - acc: 0.9096 - val_loss: 0.2679 - val_acc: 0.9141\n",
      "Epoch 114/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2794 - acc: 0.9096 - val_loss: 0.2676 - val_acc: 0.9141\n",
      "Epoch 115/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2791 - acc: 0.9095 - val_loss: 0.2673 - val_acc: 0.9141\n",
      "Epoch 116/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2789 - acc: 0.9096 - val_loss: 0.2670 - val_acc: 0.9141\n",
      "Epoch 117/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2785 - acc: 0.9096 - val_loss: 0.2667 - val_acc: 0.9141\n",
      "Epoch 118/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2784 - acc: 0.9096 - val_loss: 0.2665 - val_acc: 0.9141\n",
      "Epoch 119/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2781 - acc: 0.9096 - val_loss: 0.2662 - val_acc: 0.9141\n",
      "Epoch 120/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2779 - acc: 0.9096 - val_loss: 0.2660 - val_acc: 0.9141\n",
      "Epoch 121/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2775 - acc: 0.9096 - val_loss: 0.2657 - val_acc: 0.9141\n",
      "Epoch 122/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2773 - acc: 0.9096 - val_loss: 0.2655 - val_acc: 0.9141\n",
      "Epoch 123/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2772 - acc: 0.9096 - val_loss: 0.2653 - val_acc: 0.9141\n",
      "Epoch 124/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2769 - acc: 0.9096 - val_loss: 0.2651 - val_acc: 0.9141\n",
      "Epoch 125/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2767 - acc: 0.9096 - val_loss: 0.2649 - val_acc: 0.9141\n",
      "Epoch 126/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2767 - acc: 0.9096 - val_loss: 0.2647 - val_acc: 0.9141\n",
      "Epoch 127/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2765 - acc: 0.9096 - val_loss: 0.2645 - val_acc: 0.9141\n",
      "Epoch 128/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2765 - acc: 0.9096 - val_loss: 0.2643 - val_acc: 0.9141\n",
      "Epoch 129/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2762 - acc: 0.9096 - val_loss: 0.2641 - val_acc: 0.9141\n",
      "Epoch 130/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2760 - acc: 0.9096 - val_loss: 0.2640 - val_acc: 0.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2760 - acc: 0.9096 - val_loss: 0.2638 - val_acc: 0.9141\n",
      "Epoch 132/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2758 - acc: 0.9096 - val_loss: 0.2637 - val_acc: 0.9141\n",
      "Epoch 133/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2756 - acc: 0.9096 - val_loss: 0.2635 - val_acc: 0.9141\n",
      "Epoch 134/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2754 - acc: 0.9096 - val_loss: 0.2634 - val_acc: 0.9141\n",
      "Epoch 135/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2753 - acc: 0.9096 - val_loss: 0.2633 - val_acc: 0.9141\n",
      "Epoch 136/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2752 - acc: 0.9096 - val_loss: 0.2631 - val_acc: 0.9141\n",
      "Epoch 137/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2752 - acc: 0.9096 - val_loss: 0.2630 - val_acc: 0.9141\n",
      "Epoch 138/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2753 - acc: 0.9096 - val_loss: 0.2629 - val_acc: 0.9141\n",
      "Epoch 139/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2750 - acc: 0.9096 - val_loss: 0.2628 - val_acc: 0.9141\n",
      "Epoch 140/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2749 - acc: 0.9096 - val_loss: 0.2627 - val_acc: 0.9141\n",
      "Epoch 141/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2749 - acc: 0.9096 - val_loss: 0.2626 - val_acc: 0.9141\n",
      "Epoch 142/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2748 - acc: 0.9096 - val_loss: 0.2625 - val_acc: 0.9141\n",
      "Epoch 143/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2747 - acc: 0.9096 - val_loss: 0.2624 - val_acc: 0.9141\n",
      "Epoch 144/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2745 - acc: 0.9096 - val_loss: 0.2623 - val_acc: 0.9141\n",
      "Epoch 145/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2744 - acc: 0.9096 - val_loss: 0.2622 - val_acc: 0.9141\n",
      "Epoch 146/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2744 - acc: 0.9096 - val_loss: 0.2622 - val_acc: 0.9141\n",
      "Epoch 147/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2743 - acc: 0.9096 - val_loss: 0.2621 - val_acc: 0.9141\n",
      "Epoch 148/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2744 - acc: 0.9096 - val_loss: 0.2620 - val_acc: 0.9141\n",
      "Epoch 149/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2743 - acc: 0.9096 - val_loss: 0.2619 - val_acc: 0.9141\n",
      "Epoch 150/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2742 - acc: 0.9096 - val_loss: 0.2619 - val_acc: 0.9141\n",
      "Epoch 151/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2741 - acc: 0.9096 - val_loss: 0.2618 - val_acc: 0.9141\n",
      "Epoch 152/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2740 - acc: 0.9096 - val_loss: 0.2618 - val_acc: 0.9141\n",
      "Epoch 153/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2740 - acc: 0.9096 - val_loss: 0.2617 - val_acc: 0.9141\n",
      "Epoch 154/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2739 - acc: 0.9096 - val_loss: 0.2617 - val_acc: 0.9141\n",
      "Epoch 155/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2739 - acc: 0.9096 - val_loss: 0.2616 - val_acc: 0.9141\n",
      "Epoch 156/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2616 - val_acc: 0.9141\n",
      "Epoch 157/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2740 - acc: 0.9096 - val_loss: 0.2615 - val_acc: 0.9141\n",
      "Epoch 158/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2615 - val_acc: 0.9141\n",
      "Epoch 159/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2738 - acc: 0.9096 - val_loss: 0.2614 - val_acc: 0.9141\n",
      "Epoch 160/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2614 - val_acc: 0.9141\n",
      "Epoch 161/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2738 - acc: 0.9096 - val_loss: 0.2614 - val_acc: 0.9141\n",
      "Epoch 162/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2613 - val_acc: 0.9141\n",
      "Epoch 163/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2613 - val_acc: 0.9141\n",
      "Epoch 164/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2613 - val_acc: 0.9141\n",
      "Epoch 165/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9141\n",
      "Epoch 166/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9141\n",
      "Epoch 167/500\n",
      "11159/11159 [==============================] - 26s 2ms/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9141\n",
      "Epoch 168/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9141\n",
      "Epoch 169/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2735 - acc: 0.9096 - val_loss: 0.2611 - val_acc: 0.9141\n",
      "Epoch 170/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2611 - val_acc: 0.9141\n",
      "Epoch 171/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2735 - acc: 0.9096 - val_loss: 0.2611 - val_acc: 0.9141\n",
      "Epoch 172/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2735 - acc: 0.9096 - val_loss: 0.2611 - val_acc: 0.9141\n",
      "Epoch 173/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2611 - val_acc: 0.9141\n",
      "Epoch 174/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 175/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 176/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 177/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 178/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 179/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 180/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2610 - val_acc: 0.9141\n",
      "Epoch 181/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 182/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 183/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9095 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 184/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 185/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 186/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 187/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 188/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 189/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 190/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 191/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9141\n",
      "Epoch 192/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 193/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 194/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 195/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 196/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 197/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 198/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 199/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 200/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 201/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 202/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 203/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 204/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 205/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 206/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 207/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 208/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 209/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 210/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 211/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 212/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 213/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 214/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 215/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 216/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 217/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 218/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 219/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 220/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9097 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 221/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 222/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2608 - val_acc: 0.9141\n",
      "Epoch 223/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 224/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 225/500\n",
      "11159/11159 [==============================] - 30s 3ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 226/500\n",
      "11159/11159 [==============================] - 33s 3ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 227/500\n",
      "11159/11159 [==============================] - 26s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 228/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2732 - acc: 0.9097 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 229/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 230/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 231/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 232/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 233/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2733 - acc: 0.9095 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 234/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 235/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 236/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 237/500\n",
      "11159/11159 [==============================] - 28s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 238/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 239/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 240/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 241/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 242/500\n",
      "11159/11159 [==============================] - 25s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 243/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 244/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 245/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 246/500\n",
      "11159/11159 [==============================] - 31s 3ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 247/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159/11159 [==============================] - 27s 2ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 248/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 249/500\n",
      "11159/11159 [==============================] - 28s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 250/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 251/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 252/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 253/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2734 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 254/500\n",
      "11159/11159 [==============================] - 24s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 255/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 256/500\n",
      "11159/11159 [==============================] - 28s 3ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 257/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 258/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 259/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 260/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 261/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 262/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 263/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 264/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 265/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 266/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 267/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 268/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 269/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2730 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 270/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 271/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 272/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 273/500\n",
      "11159/11159 [==============================] - 21s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 274/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 275/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 276/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 277/500\n",
      "11159/11159 [==============================] - 20s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 278/500\n",
      "11159/11159 [==============================] - 22s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 279/500\n",
      "11159/11159 [==============================] - 28s 2ms/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 280/500\n",
      "11159/11159 [==============================] - 28s 2ms/step - loss: 0.2730 - acc: 0.9097 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 281/500\n",
      "11159/11159 [==============================] - 23s 2ms/step - loss: 0.2732 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "[21:44:21] train_log_loss:0.26983717581622285 test_log_loss:0.28615429364931017\n",
      "[21:44:21] train_acc:0.910147013510188 test_acc:0.9011724212111434\n",
      "\n",
      "---------- split 4 ----------\n",
      "[21:44:21] train_index:0~15499 test_index:15500~18599\n",
      "Train on 13949 samples, validate on 1550 samples\n",
      "Epoch 1/500\n",
      "13949/13949 [==============================] - 30s 2ms/step - loss: 0.6576 - acc: 0.6109 - val_loss: 0.6296 - val_acc: 0.6875\n",
      "Epoch 2/500\n",
      "13949/13949 [==============================] - 28s 2ms/step - loss: 0.6141 - acc: 0.7087 - val_loss: 0.5983 - val_acc: 0.7429\n",
      "Epoch 3/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.5872 - acc: 0.7628 - val_loss: 0.5754 - val_acc: 0.7866\n",
      "Epoch 4/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.5664 - acc: 0.8013 - val_loss: 0.5568 - val_acc: 0.8242\n",
      "Epoch 5/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.5491 - acc: 0.8301 - val_loss: 0.5410 - val_acc: 0.8540\n",
      "Epoch 6/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.5339 - acc: 0.8527 - val_loss: 0.5270 - val_acc: 0.8816\n",
      "Epoch 7/500\n",
      "13949/13949 [==============================] - 36s 3ms/step - loss: 0.5203 - acc: 0.8700 - val_loss: 0.5144 - val_acc: 0.8951\n",
      "Epoch 8/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.5081 - acc: 0.8825 - val_loss: 0.5029 - val_acc: 0.8995\n",
      "Epoch 9/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4969 - acc: 0.8912 - val_loss: 0.4924 - val_acc: 0.9017\n",
      "Epoch 10/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.4869 - acc: 0.8970 - val_loss: 0.4826 - val_acc: 0.9017\n",
      "Epoch 11/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.4768 - acc: 0.9012 - val_loss: 0.4735 - val_acc: 0.9026\n",
      "Epoch 12/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4681 - acc: 0.9037 - val_loss: 0.4649 - val_acc: 0.9026\n",
      "Epoch 13/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4599 - acc: 0.9055 - val_loss: 0.4569 - val_acc: 0.9026\n",
      "Epoch 14/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4519 - acc: 0.9066 - val_loss: 0.4493 - val_acc: 0.9026\n",
      "Epoch 15/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4442 - acc: 0.9074 - val_loss: 0.4420 - val_acc: 0.9026\n",
      "Epoch 16/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4369 - acc: 0.9078 - val_loss: 0.4352 - val_acc: 0.9026\n",
      "Epoch 17/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4301 - acc: 0.9082 - val_loss: 0.4286 - val_acc: 0.9026\n",
      "Epoch 18/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.4236 - acc: 0.9084 - val_loss: 0.4224 - val_acc: 0.9026\n",
      "Epoch 19/500\n",
      "13949/13949 [==============================] - 29s 2ms/step - loss: 0.4172 - acc: 0.9085 - val_loss: 0.4165 - val_acc: 0.9026\n",
      "Epoch 20/500\n",
      "13949/13949 [==============================] - 35s 2ms/step - loss: 0.4114 - acc: 0.9086 - val_loss: 0.4108 - val_acc: 0.9026\n",
      "Epoch 21/500\n",
      "13949/13949 [==============================] - 33s 2ms/step - loss: 0.4058 - acc: 0.9088 - val_loss: 0.4053 - val_acc: 0.9026\n",
      "Epoch 22/500\n",
      "13949/13949 [==============================] - 32s 2ms/step - loss: 0.4003 - acc: 0.9087 - val_loss: 0.4001 - val_acc: 0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "13949/13949 [==============================] - 32s 2ms/step - loss: 0.3953 - acc: 0.9087 - val_loss: 0.3951 - val_acc: 0.9026\n",
      "Epoch 24/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3904 - acc: 0.9088 - val_loss: 0.3903 - val_acc: 0.9026\n",
      "Epoch 25/500\n",
      "13949/13949 [==============================] - 32s 2ms/step - loss: 0.3853 - acc: 0.9088 - val_loss: 0.3857 - val_acc: 0.9026\n",
      "Epoch 26/500\n",
      "13949/13949 [==============================] - 29s 2ms/step - loss: 0.3807 - acc: 0.9089 - val_loss: 0.3813 - val_acc: 0.9026\n",
      "Epoch 27/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3764 - acc: 0.9088 - val_loss: 0.3771 - val_acc: 0.9026\n",
      "Epoch 28/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3722 - acc: 0.9088 - val_loss: 0.3730 - val_acc: 0.9026\n",
      "Epoch 29/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3680 - acc: 0.9089 - val_loss: 0.3691 - val_acc: 0.9026\n",
      "Epoch 30/500\n",
      "13949/13949 [==============================] - 31s 2ms/step - loss: 0.3640 - acc: 0.9089 - val_loss: 0.3653 - val_acc: 0.9026\n",
      "Epoch 31/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.3607 - acc: 0.9088 - val_loss: 0.3617 - val_acc: 0.9026\n",
      "Epoch 32/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3567 - acc: 0.9089 - val_loss: 0.3582 - val_acc: 0.9026\n",
      "Epoch 33/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3530 - acc: 0.9089 - val_loss: 0.3548 - val_acc: 0.9026\n",
      "Epoch 34/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3499 - acc: 0.9088 - val_loss: 0.3516 - val_acc: 0.9026\n",
      "Epoch 35/500\n",
      "13949/13949 [==============================] - 28s 2ms/step - loss: 0.3465 - acc: 0.9088 - val_loss: 0.3485 - val_acc: 0.9026\n",
      "Epoch 36/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3434 - acc: 0.9089 - val_loss: 0.3455 - val_acc: 0.9026\n",
      "Epoch 37/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3406 - acc: 0.9088 - val_loss: 0.3426 - val_acc: 0.9026\n",
      "Epoch 38/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3377 - acc: 0.9089 - val_loss: 0.3399 - val_acc: 0.9026\n",
      "Epoch 39/500\n",
      "13949/13949 [==============================] - 28s 2ms/step - loss: 0.3346 - acc: 0.9088 - val_loss: 0.3372 - val_acc: 0.9026\n",
      "Epoch 40/500\n",
      "13949/13949 [==============================] - 30s 2ms/step - loss: 0.3319 - acc: 0.9088 - val_loss: 0.3347 - val_acc: 0.9026\n",
      "Epoch 41/500\n",
      "13949/13949 [==============================] - 31s 2ms/step - loss: 0.3293 - acc: 0.9089 - val_loss: 0.3322 - val_acc: 0.9026\n",
      "Epoch 42/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3269 - acc: 0.9088 - val_loss: 0.3299 - val_acc: 0.9026\n",
      "Epoch 43/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3250 - acc: 0.9089 - val_loss: 0.3276 - val_acc: 0.9026\n",
      "Epoch 44/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.3227 - acc: 0.9088 - val_loss: 0.3254 - val_acc: 0.9026\n",
      "Epoch 45/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.3201 - acc: 0.9088 - val_loss: 0.3234 - val_acc: 0.9026\n",
      "Epoch 46/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.3181 - acc: 0.9088 - val_loss: 0.3214 - val_acc: 0.9026\n",
      "Epoch 47/500\n",
      "13949/13949 [==============================] - 33s 2ms/step - loss: 0.3160 - acc: 0.9088 - val_loss: 0.3194 - val_acc: 0.9026\n",
      "Epoch 48/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3142 - acc: 0.9089 - val_loss: 0.3176 - val_acc: 0.9026\n",
      "Epoch 49/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3122 - acc: 0.9088 - val_loss: 0.3158 - val_acc: 0.9026\n",
      "Epoch 50/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3105 - acc: 0.9088 - val_loss: 0.3141 - val_acc: 0.9026\n",
      "Epoch 51/500\n",
      "13949/13949 [==============================] - 31s 2ms/step - loss: 0.3087 - acc: 0.9089 - val_loss: 0.3125 - val_acc: 0.9026\n",
      "Epoch 52/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3070 - acc: 0.9088 - val_loss: 0.3110 - val_acc: 0.9026\n",
      "Epoch 53/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3052 - acc: 0.9089 - val_loss: 0.3095 - val_acc: 0.9026\n",
      "Epoch 54/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3042 - acc: 0.9089 - val_loss: 0.3080 - val_acc: 0.9026\n",
      "Epoch 55/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.3026 - acc: 0.9089 - val_loss: 0.3067 - val_acc: 0.9026\n",
      "Epoch 56/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3010 - acc: 0.9088 - val_loss: 0.3054 - val_acc: 0.9026\n",
      "Epoch 57/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.3002 - acc: 0.9089 - val_loss: 0.3041 - val_acc: 0.9026\n",
      "Epoch 58/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2985 - acc: 0.9089 - val_loss: 0.3029 - val_acc: 0.9026\n",
      "Epoch 59/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2973 - acc: 0.9089 - val_loss: 0.3018 - val_acc: 0.9026\n",
      "Epoch 60/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2961 - acc: 0.9088 - val_loss: 0.3007 - val_acc: 0.9026\n",
      "Epoch 61/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2951 - acc: 0.9088 - val_loss: 0.2996 - val_acc: 0.9026\n",
      "Epoch 62/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2940 - acc: 0.9089 - val_loss: 0.2986 - val_acc: 0.9026\n",
      "Epoch 63/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2930 - acc: 0.9089 - val_loss: 0.2977 - val_acc: 0.9026\n",
      "Epoch 64/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2921 - acc: 0.9089 - val_loss: 0.2968 - val_acc: 0.9026\n",
      "Epoch 65/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2910 - acc: 0.9089 - val_loss: 0.2959 - val_acc: 0.9026\n",
      "Epoch 66/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2903 - acc: 0.9088 - val_loss: 0.2951 - val_acc: 0.9026\n",
      "Epoch 67/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2895 - acc: 0.9089 - val_loss: 0.2943 - val_acc: 0.9026\n",
      "Epoch 68/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2886 - acc: 0.9089 - val_loss: 0.2935 - val_acc: 0.9026\n",
      "Epoch 69/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2877 - acc: 0.9089 - val_loss: 0.2928 - val_acc: 0.9026\n",
      "Epoch 70/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2870 - acc: 0.9088 - val_loss: 0.2922 - val_acc: 0.9026\n",
      "Epoch 71/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2862 - acc: 0.9088 - val_loss: 0.2915 - val_acc: 0.9026\n",
      "Epoch 72/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2857 - acc: 0.9089 - val_loss: 0.2909 - val_acc: 0.9026\n",
      "Epoch 73/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2851 - acc: 0.9088 - val_loss: 0.2903 - val_acc: 0.9026\n",
      "Epoch 74/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2844 - acc: 0.9088 - val_loss: 0.2898 - val_acc: 0.9026\n",
      "Epoch 75/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2837 - acc: 0.9089 - val_loss: 0.2892 - val_acc: 0.9026\n",
      "Epoch 76/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2831 - acc: 0.9089 - val_loss: 0.2887 - val_acc: 0.9026\n",
      "Epoch 77/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2828 - acc: 0.9088 - val_loss: 0.2883 - val_acc: 0.9026\n",
      "Epoch 78/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2823 - acc: 0.9089 - val_loss: 0.2878 - val_acc: 0.9026\n",
      "Epoch 79/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2818 - acc: 0.9088 - val_loss: 0.2874 - val_acc: 0.9026\n",
      "Epoch 80/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2814 - acc: 0.9089 - val_loss: 0.2870 - val_acc: 0.9026\n",
      "Epoch 81/500\n",
      "13949/13949 [==============================] - 28s 2ms/step - loss: 0.2809 - acc: 0.9089 - val_loss: 0.2866 - val_acc: 0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "13949/13949 [==============================] - 39s 3ms/step - loss: 0.2807 - acc: 0.9088 - val_loss: 0.2862 - val_acc: 0.9026\n",
      "Epoch 83/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.2801 - acc: 0.9089 - val_loss: 0.2859 - val_acc: 0.9026\n",
      "Epoch 84/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.2798 - acc: 0.9089 - val_loss: 0.2856 - val_acc: 0.9026\n",
      "Epoch 85/500\n",
      "13949/13949 [==============================] - 32s 2ms/step - loss: 0.2796 - acc: 0.9088 - val_loss: 0.2853 - val_acc: 0.9026\n",
      "Epoch 86/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2791 - acc: 0.9089 - val_loss: 0.2850 - val_acc: 0.9026\n",
      "Epoch 87/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2789 - acc: 0.9089 - val_loss: 0.2847 - val_acc: 0.9026\n",
      "Epoch 88/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2785 - acc: 0.9089 - val_loss: 0.2845 - val_acc: 0.9026\n",
      "Epoch 89/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2784 - acc: 0.9089 - val_loss: 0.2842 - val_acc: 0.9026\n",
      "Epoch 90/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2781 - acc: 0.9089 - val_loss: 0.2840 - val_acc: 0.9026\n",
      "Epoch 91/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2779 - acc: 0.9088 - val_loss: 0.2838 - val_acc: 0.9026\n",
      "Epoch 92/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2776 - acc: 0.9089 - val_loss: 0.2836 - val_acc: 0.9026\n",
      "Epoch 93/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2774 - acc: 0.9088 - val_loss: 0.2834 - val_acc: 0.9026\n",
      "Epoch 94/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.2772 - acc: 0.9089 - val_loss: 0.2833 - val_acc: 0.9026\n",
      "Epoch 95/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2770 - acc: 0.9088 - val_loss: 0.2831 - val_acc: 0.9026\n",
      "Epoch 96/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2768 - acc: 0.9088 - val_loss: 0.2829 - val_acc: 0.9026\n",
      "Epoch 97/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2766 - acc: 0.9089 - val_loss: 0.2828 - val_acc: 0.9026\n",
      "Epoch 98/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2766 - acc: 0.9088 - val_loss: 0.2827 - val_acc: 0.9026\n",
      "Epoch 99/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2762 - acc: 0.9088 - val_loss: 0.2826 - val_acc: 0.9026\n",
      "Epoch 100/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2763 - acc: 0.9089 - val_loss: 0.2824 - val_acc: 0.9026\n",
      "Epoch 101/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2761 - acc: 0.9088 - val_loss: 0.2823 - val_acc: 0.9026\n",
      "Epoch 102/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2759 - acc: 0.9089 - val_loss: 0.2822 - val_acc: 0.9026\n",
      "Epoch 103/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2758 - acc: 0.9089 - val_loss: 0.2822 - val_acc: 0.9026\n",
      "Epoch 104/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2757 - acc: 0.9089 - val_loss: 0.2821 - val_acc: 0.9026\n",
      "Epoch 105/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2756 - acc: 0.9089 - val_loss: 0.2820 - val_acc: 0.9026\n",
      "Epoch 106/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2755 - acc: 0.9089 - val_loss: 0.2819 - val_acc: 0.9026\n",
      "Epoch 107/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2755 - acc: 0.9089 - val_loss: 0.2819 - val_acc: 0.9026\n",
      "Epoch 108/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2753 - acc: 0.9089 - val_loss: 0.2818 - val_acc: 0.9026\n",
      "Epoch 109/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2753 - acc: 0.9088 - val_loss: 0.2817 - val_acc: 0.9026\n",
      "Epoch 110/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2752 - acc: 0.9088 - val_loss: 0.2817 - val_acc: 0.9026\n",
      "Epoch 111/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2754 - acc: 0.9088 - val_loss: 0.2816 - val_acc: 0.9026\n",
      "Epoch 112/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2752 - acc: 0.9088 - val_loss: 0.2816 - val_acc: 0.9026\n",
      "Epoch 113/500\n",
      "13949/13949 [==============================] - 31s 2ms/step - loss: 0.2750 - acc: 0.9089 - val_loss: 0.2816 - val_acc: 0.9026\n",
      "Epoch 114/500\n",
      "13949/13949 [==============================] - 35s 3ms/step - loss: 0.2749 - acc: 0.9089 - val_loss: 0.2815 - val_acc: 0.9026\n",
      "Epoch 115/500\n",
      "13949/13949 [==============================] - 27s 2ms/step - loss: 0.2749 - acc: 0.9088 - val_loss: 0.2815 - val_acc: 0.9026\n",
      "Epoch 116/500\n",
      "13949/13949 [==============================] - 28s 2ms/step - loss: 0.2749 - acc: 0.9089 - val_loss: 0.2815 - val_acc: 0.9026\n",
      "Epoch 117/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2749 - acc: 0.9088 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 118/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2749 - acc: 0.9089 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 119/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2749 - acc: 0.9089 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 120/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 121/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2749 - acc: 0.9088 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 122/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.2814 - val_acc: 0.9026\n",
      "Epoch 123/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2748 - acc: 0.9088 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 124/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2747 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 125/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2746 - acc: 0.9088 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 126/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 127/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 128/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2747 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 129/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9088 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 130/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2747 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 131/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 132/500\n",
      "13949/13949 [==============================] - 25s 2ms/step - loss: 0.2745 - acc: 0.9088 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 133/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2744 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 134/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2744 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 135/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9088 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 136/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 137/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2745 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 138/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2744 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "Epoch 139/500\n",
      "13949/13949 [==============================] - 26s 2ms/step - loss: 0.2744 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9026\n",
      "[22:46:32] train_log_loss:0.27306021900668703 test_log_loss:0.29827652868945326\n",
      "[22:46:32] train_acc:0.9083553777663075 test_acc:0.8949206112807274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Actual Model --> Assign all observations to prediction\n",
    "\n",
    "# define model\n",
    "model = MyLSTM(**def_params)\n",
    "\n",
    "# time series cross validation\n",
    "train_scores_df, test_scores_df, y_test_probs = time_series_cv(x_all,\n",
    "                                                               y_all,\n",
    "                                                               n_splits=n_splits,\n",
    "                                                               model=model,\n",
    "                                                               fit_params=fit_params,\n",
    "                                                               baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893426</td>\n",
       "      <td>0.308521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906527</td>\n",
       "      <td>0.278036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.910056</td>\n",
       "      <td>0.270104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.910147</td>\n",
       "      <td>0.269837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908355</td>\n",
       "      <td>0.273060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  log_loss\n",
       "0  0.893426  0.308521\n",
       "1  0.906527  0.278036\n",
       "2  0.910056  0.270104\n",
       "3  0.910147  0.269837\n",
       "4  0.908355  0.273060"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train metrics\n",
    "train_scores_df.to_csv(\"./results/train_scores.csv\", index=False)\n",
    "train_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918609</td>\n",
       "      <td>0.260748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916545</td>\n",
       "      <td>0.255125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.910434</td>\n",
       "      <td>0.269369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901172</td>\n",
       "      <td>0.286154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894921</td>\n",
       "      <td>0.298277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  log_loss\n",
       "0  0.918609  0.260748\n",
       "1  0.916545  0.255125\n",
       "2  0.910434  0.269369\n",
       "3  0.901172  0.286154\n",
       "4  0.894921  0.298277"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test metrics\n",
    "test_scores_df.to_csv(\"./results/test_scores.csv\", index=False)\n",
    "test_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>06075010100</th>\n",
       "      <th>06075010200</th>\n",
       "      <th>06075010300</th>\n",
       "      <th>06075010400</th>\n",
       "      <th>06075010500</th>\n",
       "      <th>06075010600</th>\n",
       "      <th>06075010700</th>\n",
       "      <th>06075010800</th>\n",
       "      <th>06075010900</th>\n",
       "      <th>06075011000</th>\n",
       "      <th>06075011100</th>\n",
       "      <th>06075011200</th>\n",
       "      <th>06075011300</th>\n",
       "      <th>06075011700</th>\n",
       "      <th>06075011800</th>\n",
       "      <th>06075011901</th>\n",
       "      <th>06075011902</th>\n",
       "      <th>06075012000</th>\n",
       "      <th>06075012100</th>\n",
       "      <th>06075012201</th>\n",
       "      <th>06075012202</th>\n",
       "      <th>06075012301</th>\n",
       "      <th>06075012302</th>\n",
       "      <th>06075012401</th>\n",
       "      <th>06075012402</th>\n",
       "      <th>06075012501</th>\n",
       "      <th>06075012502</th>\n",
       "      <th>06075012601</th>\n",
       "      <th>06075012602</th>\n",
       "      <th>06075012700</th>\n",
       "      <th>06075012800</th>\n",
       "      <th>06075012901</th>\n",
       "      <th>06075012902</th>\n",
       "      <th>06075013000</th>\n",
       "      <th>06075013101</th>\n",
       "      <th>06075013102</th>\n",
       "      <th>06075013200</th>\n",
       "      <th>06075013300</th>\n",
       "      <th>06075013400</th>\n",
       "      <th>06075013500</th>\n",
       "      <th>06075015100</th>\n",
       "      <th>06075015200</th>\n",
       "      <th>06075015300</th>\n",
       "      <th>06075015400</th>\n",
       "      <th>06075015500</th>\n",
       "      <th>06075015600</th>\n",
       "      <th>06075015700</th>\n",
       "      <th>06075015801</th>\n",
       "      <th>06075015802</th>\n",
       "      <th>06075015900</th>\n",
       "      <th>06075016000</th>\n",
       "      <th>06075016100</th>\n",
       "      <th>06075016200</th>\n",
       "      <th>06075016300</th>\n",
       "      <th>06075016400</th>\n",
       "      <th>06075016500</th>\n",
       "      <th>06075016600</th>\n",
       "      <th>06075016700</th>\n",
       "      <th>06075016801</th>\n",
       "      <th>06075016802</th>\n",
       "      <th>06075016900</th>\n",
       "      <th>06075017000</th>\n",
       "      <th>06075017101</th>\n",
       "      <th>06075017102</th>\n",
       "      <th>06075017601</th>\n",
       "      <th>06075017700</th>\n",
       "      <th>06075017801</th>\n",
       "      <th>06075017802</th>\n",
       "      <th>06075017902</th>\n",
       "      <th>06075018000</th>\n",
       "      <th>06075020100</th>\n",
       "      <th>06075020200</th>\n",
       "      <th>06075020300</th>\n",
       "      <th>06075020401</th>\n",
       "      <th>06075020402</th>\n",
       "      <th>06075020500</th>\n",
       "      <th>06075020600</th>\n",
       "      <th>06075020700</th>\n",
       "      <th>06075020800</th>\n",
       "      <th>06075020900</th>\n",
       "      <th>06075021000</th>\n",
       "      <th>06075021100</th>\n",
       "      <th>06075021200</th>\n",
       "      <th>06075021300</th>\n",
       "      <th>06075021400</th>\n",
       "      <th>06075021500</th>\n",
       "      <th>06075021600</th>\n",
       "      <th>06075021700</th>\n",
       "      <th>06075021800</th>\n",
       "      <th>06075022600</th>\n",
       "      <th>06075022702</th>\n",
       "      <th>06075022704</th>\n",
       "      <th>06075022801</th>\n",
       "      <th>06075022802</th>\n",
       "      <th>06075022803</th>\n",
       "      <th>06075022901</th>\n",
       "      <th>06075022902</th>\n",
       "      <th>06075022903</th>\n",
       "      <th>06075023001</th>\n",
       "      <th>06075023003</th>\n",
       "      <th>06075023102</th>\n",
       "      <th>06075023103</th>\n",
       "      <th>06075023200</th>\n",
       "      <th>06075023300</th>\n",
       "      <th>06075023400</th>\n",
       "      <th>06075025100</th>\n",
       "      <th>06075025200</th>\n",
       "      <th>06075025300</th>\n",
       "      <th>06075025401</th>\n",
       "      <th>06075025402</th>\n",
       "      <th>06075025403</th>\n",
       "      <th>06075025500</th>\n",
       "      <th>06075025600</th>\n",
       "      <th>06075025701</th>\n",
       "      <th>06075025702</th>\n",
       "      <th>06075025800</th>\n",
       "      <th>06075025900</th>\n",
       "      <th>06075026001</th>\n",
       "      <th>06075026002</th>\n",
       "      <th>06075026003</th>\n",
       "      <th>06075026004</th>\n",
       "      <th>06075026100</th>\n",
       "      <th>06075026200</th>\n",
       "      <th>06075026301</th>\n",
       "      <th>06075026302</th>\n",
       "      <th>06075026303</th>\n",
       "      <th>06075026401</th>\n",
       "      <th>06075026402</th>\n",
       "      <th>06075026403</th>\n",
       "      <th>06075026404</th>\n",
       "      <th>06075030101</th>\n",
       "      <th>06075030102</th>\n",
       "      <th>06075030201</th>\n",
       "      <th>06075030202</th>\n",
       "      <th>06075030301</th>\n",
       "      <th>06075030302</th>\n",
       "      <th>06075030400</th>\n",
       "      <th>06075030500</th>\n",
       "      <th>06075030600</th>\n",
       "      <th>06075030700</th>\n",
       "      <th>06075030800</th>\n",
       "      <th>06075030900</th>\n",
       "      <th>06075031000</th>\n",
       "      <th>06075031100</th>\n",
       "      <th>06075031201</th>\n",
       "      <th>06075031202</th>\n",
       "      <th>06075031301</th>\n",
       "      <th>06075031302</th>\n",
       "      <th>06075031400</th>\n",
       "      <th>06075032601</th>\n",
       "      <th>06075032602</th>\n",
       "      <th>06075032700</th>\n",
       "      <th>06075032801</th>\n",
       "      <th>06075032802</th>\n",
       "      <th>06075032901</th>\n",
       "      <th>06075032902</th>\n",
       "      <th>06075033000</th>\n",
       "      <th>06075033100</th>\n",
       "      <th>06075033201</th>\n",
       "      <th>06075033203</th>\n",
       "      <th>06075033204</th>\n",
       "      <th>06075035100</th>\n",
       "      <th>06075035201</th>\n",
       "      <th>06075035202</th>\n",
       "      <th>06075035300</th>\n",
       "      <th>06075035400</th>\n",
       "      <th>06075040100</th>\n",
       "      <th>06075040200</th>\n",
       "      <th>06075042601</th>\n",
       "      <th>06075042602</th>\n",
       "      <th>06075042700</th>\n",
       "      <th>06075042800</th>\n",
       "      <th>06075045100</th>\n",
       "      <th>06075045200</th>\n",
       "      <th>06075047600</th>\n",
       "      <th>06075047701</th>\n",
       "      <th>06075047702</th>\n",
       "      <th>06075047801</th>\n",
       "      <th>06075047802</th>\n",
       "      <th>06075047901</th>\n",
       "      <th>06075047902</th>\n",
       "      <th>06075060100</th>\n",
       "      <th>06075060400</th>\n",
       "      <th>06075060502</th>\n",
       "      <th>06075060700</th>\n",
       "      <th>06075061000</th>\n",
       "      <th>06075061100</th>\n",
       "      <th>06075061200</th>\n",
       "      <th>06075061400</th>\n",
       "      <th>06075061500</th>\n",
       "      <th>06075980200</th>\n",
       "      <th>06075980300</th>\n",
       "      <th>06075980501</th>\n",
       "      <th>06075980600</th>\n",
       "      <th>06075980900</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-17 08:00:00</th>\n",
       "      <td>0.387637</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.07577</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.18622</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.14852</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.100662</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.097745</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.365396</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.637707</td>\n",
       "      <td>0.440635</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.22112</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.166206</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.079564</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.06743</td>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.091914</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.065606</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.104192</td>\n",
       "      <td>0.123871</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.08828</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.071536</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.06389</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.089036</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.14492</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.262894</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.239947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-17 10:00:00</th>\n",
       "      <td>0.387637</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.07577</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.18622</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.14852</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.100662</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.097745</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.365396</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.637707</td>\n",
       "      <td>0.440635</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.22112</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.166206</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.079564</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.06743</td>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.091914</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.065606</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.104192</td>\n",
       "      <td>0.123871</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.08828</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.071536</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.06389</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.089036</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.14492</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.262894</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.239947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-17 12:00:00</th>\n",
       "      <td>0.387637</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.07577</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.18622</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.14852</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.100662</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.097745</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.365396</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.637707</td>\n",
       "      <td>0.440635</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.22112</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.166206</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.079564</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.06743</td>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.091914</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.065606</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.104192</td>\n",
       "      <td>0.123871</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.08828</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.071536</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.06389</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.089036</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.14492</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.262894</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.239947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-17 14:00:00</th>\n",
       "      <td>0.387637</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.07577</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.18622</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.14852</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.100662</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.097745</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.365396</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.637707</td>\n",
       "      <td>0.440635</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.22112</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.166206</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.079564</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.06743</td>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.091914</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.065606</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.104192</td>\n",
       "      <td>0.123871</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.08828</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.071536</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.06389</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.089036</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.14492</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.262894</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.239947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-17 16:00:00</th>\n",
       "      <td>0.387637</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.05997</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.07577</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.18622</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.065912</td>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.14852</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.107451</td>\n",
       "      <td>0.214664</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.100662</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.214096</td>\n",
       "      <td>0.111621</td>\n",
       "      <td>0.097745</td>\n",
       "      <td>0.124948</td>\n",
       "      <td>0.158183</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.365396</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.637707</td>\n",
       "      <td>0.440635</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.22112</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>0.166206</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.145326</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.095185</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.186231</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.079564</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.06743</td>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.091914</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>0.04749</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.065606</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.104192</td>\n",
       "      <td>0.123871</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.08828</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.071536</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.122789</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.081875</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.06389</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.055858</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.089036</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.14492</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.262894</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.239947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     06075010100  06075010200  06075010300  06075010400  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.387637     0.241744     0.098925     0.095542   \n",
       "2015-09-17 10:00:00     0.387637     0.241744     0.098925     0.095542   \n",
       "2015-09-17 12:00:00     0.387637     0.241744     0.098925     0.095542   \n",
       "2015-09-17 14:00:00     0.387637     0.241744     0.098925     0.095542   \n",
       "2015-09-17 16:00:00     0.387637     0.241744     0.098925     0.095542   \n",
       "\n",
       "                     06075010500  06075010600  06075010700  06075010800  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.292688     0.127813     0.185343      0.05997   \n",
       "2015-09-17 10:00:00     0.292688     0.127813     0.185343      0.05997   \n",
       "2015-09-17 12:00:00     0.292688     0.127813     0.185343      0.05997   \n",
       "2015-09-17 14:00:00     0.292688     0.127813     0.185343      0.05997   \n",
       "2015-09-17 16:00:00     0.292688     0.127813     0.185343      0.05997   \n",
       "\n",
       "                     06075010900  06075011000  06075011100  06075011200  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.095403     0.100532     0.201888     0.090691   \n",
       "2015-09-17 10:00:00     0.095403     0.100532     0.201888     0.090691   \n",
       "2015-09-17 12:00:00     0.095403     0.100532     0.201888     0.090691   \n",
       "2015-09-17 14:00:00     0.095403     0.100532     0.201888     0.090691   \n",
       "2015-09-17 16:00:00     0.095403     0.100532     0.201888     0.090691   \n",
       "\n",
       "                     06075011300  06075011700  06075011800  06075011901  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.07577     0.542401     0.057486     0.050868   \n",
       "2015-09-17 10:00:00      0.07577     0.542401     0.057486     0.050868   \n",
       "2015-09-17 12:00:00      0.07577     0.542401     0.057486     0.050868   \n",
       "2015-09-17 14:00:00      0.07577     0.542401     0.057486     0.050868   \n",
       "2015-09-17 16:00:00      0.07577     0.542401     0.057486     0.050868   \n",
       "\n",
       "                     06075011902  06075012000  06075012100  06075012201  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.101254      0.18622     0.153662     0.164475   \n",
       "2015-09-17 10:00:00     0.101254      0.18622     0.153662     0.164475   \n",
       "2015-09-17 12:00:00     0.101254      0.18622     0.153662     0.164475   \n",
       "2015-09-17 14:00:00     0.101254      0.18622     0.153662     0.164475   \n",
       "2015-09-17 16:00:00     0.101254      0.18622     0.153662     0.164475   \n",
       "\n",
       "                     06075012202  06075012301  06075012302  06075012401  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.218936     0.248881     0.178816     0.277531   \n",
       "2015-09-17 10:00:00     0.218936     0.248881     0.178816     0.277531   \n",
       "2015-09-17 12:00:00     0.218936     0.248881     0.178816     0.277531   \n",
       "2015-09-17 14:00:00     0.218936     0.248881     0.178816     0.277531   \n",
       "2015-09-17 16:00:00     0.218936     0.248881     0.178816     0.277531   \n",
       "\n",
       "                     06075012402  06075012501  06075012502  06075012601  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.451848     0.359447     0.225989     0.062736   \n",
       "2015-09-17 10:00:00     0.451848     0.359447     0.225989     0.062736   \n",
       "2015-09-17 12:00:00     0.451848     0.359447     0.225989     0.062736   \n",
       "2015-09-17 14:00:00     0.451848     0.359447     0.225989     0.062736   \n",
       "2015-09-17 16:00:00     0.451848     0.359447     0.225989     0.062736   \n",
       "\n",
       "                     06075012602  06075012700  06075012800  06075012901  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.094343     0.086376      0.17519      0.07913   \n",
       "2015-09-17 10:00:00     0.094343     0.086376      0.17519      0.07913   \n",
       "2015-09-17 12:00:00     0.094343     0.086376      0.17519      0.07913   \n",
       "2015-09-17 14:00:00     0.094343     0.086376      0.17519      0.07913   \n",
       "2015-09-17 16:00:00     0.094343     0.086376      0.17519      0.07913   \n",
       "\n",
       "                     06075012902  06075013000  06075013101  06075013102  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.094767     0.123563     0.092806     0.072251   \n",
       "2015-09-17 10:00:00     0.094767     0.123563     0.092806     0.072251   \n",
       "2015-09-17 12:00:00     0.094767     0.123563     0.092806     0.072251   \n",
       "2015-09-17 14:00:00     0.094767     0.123563     0.092806     0.072251   \n",
       "2015-09-17 16:00:00     0.094767     0.123563     0.092806     0.072251   \n",
       "\n",
       "                     06075013200  06075013300  06075013400  06075013500  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.081813     0.065912     0.061012     0.087861   \n",
       "2015-09-17 10:00:00     0.081813     0.065912     0.061012     0.087861   \n",
       "2015-09-17 12:00:00     0.081813     0.065912     0.061012     0.087861   \n",
       "2015-09-17 14:00:00     0.081813     0.065912     0.061012     0.087861   \n",
       "2015-09-17 16:00:00     0.081813     0.065912     0.061012     0.087861   \n",
       "\n",
       "                     06075015100  06075015200  06075015300  06075015400  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.14852     0.116283     0.059592     0.101352   \n",
       "2015-09-17 10:00:00      0.14852     0.116283     0.059592     0.101352   \n",
       "2015-09-17 12:00:00      0.14852     0.116283     0.059592     0.101352   \n",
       "2015-09-17 14:00:00      0.14852     0.116283     0.059592     0.101352   \n",
       "2015-09-17 16:00:00      0.14852     0.116283     0.059592     0.101352   \n",
       "\n",
       "                     06075015500  06075015600  06075015700  06075015801  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.163449     0.082159      0.16789     0.147182   \n",
       "2015-09-17 10:00:00     0.163449     0.082159      0.16789     0.147182   \n",
       "2015-09-17 12:00:00     0.163449     0.082159      0.16789     0.147182   \n",
       "2015-09-17 14:00:00     0.163449     0.082159      0.16789     0.147182   \n",
       "2015-09-17 16:00:00     0.163449     0.082159      0.16789     0.147182   \n",
       "\n",
       "                     06075015802  06075015900  06075016000  06075016100  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.098014     0.225008     0.107451     0.214664   \n",
       "2015-09-17 10:00:00     0.098014     0.225008     0.107451     0.214664   \n",
       "2015-09-17 12:00:00     0.098014     0.225008     0.107451     0.214664   \n",
       "2015-09-17 14:00:00     0.098014     0.225008     0.107451     0.214664   \n",
       "2015-09-17 16:00:00     0.098014     0.225008     0.107451     0.214664   \n",
       "\n",
       "                     06075016200  06075016300  06075016400  06075016500  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.190793     0.100662     0.133423     0.133659   \n",
       "2015-09-17 10:00:00     0.190793     0.100662     0.133423     0.133659   \n",
       "2015-09-17 12:00:00     0.190793     0.100662     0.133423     0.133659   \n",
       "2015-09-17 14:00:00     0.190793     0.100662     0.133423     0.133659   \n",
       "2015-09-17 16:00:00     0.190793     0.100662     0.133423     0.133659   \n",
       "\n",
       "                     06075016600  06075016700  06075016801  06075016802  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.214096     0.111621     0.097745     0.124948   \n",
       "2015-09-17 10:00:00     0.214096     0.111621     0.097745     0.124948   \n",
       "2015-09-17 12:00:00     0.214096     0.111621     0.097745     0.124948   \n",
       "2015-09-17 14:00:00     0.214096     0.111621     0.097745     0.124948   \n",
       "2015-09-17 16:00:00     0.214096     0.111621     0.097745     0.124948   \n",
       "\n",
       "                     06075016900  06075017000  06075017101  06075017102  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.158183     0.073988     0.059291     0.070247   \n",
       "2015-09-17 10:00:00     0.158183     0.073988     0.059291     0.070247   \n",
       "2015-09-17 12:00:00     0.158183     0.073988     0.059291     0.070247   \n",
       "2015-09-17 14:00:00     0.158183     0.073988     0.059291     0.070247   \n",
       "2015-09-17 16:00:00     0.158183     0.073988     0.059291     0.070247   \n",
       "\n",
       "                     06075017601  06075017700  06075017801  06075017802  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.644698     0.365396     0.185017     0.407634   \n",
       "2015-09-17 10:00:00     0.644698     0.365396     0.185017     0.407634   \n",
       "2015-09-17 12:00:00     0.644698     0.365396     0.185017     0.407634   \n",
       "2015-09-17 14:00:00     0.644698     0.365396     0.185017     0.407634   \n",
       "2015-09-17 16:00:00     0.644698     0.365396     0.185017     0.407634   \n",
       "\n",
       "                     06075017902  06075018000  06075020100  06075020200  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.070816     0.637707     0.440635     0.150933   \n",
       "2015-09-17 10:00:00     0.070816     0.637707     0.440635     0.150933   \n",
       "2015-09-17 12:00:00     0.070816     0.637707     0.440635     0.150933   \n",
       "2015-09-17 14:00:00     0.070816     0.637707     0.440635     0.150933   \n",
       "2015-09-17 16:00:00     0.070816     0.637707     0.440635     0.150933   \n",
       "\n",
       "                     06075020300  06075020401  06075020402  06075020500  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.132466     0.076848     0.055367     0.121466   \n",
       "2015-09-17 10:00:00     0.132466     0.076848     0.055367     0.121466   \n",
       "2015-09-17 12:00:00     0.132466     0.076848     0.055367     0.121466   \n",
       "2015-09-17 14:00:00     0.132466     0.076848     0.055367     0.121466   \n",
       "2015-09-17 16:00:00     0.132466     0.076848     0.055367     0.121466   \n",
       "\n",
       "                     06075020600  06075020700  06075020800  06075020900  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.168135     0.144559      0.22112     0.194331   \n",
       "2015-09-17 10:00:00     0.168135     0.144559      0.22112     0.194331   \n",
       "2015-09-17 12:00:00     0.168135     0.144559      0.22112     0.194331   \n",
       "2015-09-17 14:00:00     0.168135     0.144559      0.22112     0.194331   \n",
       "2015-09-17 16:00:00     0.168135     0.144559      0.22112     0.194331   \n",
       "\n",
       "                     06075021000  06075021100  06075021200  06075021300  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.073108      0.06429     0.055051     0.037496   \n",
       "2015-09-17 10:00:00     0.073108      0.06429     0.055051     0.037496   \n",
       "2015-09-17 12:00:00     0.073108      0.06429     0.055051     0.037496   \n",
       "2015-09-17 14:00:00     0.073108      0.06429     0.055051     0.037496   \n",
       "2015-09-17 16:00:00     0.073108      0.06429     0.055051     0.037496   \n",
       "\n",
       "                     06075021400  06075021500  06075021600  06075021700  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.048268     0.081085       0.0539     0.069787   \n",
       "2015-09-17 10:00:00     0.048268     0.081085       0.0539     0.069787   \n",
       "2015-09-17 12:00:00     0.048268     0.081085       0.0539     0.069787   \n",
       "2015-09-17 14:00:00     0.048268     0.081085       0.0539     0.069787   \n",
       "2015-09-17 16:00:00     0.048268     0.081085       0.0539     0.069787   \n",
       "\n",
       "                     06075021800  06075022600  06075022702  06075022704  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.082113     0.166206     0.071697     0.112761   \n",
       "2015-09-17 10:00:00     0.082113     0.166206     0.071697     0.112761   \n",
       "2015-09-17 12:00:00     0.082113     0.166206     0.071697     0.112761   \n",
       "2015-09-17 14:00:00     0.082113     0.166206     0.071697     0.112761   \n",
       "2015-09-17 16:00:00     0.082113     0.166206     0.071697     0.112761   \n",
       "\n",
       "                     06075022801  06075022802  06075022803  06075022901  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.145326     0.213569     0.081627     0.090261   \n",
       "2015-09-17 10:00:00     0.145326     0.213569     0.081627     0.090261   \n",
       "2015-09-17 12:00:00     0.145326     0.213569     0.081627     0.090261   \n",
       "2015-09-17 14:00:00     0.145326     0.213569     0.081627     0.090261   \n",
       "2015-09-17 16:00:00     0.145326     0.213569     0.081627     0.090261   \n",
       "\n",
       "                     06075022902  06075022903  06075023001  06075023003  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.053519     0.095185     0.082765     0.084917   \n",
       "2015-09-17 10:00:00     0.053519     0.095185     0.082765     0.084917   \n",
       "2015-09-17 12:00:00     0.053519     0.095185     0.082765     0.084917   \n",
       "2015-09-17 14:00:00     0.053519     0.095185     0.082765     0.084917   \n",
       "2015-09-17 16:00:00     0.053519     0.095185     0.082765     0.084917   \n",
       "\n",
       "                     06075023102  06075023103  06075023200  06075023300  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.113262     0.147365     0.186231     0.120469   \n",
       "2015-09-17 10:00:00     0.113262     0.147365     0.186231     0.120469   \n",
       "2015-09-17 12:00:00     0.113262     0.147365     0.186231     0.120469   \n",
       "2015-09-17 14:00:00     0.113262     0.147365     0.186231     0.120469   \n",
       "2015-09-17 16:00:00     0.113262     0.147365     0.186231     0.120469   \n",
       "\n",
       "                     06075023400  06075025100  06075025200  06075025300  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.128209     0.079564     0.112135     0.160015   \n",
       "2015-09-17 10:00:00     0.128209     0.079564     0.112135     0.160015   \n",
       "2015-09-17 12:00:00     0.128209     0.079564     0.112135     0.160015   \n",
       "2015-09-17 14:00:00     0.128209     0.079564     0.112135     0.160015   \n",
       "2015-09-17 16:00:00     0.128209     0.079564     0.112135     0.160015   \n",
       "\n",
       "                     06075025401  06075025402  06075025403  06075025500  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.085764     0.050653     0.085247     0.177404   \n",
       "2015-09-17 10:00:00     0.085764     0.050653     0.085247     0.177404   \n",
       "2015-09-17 12:00:00     0.085764     0.050653     0.085247     0.177404   \n",
       "2015-09-17 14:00:00     0.085764     0.050653     0.085247     0.177404   \n",
       "2015-09-17 16:00:00     0.085764     0.050653     0.085247     0.177404   \n",
       "\n",
       "                     06075025600  06075025701  06075025702  06075025800  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.074889     0.087427     0.109489     0.050102   \n",
       "2015-09-17 10:00:00     0.074889     0.087427     0.109489     0.050102   \n",
       "2015-09-17 12:00:00     0.074889     0.087427     0.109489     0.050102   \n",
       "2015-09-17 14:00:00     0.074889     0.087427     0.109489     0.050102   \n",
       "2015-09-17 16:00:00     0.074889     0.087427     0.109489     0.050102   \n",
       "\n",
       "                     06075025900  06075026001  06075026002  06075026003  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.06743     0.119345     0.066927     0.054143   \n",
       "2015-09-17 10:00:00      0.06743     0.119345     0.066927     0.054143   \n",
       "2015-09-17 12:00:00      0.06743     0.119345     0.066927     0.054143   \n",
       "2015-09-17 14:00:00      0.06743     0.119345     0.066927     0.054143   \n",
       "2015-09-17 16:00:00      0.06743     0.119345     0.066927     0.054143   \n",
       "\n",
       "                     06075026004  06075026100  06075026200  06075026301  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.065293     0.144328     0.078764     0.091914   \n",
       "2015-09-17 10:00:00     0.065293     0.144328     0.078764     0.091914   \n",
       "2015-09-17 12:00:00     0.065293     0.144328     0.078764     0.091914   \n",
       "2015-09-17 14:00:00     0.065293     0.144328     0.078764     0.091914   \n",
       "2015-09-17 16:00:00     0.065293     0.144328     0.078764     0.091914   \n",
       "\n",
       "                     06075026302  06075026303  06075026401  06075026402  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.061875      0.04749     0.058924     0.070556   \n",
       "2015-09-17 10:00:00     0.061875      0.04749     0.058924     0.070556   \n",
       "2015-09-17 12:00:00     0.061875      0.04749     0.058924     0.070556   \n",
       "2015-09-17 14:00:00     0.061875      0.04749     0.058924     0.070556   \n",
       "2015-09-17 16:00:00     0.061875      0.04749     0.058924     0.070556   \n",
       "\n",
       "                     06075026403  06075026404  06075030101  06075030102  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.065606     0.055345     0.090645     0.081829   \n",
       "2015-09-17 10:00:00     0.065606     0.055345     0.090645     0.081829   \n",
       "2015-09-17 12:00:00     0.065606     0.055345     0.090645     0.081829   \n",
       "2015-09-17 14:00:00     0.065606     0.055345     0.090645     0.081829   \n",
       "2015-09-17 16:00:00     0.065606     0.055345     0.090645     0.081829   \n",
       "\n",
       "                     06075030201  06075030202  06075030301  06075030302  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.069899     0.085814     0.083385     0.078677   \n",
       "2015-09-17 10:00:00     0.069899     0.085814     0.083385     0.078677   \n",
       "2015-09-17 12:00:00     0.069899     0.085814     0.083385     0.078677   \n",
       "2015-09-17 14:00:00     0.069899     0.085814     0.083385     0.078677   \n",
       "2015-09-17 16:00:00     0.069899     0.085814     0.083385     0.078677   \n",
       "\n",
       "                     06075030400  06075030500  06075030600  06075030700  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.062289     0.087603     0.069681     0.078481   \n",
       "2015-09-17 10:00:00     0.062289     0.087603     0.069681     0.078481   \n",
       "2015-09-17 12:00:00     0.062289     0.087603     0.069681     0.078481   \n",
       "2015-09-17 14:00:00     0.062289     0.087603     0.069681     0.078481   \n",
       "2015-09-17 16:00:00     0.062289     0.087603     0.069681     0.078481   \n",
       "\n",
       "                     06075030800  06075030900  06075031000  06075031100  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.104192     0.123871     0.072839      0.11032   \n",
       "2015-09-17 10:00:00     0.104192     0.123871     0.072839      0.11032   \n",
       "2015-09-17 12:00:00     0.104192     0.123871     0.072839      0.11032   \n",
       "2015-09-17 14:00:00     0.104192     0.123871     0.072839      0.11032   \n",
       "2015-09-17 16:00:00     0.104192     0.123871     0.072839      0.11032   \n",
       "\n",
       "                     06075031201  06075031202  06075031301  06075031302  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.08828     0.082275     0.088337     0.071536   \n",
       "2015-09-17 10:00:00      0.08828     0.082275     0.088337     0.071536   \n",
       "2015-09-17 12:00:00      0.08828     0.082275     0.088337     0.071536   \n",
       "2015-09-17 14:00:00      0.08828     0.082275     0.088337     0.071536   \n",
       "2015-09-17 16:00:00      0.08828     0.082275     0.088337     0.071536   \n",
       "\n",
       "                     06075031400  06075032601  06075032602  06075032700  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.088664     0.073552     0.041301     0.076077   \n",
       "2015-09-17 10:00:00     0.088664     0.073552     0.041301     0.076077   \n",
       "2015-09-17 12:00:00     0.088664     0.073552     0.041301     0.076077   \n",
       "2015-09-17 14:00:00     0.088664     0.073552     0.041301     0.076077   \n",
       "2015-09-17 16:00:00     0.088664     0.073552     0.041301     0.076077   \n",
       "\n",
       "                     06075032801  06075032802  06075032901  06075032902  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.09277     0.057026     0.052737     0.051463   \n",
       "2015-09-17 10:00:00      0.09277     0.057026     0.052737     0.051463   \n",
       "2015-09-17 12:00:00      0.09277     0.057026     0.052737     0.051463   \n",
       "2015-09-17 14:00:00      0.09277     0.057026     0.052737     0.051463   \n",
       "2015-09-17 16:00:00      0.09277     0.057026     0.052737     0.051463   \n",
       "\n",
       "                     06075033000  06075033100  06075033201  06075033203  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.118503     0.071454     0.122789     0.119352   \n",
       "2015-09-17 10:00:00     0.118503     0.071454     0.122789     0.119352   \n",
       "2015-09-17 12:00:00     0.118503     0.071454     0.122789     0.119352   \n",
       "2015-09-17 14:00:00     0.118503     0.071454     0.122789     0.119352   \n",
       "2015-09-17 16:00:00     0.118503     0.071454     0.122789     0.119352   \n",
       "\n",
       "                     06075033204  06075035100  06075035201  06075035202  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.065162     0.081875     0.058941     0.083706   \n",
       "2015-09-17 10:00:00     0.065162     0.081875     0.058941     0.083706   \n",
       "2015-09-17 12:00:00     0.065162     0.081875     0.058941     0.083706   \n",
       "2015-09-17 14:00:00     0.065162     0.081875     0.058941     0.083706   \n",
       "2015-09-17 16:00:00     0.065162     0.081875     0.058941     0.083706   \n",
       "\n",
       "                     06075035300  06075035400  06075040100  06075040200  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00      0.06389     0.061914     0.063923     0.083577   \n",
       "2015-09-17 10:00:00      0.06389     0.061914     0.063923     0.083577   \n",
       "2015-09-17 12:00:00      0.06389     0.061914     0.063923     0.083577   \n",
       "2015-09-17 14:00:00      0.06389     0.061914     0.063923     0.083577   \n",
       "2015-09-17 16:00:00      0.06389     0.061914     0.063923     0.083577   \n",
       "\n",
       "                     06075042601  06075042602  06075042700  06075042800  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.058742     0.065145     0.055858     0.036256   \n",
       "2015-09-17 10:00:00     0.058742     0.065145     0.055858     0.036256   \n",
       "2015-09-17 12:00:00     0.058742     0.065145     0.055858     0.036256   \n",
       "2015-09-17 14:00:00     0.058742     0.065145     0.055858     0.036256   \n",
       "2015-09-17 16:00:00     0.058742     0.065145     0.055858     0.036256   \n",
       "\n",
       "                     06075045100  06075045200  06075047600  06075047701  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.089036     0.148121     0.078161     0.066101   \n",
       "2015-09-17 10:00:00     0.089036     0.148121     0.078161     0.066101   \n",
       "2015-09-17 12:00:00     0.089036     0.148121     0.078161     0.066101   \n",
       "2015-09-17 14:00:00     0.089036     0.148121     0.078161     0.066101   \n",
       "2015-09-17 16:00:00     0.089036     0.148121     0.078161     0.066101   \n",
       "\n",
       "                     06075047702  06075047801  06075047802  06075047901  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.034408     0.053006     0.063886      0.14492   \n",
       "2015-09-17 10:00:00     0.034408     0.053006     0.063886      0.14492   \n",
       "2015-09-17 12:00:00     0.034408     0.053006     0.063886      0.14492   \n",
       "2015-09-17 14:00:00     0.034408     0.053006     0.063886      0.14492   \n",
       "2015-09-17 16:00:00     0.034408     0.053006     0.063886      0.14492   \n",
       "\n",
       "                     06075047902  06075060100  06075060400  06075060502  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.049501     0.031787     0.094673     0.123552   \n",
       "2015-09-17 10:00:00     0.049501     0.031787     0.094673     0.123552   \n",
       "2015-09-17 12:00:00     0.049501     0.031787     0.094673     0.123552   \n",
       "2015-09-17 14:00:00     0.049501     0.031787     0.094673     0.123552   \n",
       "2015-09-17 16:00:00     0.049501     0.031787     0.094673     0.123552   \n",
       "\n",
       "                     06075060700  06075061000  06075061100  06075061200  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.262894     0.066646     0.181965     0.232893   \n",
       "2015-09-17 10:00:00     0.262894     0.066646     0.181965     0.232893   \n",
       "2015-09-17 12:00:00     0.262894     0.066646     0.181965     0.232893   \n",
       "2015-09-17 14:00:00     0.262894     0.066646     0.181965     0.232893   \n",
       "2015-09-17 16:00:00     0.262894     0.066646     0.181965     0.232893   \n",
       "\n",
       "                     06075061400  06075061500  06075980200  06075980300  \\\n",
       "datetime                                                                  \n",
       "2015-09-17 08:00:00     0.147538     0.595801     0.034729     0.289463   \n",
       "2015-09-17 10:00:00     0.147538     0.595801     0.034729     0.289463   \n",
       "2015-09-17 12:00:00     0.147538     0.595801     0.034729     0.289463   \n",
       "2015-09-17 14:00:00     0.147538     0.595801     0.034729     0.289463   \n",
       "2015-09-17 16:00:00     0.147538     0.595801     0.034729     0.289463   \n",
       "\n",
       "                     06075980501  06075980600  06075980900  \n",
       "datetime                                                    \n",
       "2015-09-17 08:00:00     0.048519     0.043297     0.239947  \n",
       "2015-09-17 10:00:00     0.048519     0.043297     0.239947  \n",
       "2015-09-17 12:00:00     0.048519     0.043297     0.239947  \n",
       "2015-09-17 14:00:00     0.048519     0.043297     0.239947  \n",
       "2015-09-17 16:00:00     0.048519     0.043297     0.239947  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probability of crime occurance\n",
    "y_probs_df = pd.DataFrame(y_test_probs, index=y_datetime, columns=geo_ids)\n",
    "y_probs_df = y_probs_df.loc[(y_probs_df != 0).any(axis=1), :]\n",
    "y_probs_df.to_csv(\"./results/y_probs.csv\", index=True)\n",
    "y_probs_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
