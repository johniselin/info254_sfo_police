{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: sodapy in /anaconda/lib/python2.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: future>=0.17.1 in /anaconda/lib/python2.7/site-packages (from sodapy) (0.17.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /anaconda/lib/python2.7/site-packages (from sodapy) (2.21.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda/lib/python2.7/site-packages (from requests>=2.20.0->sodapy) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/lib/python2.7/site-packages (from requests>=2.20.0->sodapy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/lib/python2.7/site-packages (from requests>=2.20.0->sodapy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/lib/python2.7/site-packages (from requests>=2.20.0->sodapy) (2019.3.9)\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: feather-format in /anaconda/lib/python2.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /anaconda/lib/python2.7/site-packages (from feather-format) (0.13.0)\n",
      "Requirement already satisfied: six>=1.0.0 in /anaconda/lib/python2.7/site-packages (from pyarrow>=0.4.0->feather-format) (1.10.0)\n",
      "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /anaconda/lib/python2.7/site-packages (from pyarrow>=0.4.0->feather-format) (1.1.6)\n",
      "Requirement already satisfied: numpy>=1.14 in /anaconda/lib/python2.7/site-packages (from pyarrow>=0.4.0->feather-format) (1.16.2)\n",
      "Requirement already satisfied: futures; python_version < \"3.2\" in /anaconda/lib/python2.7/site-packages (from pyarrow>=0.4.0->feather-format) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install sodapy\n",
    "!pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "import collections;\n",
    "import re;\n",
    "from time import time\n",
    "import math\n",
    "import feather\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "# Set up Socrata\n",
    "client = Socrata(\"data.sfgov.org\", None)\n",
    "socrata_id_older = \"cuks-n6tp\"\n",
    "socrata_id_newer = \"wg3w-h783\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'IncidntNum',\n",
       " u'Category',\n",
       " u'Descript',\n",
       " u'DayOfWeek',\n",
       " u'Date',\n",
       " u'Time',\n",
       " u'PdDistrict',\n",
       " u'Resolution',\n",
       " u'Address',\n",
       " u'X',\n",
       " u'Y',\n",
       " u'Location',\n",
       " u'Location (address)',\n",
       " u'Location (city)',\n",
       " u'Location (state)',\n",
       " u'Location (zip)',\n",
       " u'PdId',\n",
       " u'SF Find Neighborhoods',\n",
       " u'Current Police Districts',\n",
       " u'Current Supervisor Districts',\n",
       " u'Analysis Neighborhoods',\n",
       " u':@computed_region_yftq_j783',\n",
       " u':@computed_region_p5aj_wyqh',\n",
       " u':@computed_region_rxqg_mtj9',\n",
       " u':@computed_region_bh8s_q3mv',\n",
       " u':@computed_region_fyvs_ahh9',\n",
       " u':@computed_region_9dfj_4gjx',\n",
       " u':@computed_region_n4xg_c4py',\n",
       " u':@computed_region_4isq_27mq',\n",
       " u':@computed_region_fcz8_est8',\n",
       " u':@computed_region_pigm_ib2e',\n",
       " u':@computed_region_9jxd_iqea',\n",
       " u':@computed_region_6pnf_4xz7',\n",
       " u':@computed_region_6ezc_tdp2',\n",
       " u':@computed_region_h4ep_8xdi',\n",
       " u':@computed_region_nqbw_i6c3',\n",
       " u':@computed_region_2dwj_jsy4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Metadata for 2003-2018\n",
    "metadata_old = client.get_metadata(socrata_id_older)\n",
    "[x['name'] for x in metadata_old['columns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Incident Datetime',\n",
       " u'Incident Date',\n",
       " u'Incident Time',\n",
       " u'Incident Year',\n",
       " u'Incident Day of Week',\n",
       " u'Report Datetime',\n",
       " u'Row ID',\n",
       " u'Incident ID',\n",
       " u'Incident Number',\n",
       " u'CAD Number',\n",
       " u'Report Type Code',\n",
       " u'Report Type Description',\n",
       " u'Filed Online',\n",
       " u'Incident Code',\n",
       " u'Incident Category',\n",
       " u'Incident Subcategory',\n",
       " u'Incident Description',\n",
       " u'Resolution',\n",
       " u'Intersection',\n",
       " u'CNN',\n",
       " u'Police District',\n",
       " u'Analysis Neighborhood',\n",
       " u'Supervisor District',\n",
       " u'Latitude',\n",
       " u'Longitude',\n",
       " u'point',\n",
       " u'SF Find Neighborhoods',\n",
       " u'Current Police Districts',\n",
       " u'Current Supervisor Districts',\n",
       " u'Analysis Neighborhoods',\n",
       " u'HSOC Zones as of 2018-06-05',\n",
       " u'OWED Public Spaces',\n",
       " u'Central Market/Tenderloin Boundary Polygon - Updated',\n",
       " u'Parks Alliance CPSI (27+TL sites)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Metadata for 2018-2019\n",
    "metadata_new = client.get_metadata(socrata_id_newer)\n",
    "[x['name'] for x in metadata_new['columns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new = []\n",
    "col_old = []\n",
    "\n",
    "for i in range(len(metadata_new['columns'])):\n",
    "    name = metadata_new['columns'][i]['name']\n",
    "    names = []\n",
    "    names.append(name)\n",
    "    col_new = col_new + names\n",
    "\n",
    "for i in range(len(metadata_old['columns'])):\n",
    "    name = metadata_old['columns'][i]['name']\n",
    "    names = []\n",
    "    names.append(name)\n",
    "    col_old = col_old + names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Loop number: 0\n",
      "\n",
      "> Loop number: 1\n",
      "\n",
      "> Loop number: 2\n",
      "\n",
      "> Loop number: 3\n",
      "\n",
      "> Loop number: 4\n",
      "\n",
      "> Loop number: 5\n",
      "\n",
      "> Loop number: 6\n",
      "\n",
      "> Loop number: 7\n",
      "\n",
      "> Loop number: 8\n",
      "\n",
      "> Loop number: 9\n",
      "\n",
      "> Loop number: 10\n",
      "\n",
      "> Loop number: 11\n",
      "\n",
      "> Loop number: 12\n",
      "\n",
      "> Loop number: 13\n",
      "\n",
      "> Loop number: 14\n",
      "\n",
      "> Loop number: 15\n",
      "\n",
      "> Loop number: 16\n",
      "\n",
      "> Loop number: 17\n",
      "\n",
      "> Loop number: 18\n",
      "\n",
      "> Loop number: 19\n"
     ]
    }
   ],
   "source": [
    "# Import 2018-2019 data via Socrata\n",
    "\n",
    "loop_size = 10000\n",
    "num_loops = 20\n",
    "\n",
    "df_new = pd.DataFrame(columns=col_new)\n",
    "\n",
    "for i in range(num_loops):\n",
    "    results = client.get(socrata_id_newer,\n",
    "                         limit=loop_size,\n",
    "                         offset=loop_size * i)\n",
    "    print(\"\\n> Loop number: {}\".format(i))\n",
    "    df_loop = pd.DataFrame(results)\n",
    "    df_new = pd.concat([df_new,df_loop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Loop number: 0\n",
      "\n",
      "> Loop number: 1\n",
      "\n",
      "> Loop number: 2\n",
      "\n",
      "> Loop number: 3\n",
      "\n",
      "> Loop number: 4\n",
      "\n",
      "> Loop number: 5\n",
      "\n",
      "> Loop number: 6\n",
      "\n",
      "> Loop number: 7\n",
      "\n",
      "> Loop number: 8\n",
      "\n",
      "> Loop number: 9\n",
      "\n",
      "> Loop number: 10\n",
      "\n",
      "> Loop number: 11\n",
      "\n",
      "> Loop number: 12\n",
      "\n",
      "> Loop number: 13\n",
      "\n",
      "> Loop number: 14\n",
      "\n",
      "> Loop number: 15\n",
      "\n",
      "> Loop number: 16\n",
      "\n",
      "> Loop number: 17\n",
      "\n",
      "> Loop number: 18\n",
      "\n",
      "> Loop number: 19\n",
      "\n",
      "> Loop number: 20\n"
     ]
    }
   ],
   "source": [
    "# Import 2003-2018 data via Socrata \n",
    "loop_size = 25000\n",
    "num_loops = 21\n",
    "\n",
    "df_old = pd.DataFrame(columns=col_old)\n",
    "\n",
    "for i in range(num_loops):\n",
    "    results = client.get(socrata_id_older,\n",
    "                         where=\"date_extract_y(Date) > 2014\",\n",
    "                         limit=loop_size,\n",
    "                         offset=loop_size * i)\n",
    "    print(\"\\n> Loop number: {}\".format(i))\n",
    "    df_loop = pd.DataFrame(results)\n",
    "    df_old = pd.concat([df_old,df_loop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data - 2018 to 2019\n",
      "(196894, 67)\n",
      "Index([u':@computed_region_26cr_cadq', u':@computed_region_2dwj_jsy4',\n",
      "       u':@computed_region_6qbp_sg9q', u':@computed_region_ajp5_b2md',\n",
      "       u':@computed_region_h4ep_8xdi', u':@computed_region_nqbw_i6c3',\n",
      "       u':@computed_region_qgnn_b9vv', u':@computed_region_y6ts_4iup',\n",
      "       u'Analysis Neighborhood', u'Analysis Neighborhoods', u'CAD Number',\n",
      "       u'CNN', u'Central Market/Tenderloin Boundary Polygon - Updated',\n",
      "       u'Current Police Districts', u'Current Supervisor Districts',\n",
      "       u'Filed Online', u'HSOC Zones as of 2018-06-05', u'Incident Category',\n",
      "       u'Incident Code', u'Incident Date', u'Incident Datetime',\n",
      "       u'Incident Day of Week', u'Incident Description', u'Incident ID',\n",
      "       u'Incident Number', u'Incident Subcategory', u'Incident Time',\n",
      "       u'Incident Year', u'Intersection', u'Latitude', u'Longitude',\n",
      "       u'OWED Public Spaces', u'Parks Alliance CPSI (27+TL sites)',\n",
      "       u'Police District', u'Report Datetime', u'Report Type Code',\n",
      "       u'Report Type Description', u'Resolution', u'Row ID',\n",
      "       u'SF Find Neighborhoods', u'Supervisor District',\n",
      "       u'analysis_neighborhood', u'cad_number', u'cnn', u'filed_online',\n",
      "       u'incident_category', u'incident_code', u'incident_date',\n",
      "       u'incident_datetime', u'incident_day_of_week', u'incident_description',\n",
      "       u'incident_id', u'incident_number', u'incident_subcategory',\n",
      "       u'incident_time', u'incident_year', u'intersection', u'latitude',\n",
      "       u'longitude', u'point', u'police_district', u'report_datetime',\n",
      "       u'report_type_code', u'report_type_description', u'resolution',\n",
      "       u'row_id', u'supervisor_district'],\n",
      "      dtype='object')\n",
      "Data - 2014 to 2018\n",
      "(508850, 50)\n",
      "Index([u':@computed_region_2dwj_jsy4', u':@computed_region_4isq_27mq',\n",
      "       u':@computed_region_6ezc_tdp2', u':@computed_region_6pnf_4xz7',\n",
      "       u':@computed_region_9dfj_4gjx', u':@computed_region_9jxd_iqea',\n",
      "       u':@computed_region_bh8s_q3mv', u':@computed_region_fcz8_est8',\n",
      "       u':@computed_region_fyvs_ahh9', u':@computed_region_h4ep_8xdi',\n",
      "       u':@computed_region_n4xg_c4py', u':@computed_region_nqbw_i6c3',\n",
      "       u':@computed_region_p5aj_wyqh', u':@computed_region_pigm_ib2e',\n",
      "       u':@computed_region_rxqg_mtj9', u':@computed_region_yftq_j783',\n",
      "       u'Address', u'Analysis Neighborhoods', u'Category',\n",
      "       u'Current Police Districts', u'Current Supervisor Districts', u'Date',\n",
      "       u'DayOfWeek', u'Descript', u'IncidntNum', u'Location',\n",
      "       u'Location (address)', u'Location (city)', u'Location (state)',\n",
      "       u'Location (zip)', u'PdDistrict', u'PdId', u'Resolution',\n",
      "       u'SF Find Neighborhoods', u'Time', u'X', u'Y', u'address', u'category',\n",
      "       u'date', u'dayofweek', u'descript', u'incidntnum', u'location',\n",
      "       u'pddistrict', u'pdid', u'resolution', u'time', u'x', u'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Data - 2018 to 2019\")\n",
    "print(df_new.shape)\n",
    "print(df_new.columns)\n",
    "\n",
    "print(\"Data - 2014 to 2018\")\n",
    "print(df_old.shape)\n",
    "print(df_old.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data cleaning - keep variables in df_new\n",
    "\n",
    "df_new = df_new[['incident_category', 'incident_date', \n",
    "                 'incident_day_of_week', 'incident_description', 'incident_number',\n",
    "                 'incident_time', 'latitude', 'longitude', 'police_district']]\n",
    "\n",
    "df_new = df_new.rename(columns={'incident_day_of_week': 'incident_dow'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u':@computed_region_2dwj_jsy4', u':@computed_region_4isq_27mq',\n",
      "       u':@computed_region_6ezc_tdp2', u':@computed_region_6pnf_4xz7',\n",
      "       u':@computed_region_9dfj_4gjx', u':@computed_region_9jxd_iqea',\n",
      "       u':@computed_region_bh8s_q3mv', u':@computed_region_fcz8_est8',\n",
      "       u':@computed_region_fyvs_ahh9', u':@computed_region_h4ep_8xdi',\n",
      "       u':@computed_region_n4xg_c4py', u':@computed_region_nqbw_i6c3',\n",
      "       u':@computed_region_p5aj_wyqh', u':@computed_region_pigm_ib2e',\n",
      "       u':@computed_region_rxqg_mtj9', u':@computed_region_yftq_j783',\n",
      "       u'Address', u'Analysis Neighborhoods', u'Category',\n",
      "       u'Current Police Districts', u'Current Supervisor Districts', u'Date',\n",
      "       u'DayOfWeek', u'Descript', u'IncidntNum', u'Location',\n",
      "       u'Location (address)', u'Location (city)', u'Location (state)',\n",
      "       u'Location (zip)', u'PdDistrict', u'PdId', u'Resolution',\n",
      "       u'SF Find Neighborhoods', u'Time', u'X', u'Y', u'address', u'category',\n",
      "       u'date', u'dayofweek', u'descript', u'incidntnum', u'location',\n",
      "       u'pddistrict', u'pdid', u'resolution', u'time', u'x', u'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_old.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data cleaning - keep variables in df_old\n",
    "\n",
    "df_old = df_old[['category', 'date', 'dayofweek', 'descript', 'incidntnum', 'time', 'x', 'y', 'pddistrict']]\n",
    "\n",
    "df_old = df_old.rename(columns={\n",
    "        'category': 'incident_category',\n",
    "        'date': 'incident_date',\n",
    "        'dayofweek': 'incident_dow',\n",
    "        'descript':'incident_description',\n",
    "        'incidntnum': 'incident_number',\n",
    "        'time': 'incident_time',\n",
    "        'x': 'latitude',\n",
    "        'y': 'longitude',\n",
    "        'pddistrict': 'police_district'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015-01-15T00:00:00.000\n",
       "1    2015-05-02T00:00:00.000\n",
       "2    2018-03-20T00:00:00.000\n",
       "3    2016-06-03T00:00:00.000\n",
       "4    2015-02-03T00:00:00.000\n",
       "Name: incident_date, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.incident_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format Dates, dealing with different formats\n",
    "# 1) create new column temp_date and store there datetimes recognized using first format\n",
    "df_new['temp_date'] = pd.to_datetime(df_new['incident_date'], format='%Y/%m/%d', errors='coerce')\n",
    "# 2) get not recognized rows\n",
    "not_recongized = df_new[df_new.temp_date.isnull()]\n",
    "# 3) inplace fill not recognized rows with values recognized using second format\n",
    "df_new['temp_date'].fillna(pd.to_datetime(not_recongized['incident_date'], format='%Y/%m/%d', errors='coerce'), inplace=True)\n",
    "\n",
    "# 4) delete starttime column\n",
    "del df_new['incident_date']\n",
    "# 5) inplace rename temp_starttime to starttime\n",
    "df_new.rename(columns={\"temp_date\": \"incident_date\"}, inplace=True)\n",
    "\n",
    "df_new['incident_date'] = pd.to_datetime(df_new['incident_date'],format='%m/%d/%Y') \n",
    "\n",
    "df_old['incident_date'] = df_old.incident_date.str.slice(0, 10)\n",
    "df_old['incident_date'] = pd.to_datetime(df_old['incident_date'],format='%Y/%m/%d') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508850\n",
      "196894\n",
      "(705744, 9)\n",
      "     incident_category incident_date               incident_description  \\\n",
      "0  Other Miscellaneous    2018-12-02      Burglary Tools, Possession Of   \n",
      "1        Lost Property    2018-12-01                      Lost Property   \n",
      "2              Assault    2019-03-18                            Battery   \n",
      "3        Larceny Theft    2019-03-20  Theft, From Locked Vehicle, >$950   \n",
      "4        Larceny Theft    2019-03-12    Theft, Other Property, $50-$200   \n",
      "\n",
      "  incident_dow incident_number incident_time            latitude  \\\n",
      "0       Sunday       180908554         00:45  37.784908299430455   \n",
      "1     Saturday       180908112         20:30   37.78640961281089   \n",
      "2       Monday       190194129         14:01   37.75683373380551   \n",
      "3    Wednesday       190199583         08:00  37.784006612420036   \n",
      "4      Tuesday       196055103         13:30                 NaN   \n",
      "\n",
      "             longitude police_district  \n",
      "0  -122.40479506275997        Southern  \n",
      "1  -122.40803623744476         Central  \n",
      "2  -122.40669900268833         Mission  \n",
      "3  -122.40486479517743        Southern  \n",
      "4                  NaN         Central  \n"
     ]
    }
   ],
   "source": [
    "## Merge incident data\n",
    "print(len(df_old))\n",
    "print(len(df_new))\n",
    "df_incident = pd.concat([df_new, df_old])\n",
    "\n",
    "print(df_incident.shape)\n",
    "print(df_incident.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new meta-crime categories\n",
    "\n",
    "df_incident['incident_category'] = df_incident['incident_category'].str.lower()\n",
    "\n",
    "viol = ['assault','homicide','rape','forcible']\n",
    "prop = ['larceny theft','larceny/theft','motor vehicle theft','motor vehicle theft','motor vehicle theft?'\n",
    "        'vehicle theft','burglary', 'robbery','stolen property', 'arson']\n",
    "df_incident['incident_type'] = 'other'\n",
    " \n",
    "for i in viol: \n",
    "    df_incident['incident_type'] = np.where(df_incident['incident_category'] == i, 'violent', df_incident['incident_type'])\n",
    "    \n",
    "for i in prop: \n",
    "    df_incident['incident_type'] = np.where(df_incident['incident_category'] == i, 'property', df_incident['incident_type'])\n",
    "    \n",
    "df_incident['incident_type'].describe()\n",
    "\n",
    "df_incident = df_incident.drop(['incident_category','incident_description', 'police_district'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_date          0\n",
      "incident_dow           0\n",
      "incident_number        0\n",
      "incident_time          0\n",
      "latitude           10378\n",
      "longitude          10378\n",
      "incident_type          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Drop if missing\n",
    "print(df_incident.isnull().sum())\n",
    "df_incident = df_incident.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feather.write_dataframe(df_incident, 'data/sf_incidents.feather')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
