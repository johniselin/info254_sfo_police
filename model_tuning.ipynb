{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import math\n",
    "import feather\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "# from tqdm import tqdm\n",
    "import optuna\n",
    "from optuna.integration import KerasPruningCallback\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "#Using keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#from scripts.utils import load_rnn_data\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# validation\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, log_loss\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "# others\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rnn_data(path, window, predict_ts, isdim3=True, geo_col=[\"geoid10_tract\"], y_cols=[\"crime\"]):\n",
    "    \"\"\"\n",
    "    y_cols: [\"crime\"] or [\"incident_type_0\", \"incident_type_1\", \"incident_type_2\"]\n",
    "    geo_col: [\"geoid10_tract\"] or [\"geoid10_block\"]\n",
    "    return y_all and x_all of given path\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    df = feather.read_dataframe(path)\n",
    "    df.sort_values(by=[\"datetime\", \"geoid10_tract\"], inplace=True)\n",
    "    df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # input columns\n",
    "    x_cols = list(df.drop(y_cols + geo_col, axis=1).columns)\n",
    "\n",
    "    # group by geoid\n",
    "    geo_grs = df.groupby(by=geo_col)\n",
    "\n",
    "    # arrayes to store x and y\n",
    "    # (no of timesteps, window size, no of tracts,  no of features, )\n",
    "    n_timesteps = int(len(df) / len(geo_grs)) - window - predict_ts + 1\n",
    "    x_all = np.empty(shape=(n_timesteps, window, len(geo_grs), len(x_cols + y_cols)))\n",
    "\n",
    "    # (output size, no of tracts, no of outputs)\n",
    "    y_all = np.empty(shape=(n_timesteps, len(geo_grs), len(y_cols)))\n",
    "\n",
    "    # to store geo_ids and y_all's datetime\n",
    "    geo_ids = []\n",
    "\n",
    "    y_datetime = df.index.unique()[window + predict_ts - 1:]\n",
    "\n",
    "    for i, (geo_id, gr) in enumerate(geo_grs):\n",
    "        geo_ids.append(geo_id)\n",
    "        x_values = gr[y_cols + x_cols].values\n",
    "        y_values = gr[y_cols].values\n",
    "\n",
    "        for j in range(window, len(gr) - predict_ts + 1):\n",
    "            # generate x_all\n",
    "            x_all[j - window, :, i, :] = x_values[j - window:j, :]\n",
    "            y_all[j - window, i, :] = y_values[j + predict_ts - 1, :]\n",
    "\n",
    "    if isdim3:\n",
    "        x_all = np.reshape(x_all,\n",
    "                           newshape=(x_all.shape[0], x_all.shape[1], x_all.shape[2] * x_all.shape[3]))\n",
    "        y_all = np.reshape(y_all,\n",
    "                           newshape=(y_all.shape[0], y_all.shape[1] * y_all.shape[2]))\n",
    "\n",
    "    return x_all, y_all, geo_ids, y_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configuration\n",
    "path = \"./features/features_binary_tract_2H.feather\"\n",
    "window = 12\n",
    "predict_ts = 1  # how many timesteps future does the model predict? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as x and y of RNN\n",
    "x_all, y_all, geo_ids, y_datetime = load_rnn_data(path=path,\n",
    "                                                  window=window,\n",
    "                                                  predict_ts=predict_ts,\n",
    "                                                  isdim3=True,\n",
    "                                                  geo_col=[\"geoid10_tract\"],\n",
    "                                                  y_cols=[\"crime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 12, 1560)\n",
      "(18600, 195)\n",
      "195\n",
      "18600\n"
     ]
    }
   ],
   "source": [
    "print(x_all.shape)\n",
    "print(y_all.shape)\n",
    "print(len(geo_ids))  # to convert model output later\n",
    "print(len(y_datetime))  # to convert model output later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "see https://github.com/pfnet/optuna/blob/master/examples/pruning/keras_integration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 128\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial, x_train, y_train):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "    \n",
    "    \n",
    "    # We define our MLP.\n",
    "#     n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    #Hitting the first error above - how do we get the time series code to feed an example of \n",
    "#     for i in range(n_layers):\n",
    "#         num_hidden = int(trial.suggest_loguniform('n_units_l{}'.format(i), 4, BATCHSIZE))\n",
    "#         model.add(Dense(num_hidden, activation='sigmoid'))\n",
    "    dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to define this to produce a training and test sample\n",
    "def splitting(x_all, y_all):\n",
    "    # create train and test set\n",
    "    split = int(x_all.shape[0] * 0.8)   \n",
    "    x_train = x_all[:split]\n",
    "    y_train = y_all[:split]\n",
    "    x_test = x_all[split:]\n",
    "    y_test = y_all[split:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split = int(len(x_all) * 0.8)    \n",
    "#x_train = x_all[:split]\n",
    "#y_train = x_all[:split]\n",
    "#x_test = x_all[split:]\n",
    "#y_test = x_all[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Clear clutter form previous session graphs.\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # time series split\n",
    "    x_train, y_train, x_test, y_test = splitting(x_all, y_all) \n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial, x_train, y_train)\n",
    "\n",
    "    earlystopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "    \n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=BATCHSIZE,\n",
    "              callbacks=[KerasPruningCallback(trial, 'val_acc'), earlystopping],\n",
    "              epochs=EPOCHS,\n",
    "              validation_split=0.2,\n",
    "              shuffle=False,\n",
    "              verbose=1)\n",
    "    # Evaluate the model accuracy on the test set.\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11904 samples, validate on 2976 samples\n",
      "Epoch 1/200\n",
      " 4480/11904 [==========>...................] - ETA: 1:41 - loss: 0.6915 - acc: 0.539 - ETA: 1:01 - loss: 0.6521 - acc: 0.613 - ETA: 47s - loss: 0.6120 - acc: 0.681 - ETA: 40s - loss: 0.5752 - acc: 0.73 - ETA: 36s - loss: 0.5449 - acc: 0.76 - ETA: 33s - loss: 0.5188 - acc: 0.78 - ETA: 31s - loss: 0.4970 - acc: 0.79 - ETA: 29s - loss: 0.4783 - acc: 0.80 - ETA: 28s - loss: 0.4629 - acc: 0.81 - ETA: 27s - loss: 0.4497 - acc: 0.82 - ETA: 26s - loss: 0.4389 - acc: 0.82 - ETA: 25s - loss: 0.4310 - acc: 0.83 - ETA: 24s - loss: 0.4242 - acc: 0.83 - ETA: 23s - loss: 0.4192 - acc: 0.84 - ETA: 23s - loss: 0.4141 - acc: 0.84 - ETA: 22s - loss: 0.4088 - acc: 0.84 - ETA: 22s - loss: 0.4049 - acc: 0.84 - ETA: 21s - loss: 0.4012 - acc: 0.85 - ETA: 21s - loss: 0.3973 - acc: 0.85 - ETA: 20s - loss: 0.3937 - acc: 0.85 - ETA: 20s - loss: 0.3904 - acc: 0.85 - ETA: 19s - loss: 0.3865 - acc: 0.85 - ETA: 19s - loss: 0.3769 - acc: 0.86 - ETA: 19s - loss: 0.3678 - acc: 0.86 - ETA: 18s - loss: 0.3640 - acc: 0.86 - ETA: 18s - loss: 0.3566 - acc: 0.87 - ETA: 18s - loss: 0.3496 - acc: 0.87 - ETA: 17s - loss: 0.3487 - acc: 0.87 - ETA: 17s - loss: 0.3479 - acc: 0.87 - ETA: 17s - loss: 0.3467 - acc: 0.87 - ETA: 16s - loss: 0.3399 - acc: 0.87 - ETA: 16s - loss: 0.3348 - acc: 0.88 - ETA: 16s - loss: 0.3335 - acc: 0.88 - ETA: 16s - loss: 0.3325 - acc: 0.88 - ETA: 15s - loss: 0.3305 - acc: 0.8840"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dd1b2aeea573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                             \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                            )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Setting trial status as {}. {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-ceefc82eefe6>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Evaluate the model accuracy on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "np.random.seed(0)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "rn.seed(0)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(0)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            pruner=optuna.pruners.MedianPruner()\n",
    "                           )\n",
    "study.optimize(objective, n_trials=100)\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trials.value)\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
