{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import math\n",
    "import feather\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import optuna\n",
    "from optuna.integration import KerasPruningCallback\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "#Using keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#from scripts.utils import load_rnn_data\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# validation\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, log_loss\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "# others\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rnn_data(path, window, predict_ts, isdim3=True, geo_col=[\"geoid10_tract\"], y_cols=[\"crime\"]):\n",
    "    \"\"\"\n",
    "    y_cols: [\"crime\"] or [\"incident_type_0\", \"incident_type_1\", \"incident_type_2\"]\n",
    "    geo_col: [\"geoid10_tract\"] or [\"geoid10_block\"]\n",
    "    return y_all and x_all of given path\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    df = feather.read_dataframe(path)\n",
    "    df.sort_values(by=[\"datetime\", \"geoid10_tract\"], inplace=True)\n",
    "    df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # input columns\n",
    "    x_cols = list(df.drop(y_cols + geo_col, axis=1).columns)\n",
    "\n",
    "    # group by geoid\n",
    "    geo_grs = df.groupby(by=geo_col)\n",
    "\n",
    "    # arrayes to store x and y\n",
    "    # (no of timesteps, window size, no of tracts,  no of features, )\n",
    "    n_timesteps = int(len(df) / len(geo_grs)) - window - predict_ts + 1\n",
    "    x_all = np.empty(shape=(n_timesteps, window, len(geo_grs), len(x_cols + y_cols)))\n",
    "\n",
    "    # (output size, no of tracts, no of outputs)\n",
    "    y_all = np.empty(shape=(n_timesteps, len(geo_grs), len(y_cols)))\n",
    "\n",
    "    # to store geo_ids and y_all's datetime\n",
    "    geo_ids = []\n",
    "\n",
    "    y_datetime = df.index.unique()[window + predict_ts - 1:]\n",
    "\n",
    "    for i, (geo_id, gr) in enumerate(tqdm(geo_grs)):\n",
    "        geo_ids.append(geo_id)\n",
    "        x_values = gr[y_cols + x_cols].values\n",
    "        y_values = gr[y_cols].values\n",
    "\n",
    "        for j in range(window, len(gr) - predict_ts + 1):\n",
    "            # generate x_all\n",
    "            x_all[j - window, :, i, :] = x_values[j - window:j, :]\n",
    "            y_all[j - window, i, :] = y_values[j + predict_ts - 1, :]\n",
    "\n",
    "    if isdim3:\n",
    "        x_all = np.reshape(x_all,\n",
    "                           newshape=(x_all.shape[0], x_all.shape[1], x_all.shape[2] * x_all.shape[3]))\n",
    "        y_all = np.reshape(y_all,\n",
    "                           newshape=(y_all.shape[0], y_all.shape[1] * y_all.shape[2]))\n",
    "\n",
    "    return x_all, y_all, geo_ids, y_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configuration\n",
    "path = \"./features/features_binary_tract_2H.feather\"\n",
    "window = 12\n",
    "predict_ts = 1  # how many timesteps future does the model predict? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6177f97e8a4d48a2154489b05b737e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=195), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data as x and y of RNN\n",
    "x_all, y_all, geo_ids, y_datetime = load_rnn_data(path=path,\n",
    "                                                  window=window,\n",
    "                                                  predict_ts=predict_ts,\n",
    "                                                  isdim3=True,\n",
    "                                                  geo_col=[\"geoid10_tract\"],\n",
    "                                                  y_cols=[\"crime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 12, 1560)\n",
      "(18600, 195)\n",
      "195\n",
      "18600\n"
     ]
    }
   ],
   "source": [
    "print(x_all.shape)\n",
    "print(y_all.shape)\n",
    "print(len(geo_ids))  # to convert model output later\n",
    "print(len(y_datetime))  # to convert model output later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "see https://github.com/pfnet/optuna/blob/master/examples/pruning/keras_integration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(0)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "rn.seed(0)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(0)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    #Hitting the first error above - how do we get the time series code to feed an example of \n",
    "    for i in range(n_layers):\n",
    "        num_hidden = int(trial.suggest_loguniform('n_units_l{}'.format(i), 4, 128))\n",
    "        model.add(Dense(num_hidden, activation='sigmoid'))\n",
    "        dropout = trial.suggest_uniform('dropout_l{}'.format(i), 0.2, 0.5)\n",
    "        model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=y_train.shape[1], activation='softmax'))   \n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to define this to produce a training and test sample\n",
    "\n",
    "def splitting(data = x_all):\n",
    "    # create train and test set\n",
    "    split = int(len(x_all) * 0.8)    \n",
    "    x_train = x_all[:split]\n",
    "    y_train = y_all[:split]\n",
    "    x_test = x_all[split:]\n",
    "    y_test = y_all[split:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Clear clutter form previous session graphs.\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # time series split\n",
    "    x_train, y_train, x_test, y_test = splitting(data = x_all)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=BATCHSIZE,\n",
    "              callbacks=[KerasPruningCallback(trial, 'val_acc')],\n",
    "              epochs=EPOCHS,\n",
    "              validation_split=0.2,\n",
    "              verbose=1)\n",
    "    # Evaluate the model accuracy on the test set.\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11904 samples, validate on 2976 samples\n",
      "Epoch 1/20\n",
      "11904/11904 [==============================] - ETA: 2:05 - loss: 97.2478 - acc: 0.00 - ETA: 1:17 - loss: 97.2913 - acc: 0.01 - ETA: 1:00 - loss: 97.3595 - acc: 0.01 - ETA: 53s - loss: 95.6150 - acc: 0.0215 - ETA: 47s - loss: 94.1753 - acc: 0.018 - ETA: 43s - loss: 93.3588 - acc: 0.018 - ETA: 40s - loss: 92.7684 - acc: 0.017 - ETA: 38s - loss: 91.7616 - acc: 0.019 - ETA: 36s - loss: 91.5565 - acc: 0.018 - ETA: 35s - loss: 91.5588 - acc: 0.018 - ETA: 33s - loss: 91.8941 - acc: 0.019 - ETA: 32s - loss: 92.7195 - acc: 0.019 - ETA: 31s - loss: 93.7106 - acc: 0.021 - ETA: 30s - loss: 93.2535 - acc: 0.020 - ETA: 29s - loss: 93.3420 - acc: 0.022 - ETA: 29s - loss: 93.2613 - acc: 0.022 - ETA: 28s - loss: 93.1429 - acc: 0.022 - ETA: 28s - loss: 93.0122 - acc: 0.023 - ETA: 27s - loss: 92.8556 - acc: 0.023 - ETA: 27s - loss: 93.2146 - acc: 0.023 - ETA: 26s - loss: 93.1098 - acc: 0.025 - ETA: 26s - loss: 93.0124 - acc: 0.025 - ETA: 25s - loss: 93.1295 - acc: 0.024 - ETA: 25s - loss: 93.2507 - acc: 0.025 - ETA: 24s - loss: 93.1729 - acc: 0.025 - ETA: 24s - loss: 93.3810 - acc: 0.025 - ETA: 24s - loss: 93.3408 - acc: 0.025 - ETA: 23s - loss: 93.2945 - acc: 0.026 - ETA: 23s - loss: 93.2772 - acc: 0.027 - ETA: 22s - loss: 93.0790 - acc: 0.027 - ETA: 22s - loss: 92.9912 - acc: 0.028 - ETA: 21s - loss: 93.1223 - acc: 0.028 - ETA: 21s - loss: 93.2873 - acc: 0.029 - ETA: 20s - loss: 93.3110 - acc: 0.029 - ETA: 20s - loss: 93.3516 - acc: 0.030 - ETA: 20s - loss: 93.1888 - acc: 0.030 - ETA: 19s - loss: 93.3115 - acc: 0.031 - ETA: 19s - loss: 93.4172 - acc: 0.031 - ETA: 18s - loss: 93.5035 - acc: 0.032 - ETA: 18s - loss: 93.4854 - acc: 0.032 - ETA: 18s - loss: 93.5225 - acc: 0.032 - ETA: 17s - loss: 93.6428 - acc: 0.032 - ETA: 17s - loss: 93.5944 - acc: 0.033 - ETA: 17s - loss: 93.5082 - acc: 0.033 - ETA: 16s - loss: 93.3154 - acc: 0.033 - ETA: 16s - loss: 93.2863 - acc: 0.034 - ETA: 16s - loss: 93.2137 - acc: 0.034 - ETA: 15s - loss: 93.1529 - acc: 0.035 - ETA: 15s - loss: 93.0741 - acc: 0.035 - ETA: 14s - loss: 93.0072 - acc: 0.035 - ETA: 14s - loss: 92.9134 - acc: 0.035 - ETA: 14s - loss: 92.8525 - acc: 0.036 - ETA: 13s - loss: 92.7672 - acc: 0.036 - ETA: 13s - loss: 92.9094 - acc: 0.036 - ETA: 13s - loss: 92.9093 - acc: 0.037 - ETA: 12s - loss: 92.9778 - acc: 0.038 - ETA: 12s - loss: 92.9056 - acc: 0.038 - ETA: 12s - loss: 92.9569 - acc: 0.039 - ETA: 11s - loss: 92.9481 - acc: 0.040 - ETA: 11s - loss: 92.9272 - acc: 0.040 - ETA: 10s - loss: 92.9958 - acc: 0.040 - ETA: 10s - loss: 92.8379 - acc: 0.040 - ETA: 10s - loss: 92.7978 - acc: 0.041 - ETA: 9s - loss: 92.7250 - acc: 0.041 - ETA: 9s - loss: 92.7482 - acc: 0.04 - ETA: 9s - loss: 92.8241 - acc: 0.04 - ETA: 8s - loss: 92.8142 - acc: 0.04 - ETA: 8s - loss: 92.8418 - acc: 0.04 - ETA: 8s - loss: 92.7889 - acc: 0.04 - ETA: 7s - loss: 92.7339 - acc: 0.04 - ETA: 7s - loss: 92.8051 - acc: 0.04 - ETA: 7s - loss: 92.8347 - acc: 0.04 - ETA: 6s - loss: 92.9275 - acc: 0.04 - ETA: 6s - loss: 92.9759 - acc: 0.04 - ETA: 6s - loss: 93.0462 - acc: 0.04 - ETA: 5s - loss: 93.0450 - acc: 0.04 - ETA: 5s - loss: 93.0384 - acc: 0.04 - ETA: 5s - loss: 93.0520 - acc: 0.04 - ETA: 4s - loss: 92.9192 - acc: 0.04 - ETA: 4s - loss: 92.9174 - acc: 0.04 - ETA: 4s - loss: 92.8472 - acc: 0.04 - ETA: 3s - loss: 92.9234 - acc: 0.04 - ETA: 3s - loss: 92.8909 - acc: 0.04 - ETA: 3s - loss: 93.0120 - acc: 0.05 - ETA: 2s - loss: 92.9983 - acc: 0.05 - ETA: 2s - loss: 92.9441 - acc: 0.05 - ETA: 2s - loss: 92.9402 - acc: 0.05 - ETA: 1s - loss: 92.9985 - acc: 0.05 - ETA: 1s - loss: 92.9887 - acc: 0.05 - ETA: 1s - loss: 92.9687 - acc: 0.05 - ETA: 0s - loss: 92.9915 - acc: 0.05 - ETA: 0s - loss: 93.0183 - acc: 0.05 - 36s 3ms/step - loss: 93.0636 - acc: 0.0535 - val_loss: 102.6931 - val_acc: 0.1079\n",
      "Epoch 2/20\n",
      "11904/11904 [==============================] - ETA: 29s - loss: 99.8636 - acc: 0.117 - ETA: 31s - loss: 99.0428 - acc: 0.101 - ETA: 31s - loss: 95.6040 - acc: 0.099 - ETA: 30s - loss: 91.9312 - acc: 0.089 - ETA: 29s - loss: 92.2235 - acc: 0.100 - ETA: 28s - loss: 92.0328 - acc: 0.101 - ETA: 27s - loss: 92.2377 - acc: 0.097 - ETA: 27s - loss: 91.5166 - acc: 0.098 - ETA: 26s - loss: 90.8321 - acc: 0.098 - ETA: 26s - loss: 90.7715 - acc: 0.098 - ETA: 26s - loss: 91.0927 - acc: 0.095 - ETA: 25s - loss: 91.4061 - acc: 0.093 - ETA: 25s - loss: 91.0338 - acc: 0.090 - ETA: 24s - loss: 91.2482 - acc: 0.092 - ETA: 24s - loss: 91.1068 - acc: 0.091 - ETA: 24s - loss: 90.9853 - acc: 0.090 - ETA: 23s - loss: 91.3636 - acc: 0.097 - ETA: 23s - loss: 91.5626 - acc: 0.100 - ETA: 23s - loss: 91.2158 - acc: 0.101 - ETA: 23s - loss: 91.3786 - acc: 0.102 - ETA: 23s - loss: 91.2301 - acc: 0.099 - ETA: 23s - loss: 91.3060 - acc: 0.100 - ETA: 22s - loss: 91.2813 - acc: 0.098 - ETA: 22s - loss: 90.9525 - acc: 0.098 - ETA: 22s - loss: 90.9705 - acc: 0.098 - ETA: 22s - loss: 91.0091 - acc: 0.097 - ETA: 22s - loss: 91.3321 - acc: 0.097 - ETA: 21s - loss: 91.4068 - acc: 0.099 - ETA: 21s - loss: 91.5937 - acc: 0.099 - ETA: 21s - loss: 91.5741 - acc: 0.100 - ETA: 20s - loss: 91.5537 - acc: 0.101 - ETA: 20s - loss: 91.4921 - acc: 0.101 - ETA: 20s - loss: 91.3470 - acc: 0.101 - ETA: 19s - loss: 91.2919 - acc: 0.101 - ETA: 19s - loss: 91.2434 - acc: 0.100 - ETA: 19s - loss: 91.2244 - acc: 0.102 - ETA: 18s - loss: 91.1389 - acc: 0.102 - ETA: 18s - loss: 91.0947 - acc: 0.101 - ETA: 18s - loss: 91.1569 - acc: 0.101 - ETA: 17s - loss: 90.9953 - acc: 0.101 - ETA: 17s - loss: 91.1239 - acc: 0.101 - ETA: 17s - loss: 91.0795 - acc: 0.101 - ETA: 16s - loss: 91.2197 - acc: 0.102 - ETA: 16s - loss: 91.2731 - acc: 0.102 - ETA: 16s - loss: 91.2830 - acc: 0.103 - ETA: 15s - loss: 91.3732 - acc: 0.103 - ETA: 15s - loss: 91.3715 - acc: 0.102 - ETA: 15s - loss: 91.4700 - acc: 0.103 - ETA: 14s - loss: 91.4745 - acc: 0.104 - ETA: 14s - loss: 91.4231 - acc: 0.105 - ETA: 14s - loss: 91.3886 - acc: 0.105 - ETA: 14s - loss: 91.3119 - acc: 0.105 - ETA: 13s - loss: 91.0757 - acc: 0.105 - ETA: 13s - loss: 91.1166 - acc: 0.105 - ETA: 13s - loss: 90.8850 - acc: 0.105 - ETA: 12s - loss: 90.9482 - acc: 0.105 - ETA: 12s - loss: 90.9968 - acc: 0.105 - ETA: 12s - loss: 91.0384 - acc: 0.105 - ETA: 11s - loss: 91.0954 - acc: 0.105 - ETA: 11s - loss: 91.2858 - acc: 0.105 - ETA: 11s - loss: 91.3862 - acc: 0.105 - ETA: 10s - loss: 91.3359 - acc: 0.105 - ETA: 10s - loss: 91.4201 - acc: 0.105 - ETA: 10s - loss: 91.3929 - acc: 0.106 - ETA: 9s - loss: 91.3322 - acc: 0.106 - ETA: 9s - loss: 91.4803 - acc: 0.10 - ETA: 8s - loss: 91.4968 - acc: 0.10 - ETA: 8s - loss: 91.5279 - acc: 0.10 - ETA: 8s - loss: 91.5082 - acc: 0.10 - ETA: 7s - loss: 91.5453 - acc: 0.10 - ETA: 7s - loss: 91.5432 - acc: 0.10 - ETA: 7s - loss: 91.4843 - acc: 0.10 - ETA: 6s - loss: 91.5368 - acc: 0.10 - ETA: 6s - loss: 91.5604 - acc: 0.11 - ETA: 6s - loss: 91.5300 - acc: 0.11 - ETA: 5s - loss: 91.5297 - acc: 0.11 - ETA: 5s - loss: 91.5393 - acc: 0.11 - ETA: 5s - loss: 91.5904 - acc: 0.11 - ETA: 4s - loss: 91.6498 - acc: 0.11 - ETA: 4s - loss: 91.7001 - acc: 0.11 - ETA: 4s - loss: 91.6571 - acc: 0.11 - ETA: 3s - loss: 91.6752 - acc: 0.11 - ETA: 3s - loss: 91.8085 - acc: 0.11 - ETA: 3s - loss: 91.8040 - acc: 0.11 - ETA: 2s - loss: 91.8152 - acc: 0.11 - ETA: 2s - loss: 91.8588 - acc: 0.11 - ETA: 2s - loss: 91.7889 - acc: 0.11 - ETA: 1s - loss: 91.8102 - acc: 0.11 - ETA: 1s - loss: 91.7863 - acc: 0.11 - ETA: 1s - loss: 91.8099 - acc: 0.11 - ETA: 0s - loss: 91.7903 - acc: 0.11 - ETA: 0s - loss: 91.7514 - acc: 0.11 - 36s 3ms/step - loss: 91.7264 - acc: 0.1151 - val_loss: 101.1314 - val_acc: 0.3821\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 34s - loss: 86.1477 - acc: 0.156 - ETA: 34s - loss: 89.8247 - acc: 0.132 - ETA: 33s - loss: 88.0889 - acc: 0.145 - ETA: 33s - loss: 88.3531 - acc: 0.140 - ETA: 33s - loss: 88.3984 - acc: 0.139 - ETA: 32s - loss: 89.0256 - acc: 0.140 - ETA: 31s - loss: 88.7680 - acc: 0.139 - ETA: 30s - loss: 88.1219 - acc: 0.138 - ETA: 29s - loss: 87.8840 - acc: 0.135 - ETA: 29s - loss: 87.8915 - acc: 0.136 - ETA: 28s - loss: 88.3634 - acc: 0.135 - ETA: 28s - loss: 88.6559 - acc: 0.135 - ETA: 27s - loss: 89.0021 - acc: 0.136 - ETA: 27s - loss: 89.2949 - acc: 0.136 - ETA: 26s - loss: 89.3539 - acc: 0.135 - ETA: 26s - loss: 89.3419 - acc: 0.134 - ETA: 26s - loss: 89.6010 - acc: 0.138 - ETA: 25s - loss: 89.3123 - acc: 0.136 - ETA: 25s - loss: 89.4863 - acc: 0.134 - ETA: 24s - loss: 89.4431 - acc: 0.133 - ETA: 24s - loss: 89.4686 - acc: 0.133 - ETA: 24s - loss: 89.4124 - acc: 0.132 - ETA: 23s - loss: 89.4569 - acc: 0.131 - ETA: 23s - loss: 89.3160 - acc: 0.133 - ETA: 23s - loss: 89.0486 - acc: 0.133 - ETA: 22s - loss: 89.0526 - acc: 0.133 - ETA: 22s - loss: 89.0866 - acc: 0.134 - ETA: 21s - loss: 89.0635 - acc: 0.134 - ETA: 21s - loss: 89.3062 - acc: 0.136 - ETA: 21s - loss: 89.4218 - acc: 0.135 - ETA: 20s - loss: 89.5666 - acc: 0.136 - ETA: 20s - loss: 89.4851 - acc: 0.136 - ETA: 20s - loss: 89.5472 - acc: 0.134 - ETA: 19s - loss: 89.7632 - acc: 0.136 - ETA: 19s - loss: 89.7460 - acc: 0.136 - ETA: 19s - loss: 89.6548 - acc: 0.135 - ETA: 18s - loss: 89.6767 - acc: 0.136 - ETA: 18s - loss: 89.5571 - acc: 0.137 - ETA: 18s - loss: 89.7211 - acc: 0.137 - ETA: 17s - loss: 89.7620 - acc: 0.137 - ETA: 17s - loss: 89.7021 - acc: 0.136 - ETA: 17s - loss: 89.7154 - acc: 0.137 - ETA: 16s - loss: 89.8466 - acc: 0.137 - ETA: 16s - loss: 89.8721 - acc: 0.137 - ETA: 16s - loss: 89.8351 - acc: 0.137 - ETA: 15s - loss: 89.8562 - acc: 0.138 - ETA: 15s - loss: 90.0470 - acc: 0.137 - ETA: 15s - loss: 90.0932 - acc: 0.137 - ETA: 14s - loss: 90.1894 - acc: 0.138 - ETA: 14s - loss: 90.1235 - acc: 0.139 - ETA: 14s - loss: 90.1064 - acc: 0.138 - ETA: 13s - loss: 90.0642 - acc: 0.139 - ETA: 13s - loss: 90.1998 - acc: 0.139 - ETA: 13s - loss: 90.1966 - acc: 0.138 - ETA: 12s - loss: 90.1885 - acc: 0.139 - ETA: 12s - loss: 90.1502 - acc: 0.139 - ETA: 12s - loss: 90.1946 - acc: 0.139 - ETA: 11s - loss: 90.1060 - acc: 0.139 - ETA: 11s - loss: 90.0818 - acc: 0.138 - ETA: 11s - loss: 90.0507 - acc: 0.139 - ETA: 10s - loss: 90.0522 - acc: 0.140 - ETA: 10s - loss: 90.0187 - acc: 0.140 - ETA: 10s - loss: 89.9982 - acc: 0.140 - ETA: 9s - loss: 89.9431 - acc: 0.140 - ETA: 9s - loss: 89.9653 - acc: 0.14 - ETA: 9s - loss: 90.0737 - acc: 0.14 - ETA: 8s - loss: 90.1458 - acc: 0.14 - ETA: 8s - loss: 90.1875 - acc: 0.14 - ETA: 7s - loss: 90.2421 - acc: 0.14 - ETA: 7s - loss: 90.2398 - acc: 0.14 - ETA: 7s - loss: 90.2914 - acc: 0.14 - ETA: 6s - loss: 90.2514 - acc: 0.14 - ETA: 6s - loss: 90.3242 - acc: 0.14 - ETA: 6s - loss: 90.2918 - acc: 0.14 - ETA: 5s - loss: 90.2992 - acc: 0.14 - ETA: 5s - loss: 90.3030 - acc: 0.14 - ETA: 5s - loss: 90.3065 - acc: 0.14 - ETA: 4s - loss: 90.3041 - acc: 0.14 - ETA: 4s - loss: 90.3397 - acc: 0.14 - ETA: 4s - loss: 90.3214 - acc: 0.14 - ETA: 3s - loss: 90.3141 - acc: 0.14 - ETA: 3s - loss: 90.3396 - acc: 0.14 - ETA: 3s - loss: 90.3535 - acc: 0.14 - ETA: 2s - loss: 90.3644 - acc: 0.14 - ETA: 2s - loss: 90.4619 - acc: 0.14 - ETA: 2s - loss: 90.4409 - acc: 0.14 - ETA: 1s - loss: 90.4518 - acc: 0.14 - ETA: 1s - loss: 90.4170 - acc: 0.14 - ETA: 1s - loss: 90.4166 - acc: 0.14 - ETA: 0s - loss: 90.4804 - acc: 0.14 - ETA: 0s - loss: 90.5161 - acc: 0.14 - ETA: 0s - loss: 90.5057 - acc: 0.14 - 34s 3ms/step - loss: 90.5256 - acc: 0.1415 - val_loss: 99.7795 - val_acc: 0.3821\n",
      "Epoch 4/20\n",
      "11904/11904 [==============================] - ETA: 27s - loss: 88.9469 - acc: 0.085 - ETA: 26s - loss: 88.3971 - acc: 0.101 - ETA: 26s - loss: 90.4096 - acc: 0.117 - ETA: 25s - loss: 91.4625 - acc: 0.134 - ETA: 25s - loss: 93.2237 - acc: 0.145 - ETA: 25s - loss: 92.5382 - acc: 0.139 - ETA: 25s - loss: 91.8038 - acc: 0.133 - ETA: 24s - loss: 91.9214 - acc: 0.133 - ETA: 24s - loss: 91.4602 - acc: 0.132 - ETA: 24s - loss: 90.7685 - acc: 0.131 - ETA: 23s - loss: 91.2574 - acc: 0.134 - ETA: 23s - loss: 91.0028 - acc: 0.137 - ETA: 23s - loss: 90.7923 - acc: 0.135 - ETA: 23s - loss: 91.0476 - acc: 0.134 - ETA: 22s - loss: 91.0234 - acc: 0.134 - ETA: 22s - loss: 91.2948 - acc: 0.137 - ETA: 22s - loss: 91.1542 - acc: 0.139 - ETA: 21s - loss: 90.7431 - acc: 0.141 - ETA: 21s - loss: 90.9466 - acc: 0.139 - ETA: 21s - loss: 90.8517 - acc: 0.139 - ETA: 21s - loss: 90.8092 - acc: 0.141 - ETA: 20s - loss: 91.0776 - acc: 0.140 - ETA: 20s - loss: 91.0947 - acc: 0.140 - ETA: 20s - loss: 91.1331 - acc: 0.142 - ETA: 20s - loss: 90.9782 - acc: 0.141 - ETA: 19s - loss: 90.9912 - acc: 0.141 - ETA: 19s - loss: 91.0350 - acc: 0.140 - ETA: 19s - loss: 90.8080 - acc: 0.141 - ETA: 19s - loss: 90.6517 - acc: 0.141 - ETA: 18s - loss: 90.6742 - acc: 0.142 - ETA: 18s - loss: 90.7701 - acc: 0.140 - ETA: 18s - loss: 90.8815 - acc: 0.140 - ETA: 17s - loss: 90.7212 - acc: 0.139 - ETA: 17s - loss: 90.8748 - acc: 0.138 - ETA: 17s - loss: 90.9860 - acc: 0.138 - ETA: 16s - loss: 90.9904 - acc: 0.138 - ETA: 16s - loss: 90.8233 - acc: 0.138 - ETA: 16s - loss: 90.7133 - acc: 0.138 - ETA: 15s - loss: 90.6046 - acc: 0.137 - ETA: 15s - loss: 90.7244 - acc: 0.137 - ETA: 15s - loss: 90.6994 - acc: 0.136 - ETA: 15s - loss: 90.7155 - acc: 0.136 - ETA: 14s - loss: 90.6108 - acc: 0.135 - ETA: 14s - loss: 90.7132 - acc: 0.135 - ETA: 14s - loss: 90.6346 - acc: 0.136 - ETA: 14s - loss: 90.5997 - acc: 0.135 - ETA: 13s - loss: 90.5066 - acc: 0.135 - ETA: 13s - loss: 90.5200 - acc: 0.135 - ETA: 13s - loss: 90.4662 - acc: 0.134 - ETA: 12s - loss: 90.3945 - acc: 0.133 - ETA: 12s - loss: 90.2713 - acc: 0.133 - ETA: 12s - loss: 90.2684 - acc: 0.133 - ETA: 12s - loss: 90.2096 - acc: 0.133 - ETA: 11s - loss: 90.1490 - acc: 0.132 - ETA: 11s - loss: 90.1878 - acc: 0.132 - ETA: 11s - loss: 90.0532 - acc: 0.131 - ETA: 10s - loss: 90.1290 - acc: 0.131 - ETA: 10s - loss: 90.1492 - acc: 0.131 - ETA: 10s - loss: 90.1040 - acc: 0.131 - ETA: 9s - loss: 90.0820 - acc: 0.131 - ETA: 9s - loss: 89.9441 - acc: 0.13 - ETA: 9s - loss: 89.8948 - acc: 0.12 - ETA: 8s - loss: 89.8659 - acc: 0.12 - ETA: 8s - loss: 89.7769 - acc: 0.12 - ETA: 8s - loss: 89.7068 - acc: 0.12 - ETA: 8s - loss: 89.6447 - acc: 0.12 - ETA: 7s - loss: 89.5937 - acc: 0.12 - ETA: 7s - loss: 89.6327 - acc: 0.12 - ETA: 7s - loss: 89.5963 - acc: 0.12 - ETA: 6s - loss: 89.4945 - acc: 0.12 - ETA: 6s - loss: 89.4141 - acc: 0.12 - ETA: 6s - loss: 89.4989 - acc: 0.12 - ETA: 5s - loss: 89.4298 - acc: 0.12 - ETA: 5s - loss: 89.4723 - acc: 0.12 - ETA: 5s - loss: 89.4885 - acc: 0.12 - ETA: 5s - loss: 89.4667 - acc: 0.12 - ETA: 4s - loss: 89.4180 - acc: 0.12 - ETA: 4s - loss: 89.4017 - acc: 0.12 - ETA: 4s - loss: 89.4956 - acc: 0.12 - ETA: 3s - loss: 89.5078 - acc: 0.12 - ETA: 3s - loss: 89.4611 - acc: 0.12 - ETA: 3s - loss: 89.5416 - acc: 0.12 - ETA: 2s - loss: 89.4905 - acc: 0.12 - ETA: 2s - loss: 89.4967 - acc: 0.12 - ETA: 2s - loss: 89.5463 - acc: 0.12 - ETA: 2s - loss: 89.6172 - acc: 0.12 - ETA: 1s - loss: 89.5808 - acc: 0.12 - ETA: 1s - loss: 89.5255 - acc: 0.12 - ETA: 1s - loss: 89.6306 - acc: 0.12 - ETA: 0s - loss: 89.5616 - acc: 0.12 - ETA: 0s - loss: 89.5866 - acc: 0.12 - ETA: 0s - loss: 89.5816 - acc: 0.12 - 31s 3ms/step - loss: 89.6154 - acc: 0.1203 - val_loss: 98.8573 - val_acc: 0.3821\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 29s - loss: 88.8377 - acc: 0.140 - ETA: 27s - loss: 90.9545 - acc: 0.121 - ETA: 25s - loss: 91.5035 - acc: 0.119 - ETA: 25s - loss: 89.8343 - acc: 0.103 - ETA: 24s - loss: 90.4066 - acc: 0.106 - ETA: 24s - loss: 91.3518 - acc: 0.106 - ETA: 24s - loss: 90.9285 - acc: 0.103 - ETA: 23s - loss: 91.7149 - acc: 0.099 - ETA: 23s - loss: 91.6982 - acc: 0.099 - ETA: 23s - loss: 91.8235 - acc: 0.097 - ETA: 22s - loss: 91.4342 - acc: 0.098 - ETA: 22s - loss: 91.5352 - acc: 0.098 - ETA: 22s - loss: 91.1748 - acc: 0.096 - ETA: 21s - loss: 90.8579 - acc: 0.093 - ETA: 21s - loss: 91.1042 - acc: 0.092 - ETA: 21s - loss: 90.8886 - acc: 0.090 - ETA: 20s - loss: 90.6926 - acc: 0.089 - ETA: 20s - loss: 90.2483 - acc: 0.088 - ETA: 20s - loss: 89.9545 - acc: 0.091 - ETA: 19s - loss: 89.7648 - acc: 0.089 - ETA: 19s - loss: 89.9745 - acc: 0.087 - ETA: 19s - loss: 90.1213 - acc: 0.088 - ETA: 18s - loss: 89.7424 - acc: 0.087 - ETA: 18s - loss: 89.5462 - acc: 0.085 - ETA: 18s - loss: 89.4321 - acc: 0.084 - ETA: 18s - loss: 89.4410 - acc: 0.084 - ETA: 17s - loss: 89.2214 - acc: 0.084 - ETA: 17s - loss: 89.2816 - acc: 0.084 - ETA: 17s - loss: 89.2398 - acc: 0.083 - ETA: 17s - loss: 89.1941 - acc: 0.082 - ETA: 16s - loss: 89.4975 - acc: 0.082 - ETA: 16s - loss: 89.4211 - acc: 0.083 - ETA: 16s - loss: 89.6029 - acc: 0.083 - ETA: 15s - loss: 89.5654 - acc: 0.082 - ETA: 15s - loss: 89.4505 - acc: 0.082 - ETA: 15s - loss: 89.5010 - acc: 0.081 - ETA: 15s - loss: 89.5215 - acc: 0.081 - ETA: 14s - loss: 89.4399 - acc: 0.082 - ETA: 14s - loss: 89.5143 - acc: 0.081 - ETA: 14s - loss: 89.4886 - acc: 0.081 - ETA: 13s - loss: 89.4172 - acc: 0.080 - ETA: 13s - loss: 89.2944 - acc: 0.079 - ETA: 13s - loss: 89.2689 - acc: 0.079 - ETA: 13s - loss: 89.1175 - acc: 0.078 - ETA: 12s - loss: 89.2168 - acc: 0.078 - ETA: 12s - loss: 89.0287 - acc: 0.078 - ETA: 12s - loss: 89.2631 - acc: 0.078 - ETA: 12s - loss: 89.3452 - acc: 0.078 - ETA: 11s - loss: 89.3971 - acc: 0.078 - ETA: 11s - loss: 89.3736 - acc: 0.077 - ETA: 11s - loss: 89.3383 - acc: 0.076 - ETA: 11s - loss: 89.2058 - acc: 0.075 - ETA: 10s - loss: 89.2056 - acc: 0.075 - ETA: 10s - loss: 89.2195 - acc: 0.074 - ETA: 10s - loss: 89.2785 - acc: 0.074 - ETA: 9s - loss: 89.3058 - acc: 0.074 - ETA: 9s - loss: 89.2918 - acc: 0.07 - ETA: 9s - loss: 89.3583 - acc: 0.07 - ETA: 9s - loss: 89.3177 - acc: 0.07 - ETA: 8s - loss: 89.3349 - acc: 0.07 - ETA: 8s - loss: 89.3142 - acc: 0.07 - ETA: 8s - loss: 89.2959 - acc: 0.07 - ETA: 8s - loss: 89.3749 - acc: 0.07 - ETA: 7s - loss: 89.2210 - acc: 0.07 - ETA: 7s - loss: 89.2663 - acc: 0.07 - ETA: 7s - loss: 89.2427 - acc: 0.07 - ETA: 7s - loss: 89.2646 - acc: 0.07 - ETA: 6s - loss: 89.2864 - acc: 0.07 - ETA: 6s - loss: 89.1975 - acc: 0.07 - ETA: 6s - loss: 89.2714 - acc: 0.07 - ETA: 5s - loss: 89.2290 - acc: 0.07 - ETA: 5s - loss: 89.2806 - acc: 0.07 - ETA: 5s - loss: 89.2482 - acc: 0.07 - ETA: 5s - loss: 89.2699 - acc: 0.06 - ETA: 4s - loss: 89.2075 - acc: 0.06 - ETA: 4s - loss: 89.2222 - acc: 0.06 - ETA: 4s - loss: 89.2996 - acc: 0.06 - ETA: 4s - loss: 89.2708 - acc: 0.06 - ETA: 3s - loss: 89.1817 - acc: 0.06 - ETA: 3s - loss: 89.1532 - acc: 0.06 - ETA: 3s - loss: 89.2030 - acc: 0.06 - ETA: 2s - loss: 89.1938 - acc: 0.06 - ETA: 2s - loss: 89.2225 - acc: 0.06 - ETA: 2s - loss: 89.2021 - acc: 0.06 - ETA: 2s - loss: 89.2207 - acc: 0.06 - ETA: 1s - loss: 89.2242 - acc: 0.06 - ETA: 1s - loss: 89.1958 - acc: 0.06 - ETA: 1s - loss: 89.1936 - acc: 0.06 - ETA: 1s - loss: 89.1817 - acc: 0.06 - ETA: 0s - loss: 89.0885 - acc: 0.06 - ETA: 0s - loss: 89.0945 - acc: 0.06 - ETA: 0s - loss: 89.0213 - acc: 0.06 - 28s 2ms/step - loss: 89.0423 - acc: 0.0622 - val_loss: 98.3131 - val_acc: 0.0047\n",
      "Epoch 6/20\n",
      "11904/11904 [==============================] - ETA: 25s - loss: 84.9609 - acc: 0.023 - ETA: 24s - loss: 86.8545 - acc: 0.035 - ETA: 23s - loss: 87.0476 - acc: 0.033 - ETA: 23s - loss: 87.2129 - acc: 0.029 - ETA: 23s - loss: 87.4575 - acc: 0.031 - ETA: 22s - loss: 87.3788 - acc: 0.029 - ETA: 22s - loss: 87.5909 - acc: 0.029 - ETA: 22s - loss: 87.2343 - acc: 0.031 - ETA: 22s - loss: 87.9574 - acc: 0.031 - ETA: 21s - loss: 88.4707 - acc: 0.031 - ETA: 21s - loss: 88.5679 - acc: 0.031 - ETA: 21s - loss: 88.1062 - acc: 0.030 - ETA: 21s - loss: 88.2991 - acc: 0.031 - ETA: 20s - loss: 88.7342 - acc: 0.030 - ETA: 20s - loss: 88.5861 - acc: 0.030 - ETA: 20s - loss: 88.8393 - acc: 0.029 - ETA: 20s - loss: 89.0295 - acc: 0.028 - ETA: 19s - loss: 89.1833 - acc: 0.029 - ETA: 19s - loss: 89.0207 - acc: 0.029 - ETA: 19s - loss: 89.3052 - acc: 0.030 - ETA: 19s - loss: 89.2116 - acc: 0.029 - ETA: 18s - loss: 89.4496 - acc: 0.029 - ETA: 18s - loss: 89.5901 - acc: 0.030 - ETA: 18s - loss: 89.9223 - acc: 0.030 - ETA: 18s - loss: 90.0033 - acc: 0.031 - ETA: 17s - loss: 89.8614 - acc: 0.031 - ETA: 17s - loss: 89.6970 - acc: 0.032 - ETA: 17s - loss: 89.5285 - acc: 0.031 - ETA: 17s - loss: 89.5643 - acc: 0.031 - ETA: 16s - loss: 89.4604 - acc: 0.031 - ETA: 16s - loss: 89.3647 - acc: 0.030 - ETA: 16s - loss: 89.2916 - acc: 0.031 - ETA: 16s - loss: 89.1795 - acc: 0.031 - ETA: 15s - loss: 89.1713 - acc: 0.031 - ETA: 15s - loss: 89.0457 - acc: 0.032 - ETA: 15s - loss: 89.0961 - acc: 0.032 - ETA: 15s - loss: 88.8788 - acc: 0.031 - ETA: 14s - loss: 89.0267 - acc: 0.031 - ETA: 14s - loss: 88.9670 - acc: 0.031 - ETA: 14s - loss: 89.0258 - acc: 0.031 - ETA: 14s - loss: 88.8734 - acc: 0.031 - ETA: 14s - loss: 88.8330 - acc: 0.031 - ETA: 13s - loss: 88.8346 - acc: 0.031 - ETA: 13s - loss: 88.7472 - acc: 0.031 - ETA: 13s - loss: 89.0137 - acc: 0.030 - ETA: 13s - loss: 88.9210 - acc: 0.030 - ETA: 13s - loss: 88.9857 - acc: 0.031 - ETA: 13s - loss: 88.9550 - acc: 0.030 - ETA: 12s - loss: 88.8209 - acc: 0.030 - ETA: 12s - loss: 88.8924 - acc: 0.029 - ETA: 12s - loss: 88.7996 - acc: 0.029 - ETA: 12s - loss: 88.8467 - acc: 0.029 - ETA: 11s - loss: 88.8647 - acc: 0.028 - ETA: 11s - loss: 88.7029 - acc: 0.028 - ETA: 11s - loss: 88.7632 - acc: 0.028 - ETA: 11s - loss: 88.7165 - acc: 0.028 - ETA: 10s - loss: 88.7367 - acc: 0.028 - ETA: 10s - loss: 88.5825 - acc: 0.028 - ETA: 10s - loss: 88.6397 - acc: 0.028 - ETA: 10s - loss: 88.5839 - acc: 0.028 - ETA: 9s - loss: 88.5930 - acc: 0.028 - ETA: 9s - loss: 88.5716 - acc: 0.02 - ETA: 9s - loss: 88.7256 - acc: 0.02 - ETA: 9s - loss: 88.7129 - acc: 0.02 - ETA: 8s - loss: 88.8383 - acc: 0.02 - ETA: 8s - loss: 88.9021 - acc: 0.02 - ETA: 8s - loss: 88.9086 - acc: 0.02 - ETA: 7s - loss: 88.9169 - acc: 0.02 - ETA: 7s - loss: 89.0089 - acc: 0.02 - ETA: 7s - loss: 88.9594 - acc: 0.02 - ETA: 7s - loss: 88.8953 - acc: 0.02 - ETA: 6s - loss: 88.9250 - acc: 0.02 - ETA: 6s - loss: 88.8813 - acc: 0.02 - ETA: 6s - loss: 88.8133 - acc: 0.02 - ETA: 5s - loss: 88.8292 - acc: 0.02 - ETA: 5s - loss: 88.8605 - acc: 0.02 - ETA: 5s - loss: 88.8319 - acc: 0.02 - ETA: 5s - loss: 88.8095 - acc: 0.02 - ETA: 4s - loss: 88.8237 - acc: 0.02 - ETA: 4s - loss: 88.8176 - acc: 0.02 - ETA: 4s - loss: 88.7844 - acc: 0.02 - ETA: 3s - loss: 88.6856 - acc: 0.02 - ETA: 3s - loss: 88.6959 - acc: 0.02 - ETA: 3s - loss: 88.7540 - acc: 0.02 - ETA: 2s - loss: 88.7340 - acc: 0.02 - ETA: 2s - loss: 88.7145 - acc: 0.02 - ETA: 2s - loss: 88.6826 - acc: 0.02 - ETA: 1s - loss: 88.7004 - acc: 0.02 - ETA: 1s - loss: 88.6556 - acc: 0.02 - ETA: 1s - loss: 88.6616 - acc: 0.02 - ETA: 0s - loss: 88.6442 - acc: 0.02 - ETA: 0s - loss: 88.6898 - acc: 0.02 - 37s 3ms/step - loss: 88.7005 - acc: 0.0242 - val_loss: 98.0143 - val_acc: 0.0047\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 31s - loss: 90.9034 - acc: 0.023 - ETA: 32s - loss: 89.3689 - acc: 0.023 - ETA: 30s - loss: 88.6233 - acc: 0.026 - ETA: 30s - loss: 90.4901 - acc: 0.021 - ETA: 30s - loss: 90.7030 - acc: 0.020 - ETA: 29s - loss: 90.3583 - acc: 0.019 - ETA: 29s - loss: 88.6272 - acc: 0.016 - ETA: 29s - loss: 89.2301 - acc: 0.014 - ETA: 28s - loss: 89.4088 - acc: 0.013 - ETA: 28s - loss: 88.5040 - acc: 0.014 - ETA: 28s - loss: 88.5551 - acc: 0.012 - ETA: 29s - loss: 88.3894 - acc: 0.014 - ETA: 29s - loss: 88.3089 - acc: 0.013 - ETA: 30s - loss: 88.2048 - acc: 0.013 - ETA: 30s - loss: 88.1504 - acc: 0.013 - ETA: 29s - loss: 88.0721 - acc: 0.013 - ETA: 29s - loss: 88.3123 - acc: 0.013 - ETA: 28s - loss: 88.4432 - acc: 0.013 - ETA: 27s - loss: 88.4196 - acc: 0.013 - ETA: 27s - loss: 88.4117 - acc: 0.012 - ETA: 26s - loss: 88.5075 - acc: 0.013 - ETA: 26s - loss: 88.4242 - acc: 0.013 - ETA: 26s - loss: 88.4815 - acc: 0.012 - ETA: 25s - loss: 88.4810 - acc: 0.012 - ETA: 25s - loss: 88.6908 - acc: 0.012 - ETA: 24s - loss: 88.9003 - acc: 0.012 - ETA: 24s - loss: 88.7523 - acc: 0.012 - ETA: 23s - loss: 88.7982 - acc: 0.012 - ETA: 23s - loss: 88.6807 - acc: 0.012 - ETA: 23s - loss: 88.6021 - acc: 0.012 - ETA: 22s - loss: 88.7651 - acc: 0.013 - ETA: 22s - loss: 88.9235 - acc: 0.013 - ETA: 22s - loss: 88.9977 - acc: 0.012 - ETA: 21s - loss: 89.0162 - acc: 0.012 - ETA: 21s - loss: 88.9991 - acc: 0.012 - ETA: 20s - loss: 88.8021 - acc: 0.013 - ETA: 20s - loss: 88.7507 - acc: 0.013 - ETA: 20s - loss: 88.7822 - acc: 0.013 - ETA: 19s - loss: 88.8564 - acc: 0.013 - ETA: 19s - loss: 88.9135 - acc: 0.013 - ETA: 19s - loss: 88.6664 - acc: 0.013 - ETA: 18s - loss: 88.6787 - acc: 0.013 - ETA: 18s - loss: 88.5424 - acc: 0.013 - ETA: 18s - loss: 88.5183 - acc: 0.012 - ETA: 17s - loss: 88.6455 - acc: 0.012 - ETA: 17s - loss: 88.6344 - acc: 0.013 - ETA: 16s - loss: 88.6161 - acc: 0.012 - ETA: 16s - loss: 88.6673 - acc: 0.013 - ETA: 16s - loss: 88.6309 - acc: 0.013 - ETA: 15s - loss: 88.6814 - acc: 0.013 - ETA: 15s - loss: 88.6711 - acc: 0.013 - ETA: 15s - loss: 88.7630 - acc: 0.013 - ETA: 14s - loss: 88.7537 - acc: 0.012 - ETA: 14s - loss: 88.6355 - acc: 0.012 - ETA: 14s - loss: 88.5989 - acc: 0.012 - ETA: 13s - loss: 88.5149 - acc: 0.012 - ETA: 13s - loss: 88.6526 - acc: 0.012 - ETA: 12s - loss: 88.7040 - acc: 0.012 - ETA: 12s - loss: 88.7120 - acc: 0.012 - ETA: 12s - loss: 88.8571 - acc: 0.012 - ETA: 11s - loss: 88.8731 - acc: 0.011 - ETA: 11s - loss: 88.8911 - acc: 0.012 - ETA: 11s - loss: 88.8908 - acc: 0.012 - ETA: 10s - loss: 88.9234 - acc: 0.012 - ETA: 10s - loss: 88.9853 - acc: 0.011 - ETA: 9s - loss: 88.8787 - acc: 0.011 - ETA: 9s - loss: 88.7596 - acc: 0.01 - ETA: 9s - loss: 88.8088 - acc: 0.01 - ETA: 8s - loss: 88.7772 - acc: 0.01 - ETA: 8s - loss: 88.7449 - acc: 0.01 - ETA: 8s - loss: 88.7490 - acc: 0.01 - ETA: 7s - loss: 88.7083 - acc: 0.01 - ETA: 7s - loss: 88.6885 - acc: 0.01 - ETA: 6s - loss: 88.6268 - acc: 0.01 - ETA: 6s - loss: 88.6997 - acc: 0.01 - ETA: 6s - loss: 88.7187 - acc: 0.01 - ETA: 5s - loss: 88.6613 - acc: 0.01 - ETA: 5s - loss: 88.6903 - acc: 0.01 - ETA: 5s - loss: 88.6814 - acc: 0.01 - ETA: 4s - loss: 88.6388 - acc: 0.01 - ETA: 4s - loss: 88.6253 - acc: 0.01 - ETA: 4s - loss: 88.6223 - acc: 0.01 - ETA: 3s - loss: 88.6507 - acc: 0.01 - ETA: 3s - loss: 88.6087 - acc: 0.01 - ETA: 2s - loss: 88.6512 - acc: 0.01 - ETA: 2s - loss: 88.6897 - acc: 0.01 - ETA: 2s - loss: 88.6194 - acc: 0.01 - ETA: 1s - loss: 88.6462 - acc: 0.01 - ETA: 1s - loss: 88.5925 - acc: 0.01 - ETA: 1s - loss: 88.5289 - acc: 0.01 - ETA: 0s - loss: 88.5377 - acc: 0.01 - ETA: 0s - loss: 88.5557 - acc: 0.01 - 38s 3ms/step - loss: 88.4852 - acc: 0.0111 - val_loss: 97.8682 - val_acc: 0.0047\n",
      "Epoch 8/20\n",
      "11904/11904 [==============================] - ETA: 29s - loss: 87.7517 - acc: 0.0000e+0 - ETA: 29s - loss: 88.5019 - acc: 0.0039    - ETA: 29s - loss: 87.5030 - acc: 0.007 - ETA: 29s - loss: 87.2470 - acc: 0.005 - ETA: 28s - loss: 88.4969 - acc: 0.004 - ETA: 28s - loss: 88.9043 - acc: 0.005 - ETA: 27s - loss: 87.9727 - acc: 0.004 - ETA: 27s - loss: 87.3923 - acc: 0.005 - ETA: 27s - loss: 88.4907 - acc: 0.005 - ETA: 27s - loss: 88.2066 - acc: 0.007 - ETA: 26s - loss: 88.4172 - acc: 0.009 - ETA: 26s - loss: 88.2789 - acc: 0.008 - ETA: 26s - loss: 88.2559 - acc: 0.009 - ETA: 25s - loss: 88.3311 - acc: 0.008 - ETA: 25s - loss: 88.2250 - acc: 0.008 - ETA: 25s - loss: 88.1475 - acc: 0.009 - ETA: 24s - loss: 88.2455 - acc: 0.010 - ETA: 24s - loss: 88.4802 - acc: 0.010 - ETA: 24s - loss: 89.0777 - acc: 0.010 - ETA: 23s - loss: 88.7463 - acc: 0.011 - ETA: 23s - loss: 88.5200 - acc: 0.011 - ETA: 23s - loss: 88.0891 - acc: 0.011 - ETA: 22s - loss: 88.0796 - acc: 0.011 - ETA: 22s - loss: 88.0700 - acc: 0.012 - ETA: 22s - loss: 88.1682 - acc: 0.012 - ETA: 21s - loss: 88.3732 - acc: 0.012 - ETA: 21s - loss: 88.3916 - acc: 0.011 - ETA: 21s - loss: 88.5400 - acc: 0.011 - ETA: 21s - loss: 88.5843 - acc: 0.011 - ETA: 20s - loss: 88.5976 - acc: 0.011 - ETA: 20s - loss: 88.6982 - acc: 0.011 - ETA: 20s - loss: 88.5597 - acc: 0.010 - ETA: 19s - loss: 88.5736 - acc: 0.010 - ETA: 19s - loss: 88.5153 - acc: 0.010 - ETA: 19s - loss: 88.4860 - acc: 0.010 - ETA: 18s - loss: 88.4544 - acc: 0.010 - ETA: 18s - loss: 88.3433 - acc: 0.010 - ETA: 18s - loss: 88.1627 - acc: 0.010 - ETA: 17s - loss: 88.1311 - acc: 0.010 - ETA: 17s - loss: 88.2364 - acc: 0.010 - ETA: 17s - loss: 88.1090 - acc: 0.010 - ETA: 16s - loss: 88.1000 - acc: 0.010 - ETA: 16s - loss: 87.9693 - acc: 0.010 - ETA: 16s - loss: 87.9664 - acc: 0.010 - ETA: 15s - loss: 88.1215 - acc: 0.010 - ETA: 15s - loss: 88.1721 - acc: 0.010 - ETA: 15s - loss: 88.2091 - acc: 0.010 - ETA: 14s - loss: 88.2661 - acc: 0.010 - ETA: 14s - loss: 88.3200 - acc: 0.010 - ETA: 14s - loss: 88.3394 - acc: 0.010 - ETA: 13s - loss: 88.2169 - acc: 0.010 - ETA: 13s - loss: 88.2103 - acc: 0.010 - ETA: 13s - loss: 88.3054 - acc: 0.010 - ETA: 12s - loss: 88.1616 - acc: 0.010 - ETA: 12s - loss: 88.2624 - acc: 0.010 - ETA: 12s - loss: 88.3280 - acc: 0.010 - ETA: 11s - loss: 88.3185 - acc: 0.010 - ETA: 11s - loss: 88.1725 - acc: 0.010 - ETA: 11s - loss: 88.1452 - acc: 0.010 - ETA: 10s - loss: 88.1326 - acc: 0.010 - ETA: 10s - loss: 88.1616 - acc: 0.010 - ETA: 10s - loss: 88.2286 - acc: 0.010 - ETA: 9s - loss: 88.2106 - acc: 0.010 - ETA: 9s - loss: 88.2615 - acc: 0.01 - ETA: 9s - loss: 88.2268 - acc: 0.01 - ETA: 8s - loss: 88.1790 - acc: 0.01 - ETA: 8s - loss: 88.2246 - acc: 0.01 - ETA: 8s - loss: 88.2284 - acc: 0.01 - ETA: 7s - loss: 88.2230 - acc: 0.01 - ETA: 7s - loss: 88.2268 - acc: 0.01 - ETA: 7s - loss: 88.2951 - acc: 0.01 - ETA: 6s - loss: 88.2509 - acc: 0.01 - ETA: 6s - loss: 88.2717 - acc: 0.01 - ETA: 6s - loss: 88.3092 - acc: 0.01 - ETA: 5s - loss: 88.2731 - acc: 0.01 - ETA: 5s - loss: 88.2497 - acc: 0.01 - ETA: 5s - loss: 88.2914 - acc: 0.01 - ETA: 5s - loss: 88.2328 - acc: 0.01 - ETA: 4s - loss: 88.2619 - acc: 0.01 - ETA: 4s - loss: 88.2126 - acc: 0.01 - ETA: 4s - loss: 88.2049 - acc: 0.01 - ETA: 3s - loss: 88.2615 - acc: 0.01 - ETA: 3s - loss: 88.2910 - acc: 0.01 - ETA: 3s - loss: 88.3016 - acc: 0.01 - ETA: 2s - loss: 88.3304 - acc: 0.01 - ETA: 2s - loss: 88.3738 - acc: 0.01 - ETA: 2s - loss: 88.3399 - acc: 0.01 - ETA: 1s - loss: 88.3033 - acc: 0.01 - ETA: 1s - loss: 88.3188 - acc: 0.01 - ETA: 1s - loss: 88.3504 - acc: 0.01 - ETA: 0s - loss: 88.3250 - acc: 0.01 - ETA: 0s - loss: 88.2988 - acc: 0.01 - 39s 3ms/step - loss: 88.3707 - acc: 0.0114 - val_loss: 97.7977 - val_acc: 0.0047\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 42s - loss: 95.2826 - acc: 0.023 - ETA: 34s - loss: 89.9982 - acc: 0.023 - ETA: 31s - loss: 90.8074 - acc: 0.015 - ETA: 29s - loss: 91.0997 - acc: 0.011 - ETA: 28s - loss: 90.3270 - acc: 0.012 - ETA: 27s - loss: 90.1414 - acc: 0.013 - ETA: 27s - loss: 90.5364 - acc: 0.014 - ETA: 27s - loss: 90.0506 - acc: 0.014 - ETA: 26s - loss: 89.5554 - acc: 0.015 - ETA: 25s - loss: 89.6259 - acc: 0.015 - ETA: 25s - loss: 89.9341 - acc: 0.014 - ETA: 24s - loss: 89.7996 - acc: 0.015 - ETA: 24s - loss: 90.0450 - acc: 0.015 - ETA: 23s - loss: 89.3512 - acc: 0.015 - ETA: 23s - loss: 89.9648 - acc: 0.017 - ETA: 23s - loss: 89.7427 - acc: 0.016 - ETA: 23s - loss: 89.5431 - acc: 0.016 - ETA: 23s - loss: 89.3344 - acc: 0.015 - ETA: 22s - loss: 89.4080 - acc: 0.014 - ETA: 22s - loss: 89.3835 - acc: 0.014 - ETA: 22s - loss: 89.1664 - acc: 0.014 - ETA: 21s - loss: 89.2765 - acc: 0.013 - ETA: 21s - loss: 88.9862 - acc: 0.013 - ETA: 21s - loss: 89.1685 - acc: 0.013 - ETA: 20s - loss: 89.2425 - acc: 0.013 - ETA: 20s - loss: 89.2787 - acc: 0.013 - ETA: 19s - loss: 88.9299 - acc: 0.013 - ETA: 19s - loss: 88.9550 - acc: 0.013 - ETA: 19s - loss: 88.7113 - acc: 0.013 - ETA: 18s - loss: 88.6907 - acc: 0.013 - ETA: 18s - loss: 88.5125 - acc: 0.013 - ETA: 18s - loss: 88.6410 - acc: 0.012 - ETA: 17s - loss: 88.7434 - acc: 0.012 - ETA: 17s - loss: 88.7198 - acc: 0.012 - ETA: 17s - loss: 88.7199 - acc: 0.012 - ETA: 17s - loss: 88.6332 - acc: 0.012 - ETA: 16s - loss: 88.4278 - acc: 0.012 - ETA: 16s - loss: 88.4025 - acc: 0.012 - ETA: 16s - loss: 88.4767 - acc: 0.012 - ETA: 15s - loss: 88.3747 - acc: 0.012 - ETA: 15s - loss: 88.1555 - acc: 0.012 - ETA: 15s - loss: 88.2859 - acc: 0.012 - ETA: 14s - loss: 88.1838 - acc: 0.012 - ETA: 14s - loss: 88.1143 - acc: 0.012 - ETA: 14s - loss: 88.1057 - acc: 0.012 - ETA: 13s - loss: 88.1535 - acc: 0.012 - ETA: 13s - loss: 88.1632 - acc: 0.012 - ETA: 13s - loss: 88.1229 - acc: 0.012 - ETA: 13s - loss: 88.1412 - acc: 0.012 - ETA: 12s - loss: 88.0327 - acc: 0.012 - ETA: 12s - loss: 88.1778 - acc: 0.012 - ETA: 12s - loss: 88.1272 - acc: 0.012 - ETA: 12s - loss: 88.0860 - acc: 0.012 - ETA: 11s - loss: 88.1373 - acc: 0.012 - ETA: 11s - loss: 88.2347 - acc: 0.012 - ETA: 11s - loss: 88.2849 - acc: 0.012 - ETA: 11s - loss: 88.2664 - acc: 0.012 - ETA: 10s - loss: 88.2206 - acc: 0.012 - ETA: 10s - loss: 88.1800 - acc: 0.012 - ETA: 10s - loss: 88.2236 - acc: 0.012 - ETA: 10s - loss: 88.2740 - acc: 0.012 - ETA: 9s - loss: 88.1687 - acc: 0.012 - ETA: 9s - loss: 88.1155 - acc: 0.01 - ETA: 9s - loss: 88.0469 - acc: 0.01 - ETA: 8s - loss: 88.0917 - acc: 0.01 - ETA: 8s - loss: 88.0545 - acc: 0.01 - ETA: 8s - loss: 87.9713 - acc: 0.01 - ETA: 7s - loss: 88.0187 - acc: 0.01 - ETA: 7s - loss: 87.9936 - acc: 0.01 - ETA: 7s - loss: 87.9190 - acc: 0.01 - ETA: 6s - loss: 87.8177 - acc: 0.01 - ETA: 6s - loss: 87.9318 - acc: 0.01 - ETA: 6s - loss: 87.9051 - acc: 0.01 - ETA: 6s - loss: 87.9078 - acc: 0.01 - ETA: 5s - loss: 87.9640 - acc: 0.01 - ETA: 5s - loss: 87.8948 - acc: 0.01 - ETA: 5s - loss: 87.8941 - acc: 0.01 - ETA: 4s - loss: 87.9752 - acc: 0.01 - ETA: 4s - loss: 88.0322 - acc: 0.01 - ETA: 4s - loss: 88.0416 - acc: 0.01 - ETA: 3s - loss: 88.0083 - acc: 0.01 - ETA: 3s - loss: 87.9704 - acc: 0.01 - ETA: 3s - loss: 87.9568 - acc: 0.01 - ETA: 2s - loss: 87.9294 - acc: 0.01 - ETA: 2s - loss: 87.9730 - acc: 0.01 - ETA: 2s - loss: 88.0720 - acc: 0.01 - ETA: 1s - loss: 88.1089 - acc: 0.01 - ETA: 1s - loss: 88.1284 - acc: 0.01 - ETA: 1s - loss: 88.1731 - acc: 0.01 - ETA: 0s - loss: 88.2361 - acc: 0.01 - ETA: 0s - loss: 88.2758 - acc: 0.01 - ETA: 0s - loss: 88.2256 - acc: 0.01 - 36s 3ms/step - loss: 88.2987 - acc: 0.0117 - val_loss: 97.7690 - val_acc: 0.0047\n",
      "Epoch 10/20\n",
      "11904/11904 [==============================] - ETA: 44s - loss: 85.0265 - acc: 0.007 - ETA: 49s - loss: 85.6990 - acc: 0.011 - ETA: 48s - loss: 87.9043 - acc: 0.020 - ETA: 48s - loss: 89.1687 - acc: 0.017 - ETA: 46s - loss: 88.8307 - acc: 0.017 - ETA: 44s - loss: 89.0814 - acc: 0.016 - ETA: 43s - loss: 88.7824 - acc: 0.015 - ETA: 42s - loss: 88.7842 - acc: 0.014 - ETA: 41s - loss: 88.9845 - acc: 0.013 - ETA: 39s - loss: 89.1399 - acc: 0.012 - ETA: 38s - loss: 89.1003 - acc: 0.012 - ETA: 36s - loss: 89.0782 - acc: 0.011 - ETA: 35s - loss: 89.0341 - acc: 0.012 - ETA: 34s - loss: 88.8852 - acc: 0.011 - ETA: 34s - loss: 88.4044 - acc: 0.011 - ETA: 34s - loss: 88.4861 - acc: 0.012 - ETA: 34s - loss: 88.5782 - acc: 0.012 - ETA: 33s - loss: 88.6596 - acc: 0.011 - ETA: 32s - loss: 88.3862 - acc: 0.011 - ETA: 31s - loss: 88.3161 - acc: 0.010 - ETA: 30s - loss: 88.1981 - acc: 0.011 - ETA: 30s - loss: 87.9224 - acc: 0.010 - ETA: 29s - loss: 87.8642 - acc: 0.010 - ETA: 28s - loss: 87.9484 - acc: 0.010 - ETA: 27s - loss: 88.0024 - acc: 0.011 - ETA: 27s - loss: 88.1120 - acc: 0.010 - ETA: 26s - loss: 88.0584 - acc: 0.010 - ETA: 26s - loss: 88.3558 - acc: 0.010 - ETA: 26s - loss: 88.2583 - acc: 0.010 - ETA: 26s - loss: 88.3236 - acc: 0.011 - ETA: 26s - loss: 88.4428 - acc: 0.011 - ETA: 26s - loss: 88.6104 - acc: 0.011 - ETA: 25s - loss: 88.5430 - acc: 0.011 - ETA: 25s - loss: 88.3877 - acc: 0.011 - ETA: 24s - loss: 88.3468 - acc: 0.011 - ETA: 24s - loss: 88.1188 - acc: 0.011 - ETA: 23s - loss: 87.9275 - acc: 0.011 - ETA: 22s - loss: 87.9602 - acc: 0.010 - ETA: 22s - loss: 88.0019 - acc: 0.010 - ETA: 21s - loss: 87.8867 - acc: 0.010 - ETA: 21s - loss: 88.0436 - acc: 0.010 - ETA: 20s - loss: 88.1250 - acc: 0.010 - ETA: 20s - loss: 88.0394 - acc: 0.010 - ETA: 19s - loss: 88.0044 - acc: 0.010 - ETA: 19s - loss: 87.8739 - acc: 0.010 - ETA: 18s - loss: 87.8840 - acc: 0.010 - ETA: 18s - loss: 87.9709 - acc: 0.010 - ETA: 18s - loss: 87.8823 - acc: 0.010 - ETA: 17s - loss: 88.1001 - acc: 0.010 - ETA: 17s - loss: 88.1022 - acc: 0.010 - ETA: 16s - loss: 88.1752 - acc: 0.010 - ETA: 16s - loss: 88.1588 - acc: 0.010 - ETA: 15s - loss: 88.2466 - acc: 0.010 - ETA: 15s - loss: 88.3298 - acc: 0.010 - ETA: 14s - loss: 88.2003 - acc: 0.010 - ETA: 14s - loss: 88.0270 - acc: 0.010 - ETA: 14s - loss: 87.9831 - acc: 0.010 - ETA: 13s - loss: 88.0591 - acc: 0.009 - ETA: 13s - loss: 88.0527 - acc: 0.009 - ETA: 13s - loss: 88.0195 - acc: 0.009 - ETA: 12s - loss: 87.9170 - acc: 0.009 - ETA: 12s - loss: 88.0008 - acc: 0.010 - ETA: 11s - loss: 88.0236 - acc: 0.010 - ETA: 11s - loss: 88.0218 - acc: 0.010 - ETA: 10s - loss: 88.0127 - acc: 0.010 - ETA: 10s - loss: 87.9503 - acc: 0.010 - ETA: 10s - loss: 87.9749 - acc: 0.010 - ETA: 9s - loss: 88.0210 - acc: 0.010 - ETA: 9s - loss: 87.9832 - acc: 0.01 - ETA: 9s - loss: 87.9386 - acc: 0.01 - ETA: 8s - loss: 87.9415 - acc: 0.01 - ETA: 8s - loss: 87.9261 - acc: 0.01 - ETA: 7s - loss: 88.0241 - acc: 0.01 - ETA: 7s - loss: 88.0099 - acc: 0.01 - ETA: 7s - loss: 88.0464 - acc: 0.01 - ETA: 6s - loss: 87.9481 - acc: 0.01 - ETA: 6s - loss: 87.9388 - acc: 0.01 - ETA: 5s - loss: 88.0200 - acc: 0.01 - ETA: 5s - loss: 88.1219 - acc: 0.01 - ETA: 5s - loss: 88.1573 - acc: 0.01 - ETA: 4s - loss: 88.1224 - acc: 0.01 - ETA: 4s - loss: 88.1556 - acc: 0.01 - ETA: 3s - loss: 88.1097 - acc: 0.01 - ETA: 3s - loss: 88.1049 - acc: 0.01 - ETA: 3s - loss: 88.0260 - acc: 0.01 - ETA: 2s - loss: 88.0882 - acc: 0.01 - ETA: 2s - loss: 88.0656 - acc: 0.01 - ETA: 1s - loss: 88.1486 - acc: 0.01 - ETA: 1s - loss: 88.1838 - acc: 0.01 - ETA: 1s - loss: 88.2101 - acc: 0.01 - ETA: 0s - loss: 88.2053 - acc: 0.01 - ETA: 0s - loss: 88.2322 - acc: 0.01 - 39s 3ms/step - loss: 88.2587 - acc: 0.0100 - val_loss: 97.7595 - val_acc: 0.0047\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 23s - loss: 94.5750 - acc: 0.0000e+0 - ETA: 23s - loss: 94.0882 - acc: 0.0000e+0 - ETA: 22s - loss: 94.5751 - acc: 0.0026    - ETA: 22s - loss: 91.9279 - acc: 0.011 - ETA: 22s - loss: 91.1780 - acc: 0.010 - ETA: 22s - loss: 90.3164 - acc: 0.009 - ETA: 22s - loss: 88.3651 - acc: 0.008 - ETA: 21s - loss: 87.9365 - acc: 0.009 - ETA: 21s - loss: 87.7348 - acc: 0.008 - ETA: 21s - loss: 87.5920 - acc: 0.010 - ETA: 21s - loss: 87.5533 - acc: 0.009 - ETA: 20s - loss: 87.5147 - acc: 0.009 - ETA: 20s - loss: 87.7655 - acc: 0.009 - ETA: 20s - loss: 87.8508 - acc: 0.010 - ETA: 20s - loss: 87.7928 - acc: 0.010 - ETA: 19s - loss: 87.9596 - acc: 0.010 - ETA: 20s - loss: 87.8351 - acc: 0.009 - ETA: 20s - loss: 88.0139 - acc: 0.009 - ETA: 19s - loss: 88.2402 - acc: 0.010 - ETA: 19s - loss: 88.4493 - acc: 0.009 - ETA: 19s - loss: 88.5268 - acc: 0.010 - ETA: 19s - loss: 88.4251 - acc: 0.009 - ETA: 18s - loss: 88.5501 - acc: 0.009 - ETA: 18s - loss: 88.5503 - acc: 0.009 - ETA: 18s - loss: 88.6510 - acc: 0.009 - ETA: 18s - loss: 88.6081 - acc: 0.009 - ETA: 17s - loss: 88.4779 - acc: 0.009 - ETA: 17s - loss: 88.4069 - acc: 0.009 - ETA: 17s - loss: 88.5604 - acc: 0.009 - ETA: 17s - loss: 88.4404 - acc: 0.009 - ETA: 17s - loss: 88.3945 - acc: 0.009 - ETA: 16s - loss: 88.1846 - acc: 0.010 - ETA: 16s - loss: 88.4180 - acc: 0.010 - ETA: 16s - loss: 88.4955 - acc: 0.009 - ETA: 15s - loss: 88.3762 - acc: 0.010 - ETA: 15s - loss: 88.3903 - acc: 0.010 - ETA: 15s - loss: 88.3158 - acc: 0.010 - ETA: 15s - loss: 88.4322 - acc: 0.009 - ETA: 14s - loss: 88.5370 - acc: 0.009 - ETA: 14s - loss: 88.5505 - acc: 0.009 - ETA: 14s - loss: 88.5344 - acc: 0.010 - ETA: 14s - loss: 88.3847 - acc: 0.010 - ETA: 13s - loss: 88.2058 - acc: 0.010 - ETA: 13s - loss: 88.2841 - acc: 0.010 - ETA: 13s - loss: 88.3072 - acc: 0.010 - ETA: 13s - loss: 88.2326 - acc: 0.010 - ETA: 12s - loss: 88.2302 - acc: 0.009 - ETA: 12s - loss: 88.0672 - acc: 0.009 - ETA: 12s - loss: 88.0853 - acc: 0.009 - ETA: 11s - loss: 88.1953 - acc: 0.009 - ETA: 11s - loss: 88.1635 - acc: 0.009 - ETA: 11s - loss: 88.0478 - acc: 0.009 - ETA: 11s - loss: 88.1104 - acc: 0.009 - ETA: 10s - loss: 87.9573 - acc: 0.009 - ETA: 10s - loss: 87.9819 - acc: 0.009 - ETA: 10s - loss: 87.9551 - acc: 0.009 - ETA: 10s - loss: 87.9536 - acc: 0.009 - ETA: 9s - loss: 88.0313 - acc: 0.009 - ETA: 9s - loss: 88.2060 - acc: 0.00 - ETA: 9s - loss: 88.2083 - acc: 0.00 - ETA: 9s - loss: 88.1559 - acc: 0.00 - ETA: 8s - loss: 88.1805 - acc: 0.00 - ETA: 8s - loss: 88.0907 - acc: 0.00 - ETA: 8s - loss: 88.0875 - acc: 0.00 - ETA: 7s - loss: 88.1263 - acc: 0.00 - ETA: 7s - loss: 88.2310 - acc: 0.00 - ETA: 7s - loss: 88.2787 - acc: 0.00 - ETA: 7s - loss: 88.3146 - acc: 0.00 - ETA: 6s - loss: 88.3076 - acc: 0.00 - ETA: 6s - loss: 88.3046 - acc: 0.00 - ETA: 6s - loss: 88.3132 - acc: 0.00 - ETA: 5s - loss: 88.2929 - acc: 0.00 - ETA: 5s - loss: 88.3196 - acc: 0.00 - ETA: 5s - loss: 88.1738 - acc: 0.00 - ETA: 5s - loss: 88.1261 - acc: 0.00 - ETA: 4s - loss: 88.1482 - acc: 0.00 - ETA: 4s - loss: 88.1519 - acc: 0.00 - ETA: 4s - loss: 88.1839 - acc: 0.00 - ETA: 3s - loss: 88.1618 - acc: 0.00 - ETA: 3s - loss: 88.0927 - acc: 0.00 - ETA: 3s - loss: 88.0842 - acc: 0.00 - ETA: 3s - loss: 88.0894 - acc: 0.00 - ETA: 2s - loss: 88.1239 - acc: 0.00 - ETA: 2s - loss: 88.1742 - acc: 0.00 - ETA: 2s - loss: 88.1114 - acc: 0.00 - ETA: 1s - loss: 88.1308 - acc: 0.00 - ETA: 1s - loss: 88.1818 - acc: 0.00 - ETA: 1s - loss: 88.1656 - acc: 0.00 - ETA: 1s - loss: 88.1826 - acc: 0.00 - ETA: 0s - loss: 88.1258 - acc: 0.00 - ETA: 0s - loss: 88.1344 - acc: 0.00 - ETA: 0s - loss: 88.1045 - acc: 0.00 - 29s 2ms/step - loss: 88.1911 - acc: 0.0077 - val_loss: 97.7602 - val_acc: 0.0047\n",
      "Epoch 12/20\n",
      "11904/11904 [==============================] - ETA: 28s - loss: 94.7261 - acc: 0.015 - ETA: 27s - loss: 93.0177 - acc: 0.015 - ETA: 26s - loss: 89.3731 - acc: 0.013 - ETA: 26s - loss: 88.9846 - acc: 0.011 - ETA: 25s - loss: 88.5287 - acc: 0.009 - ETA: 25s - loss: 89.0110 - acc: 0.009 - ETA: 24s - loss: 88.1832 - acc: 0.008 - ETA: 24s - loss: 88.4754 - acc: 0.008 - ETA: 24s - loss: 88.9875 - acc: 0.007 - ETA: 23s - loss: 88.7480 - acc: 0.008 - ETA: 23s - loss: 89.2945 - acc: 0.008 - ETA: 23s - loss: 89.0627 - acc: 0.008 - ETA: 22s - loss: 89.1544 - acc: 0.009 - ETA: 22s - loss: 89.2208 - acc: 0.008 - ETA: 22s - loss: 89.0991 - acc: 0.008 - ETA: 21s - loss: 89.0942 - acc: 0.008 - ETA: 21s - loss: 89.4694 - acc: 0.008 - ETA: 21s - loss: 89.4149 - acc: 0.008 - ETA: 21s - loss: 89.3187 - acc: 0.008 - ETA: 20s - loss: 89.4407 - acc: 0.008 - ETA: 20s - loss: 89.2835 - acc: 0.008 - ETA: 20s - loss: 89.1661 - acc: 0.008 - ETA: 19s - loss: 88.9849 - acc: 0.008 - ETA: 19s - loss: 88.9805 - acc: 0.008 - ETA: 19s - loss: 89.1670 - acc: 0.007 - ETA: 18s - loss: 89.1096 - acc: 0.008 - ETA: 18s - loss: 89.1572 - acc: 0.007 - ETA: 18s - loss: 89.0163 - acc: 0.007 - ETA: 18s - loss: 88.8475 - acc: 0.007 - ETA: 17s - loss: 88.9194 - acc: 0.007 - ETA: 17s - loss: 88.8196 - acc: 0.007 - ETA: 17s - loss: 88.7861 - acc: 0.007 - ETA: 17s - loss: 88.8347 - acc: 0.007 - ETA: 17s - loss: 88.4112 - acc: 0.007 - ETA: 16s - loss: 88.3263 - acc: 0.007 - ETA: 16s - loss: 88.3443 - acc: 0.007 - ETA: 16s - loss: 88.3916 - acc: 0.007 - ETA: 16s - loss: 88.5857 - acc: 0.007 - ETA: 16s - loss: 88.5675 - acc: 0.006 - ETA: 15s - loss: 88.4157 - acc: 0.006 - ETA: 15s - loss: 88.3632 - acc: 0.006 - ETA: 15s - loss: 88.5739 - acc: 0.006 - ETA: 15s - loss: 88.4997 - acc: 0.006 - ETA: 15s - loss: 88.6240 - acc: 0.006 - ETA: 14s - loss: 88.4915 - acc: 0.006 - ETA: 14s - loss: 88.4134 - acc: 0.006 - ETA: 14s - loss: 88.4061 - acc: 0.006 - ETA: 13s - loss: 88.4419 - acc: 0.006 - ETA: 13s - loss: 88.5452 - acc: 0.006 - ETA: 13s - loss: 88.6752 - acc: 0.006 - ETA: 12s - loss: 88.6765 - acc: 0.006 - ETA: 12s - loss: 88.6589 - acc: 0.006 - ETA: 12s - loss: 88.6041 - acc: 0.006 - ETA: 11s - loss: 88.5178 - acc: 0.006 - ETA: 11s - loss: 88.4437 - acc: 0.007 - ETA: 11s - loss: 88.5071 - acc: 0.006 - ETA: 10s - loss: 88.4275 - acc: 0.006 - ETA: 10s - loss: 88.3100 - acc: 0.006 - ETA: 10s - loss: 88.2732 - acc: 0.006 - ETA: 9s - loss: 88.2944 - acc: 0.006 - ETA: 9s - loss: 88.2754 - acc: 0.00 - ETA: 9s - loss: 88.2598 - acc: 0.00 - ETA: 8s - loss: 88.2529 - acc: 0.00 - ETA: 8s - loss: 88.2663 - acc: 0.00 - ETA: 8s - loss: 88.2152 - acc: 0.00 - ETA: 8s - loss: 88.2762 - acc: 0.00 - ETA: 7s - loss: 88.3414 - acc: 0.00 - ETA: 7s - loss: 88.3124 - acc: 0.00 - ETA: 7s - loss: 88.2618 - acc: 0.00 - ETA: 6s - loss: 88.2486 - acc: 0.00 - ETA: 6s - loss: 88.1727 - acc: 0.00 - ETA: 6s - loss: 88.1921 - acc: 0.00 - ETA: 5s - loss: 88.1994 - acc: 0.00 - ETA: 5s - loss: 88.1588 - acc: 0.00 - ETA: 5s - loss: 88.1424 - acc: 0.00 - ETA: 5s - loss: 88.1387 - acc: 0.00 - ETA: 4s - loss: 88.1318 - acc: 0.00 - ETA: 4s - loss: 88.2146 - acc: 0.00 - ETA: 4s - loss: 88.2465 - acc: 0.00 - ETA: 3s - loss: 88.2506 - acc: 0.00 - ETA: 3s - loss: 88.2628 - acc: 0.00 - ETA: 3s - loss: 88.2119 - acc: 0.00 - ETA: 2s - loss: 88.2536 - acc: 0.00 - ETA: 2s - loss: 88.2307 - acc: 0.00 - ETA: 2s - loss: 88.3059 - acc: 0.00 - ETA: 2s - loss: 88.2157 - acc: 0.00 - ETA: 1s - loss: 88.2512 - acc: 0.00 - ETA: 1s - loss: 88.2656 - acc: 0.00 - ETA: 1s - loss: 88.3005 - acc: 0.00 - ETA: 0s - loss: 88.3114 - acc: 0.00 - ETA: 0s - loss: 88.2403 - acc: 0.00 - ETA: 0s - loss: 88.2248 - acc: 0.00 - 31s 3ms/step - loss: 88.1693 - acc: 0.0070 - val_loss: 97.7565 - val_acc: 0.0047\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 34s - loss: 87.0661 - acc: 0.0000e+0 - ETA: 34s - loss: 86.1143 - acc: 0.0000e+0 - ETA: 34s - loss: 84.7471 - acc: 0.0052    - ETA: 37s - loss: 85.8901 - acc: 0.003 - ETA: 37s - loss: 85.4291 - acc: 0.006 - ETA: 35s - loss: 85.6400 - acc: 0.006 - ETA: 33s - loss: 85.1354 - acc: 0.010 - ETA: 32s - loss: 85.7792 - acc: 0.009 - ETA: 34s - loss: 86.2932 - acc: 0.008 - ETA: 34s - loss: 86.4333 - acc: 0.008 - ETA: 35s - loss: 86.4849 - acc: 0.008 - ETA: 34s - loss: 86.6392 - acc: 0.008 - ETA: 33s - loss: 86.7878 - acc: 0.007 - ETA: 34s - loss: 87.1583 - acc: 0.008 - ETA: 34s - loss: 87.1011 - acc: 0.008 - ETA: 33s - loss: 86.7251 - acc: 0.007 - ETA: 32s - loss: 86.9141 - acc: 0.008 - ETA: 31s - loss: 87.0473 - acc: 0.007 - ETA: 30s - loss: 86.9522 - acc: 0.007 - ETA: 29s - loss: 86.9274 - acc: 0.008 - ETA: 29s - loss: 87.1209 - acc: 0.008 - ETA: 28s - loss: 87.0726 - acc: 0.008 - ETA: 28s - loss: 87.1098 - acc: 0.008 - ETA: 27s - loss: 87.1343 - acc: 0.008 - ETA: 27s - loss: 87.0094 - acc: 0.008 - ETA: 26s - loss: 87.0902 - acc: 0.008 - ETA: 26s - loss: 87.2263 - acc: 0.008 - ETA: 25s - loss: 87.2980 - acc: 0.007 - ETA: 25s - loss: 87.3484 - acc: 0.008 - ETA: 24s - loss: 87.4871 - acc: 0.008 - ETA: 24s - loss: 87.4322 - acc: 0.008 - ETA: 23s - loss: 87.4853 - acc: 0.007 - ETA: 23s - loss: 87.5222 - acc: 0.008 - ETA: 22s - loss: 87.5605 - acc: 0.009 - ETA: 22s - loss: 87.4645 - acc: 0.008 - ETA: 21s - loss: 87.5767 - acc: 0.008 - ETA: 21s - loss: 87.4728 - acc: 0.008 - ETA: 20s - loss: 87.4493 - acc: 0.008 - ETA: 20s - loss: 87.4373 - acc: 0.008 - ETA: 20s - loss: 87.3302 - acc: 0.008 - ETA: 19s - loss: 87.5143 - acc: 0.008 - ETA: 19s - loss: 87.5559 - acc: 0.008 - ETA: 18s - loss: 87.4329 - acc: 0.008 - ETA: 18s - loss: 87.6516 - acc: 0.008 - ETA: 18s - loss: 87.6951 - acc: 0.008 - ETA: 17s - loss: 87.6949 - acc: 0.008 - ETA: 17s - loss: 87.6689 - acc: 0.008 - ETA: 16s - loss: 87.7077 - acc: 0.008 - ETA: 16s - loss: 87.6981 - acc: 0.008 - ETA: 16s - loss: 87.8208 - acc: 0.008 - ETA: 15s - loss: 87.9779 - acc: 0.008 - ETA: 15s - loss: 87.9795 - acc: 0.008 - ETA: 14s - loss: 87.8584 - acc: 0.008 - ETA: 14s - loss: 87.9675 - acc: 0.008 - ETA: 14s - loss: 87.9997 - acc: 0.008 - ETA: 13s - loss: 88.0978 - acc: 0.008 - ETA: 13s - loss: 88.1190 - acc: 0.008 - ETA: 12s - loss: 88.2616 - acc: 0.008 - ETA: 12s - loss: 88.2482 - acc: 0.008 - ETA: 12s - loss: 88.2327 - acc: 0.008 - ETA: 11s - loss: 88.2025 - acc: 0.008 - ETA: 11s - loss: 88.2260 - acc: 0.008 - ETA: 11s - loss: 88.2201 - acc: 0.008 - ETA: 10s - loss: 88.2335 - acc: 0.008 - ETA: 10s - loss: 88.1413 - acc: 0.008 - ETA: 10s - loss: 88.0695 - acc: 0.008 - ETA: 9s - loss: 88.1072 - acc: 0.008 - ETA: 9s - loss: 88.2279 - acc: 0.00 - ETA: 8s - loss: 88.2781 - acc: 0.00 - ETA: 8s - loss: 88.2293 - acc: 0.00 - ETA: 8s - loss: 88.2191 - acc: 0.00 - ETA: 7s - loss: 88.3157 - acc: 0.00 - ETA: 7s - loss: 88.3496 - acc: 0.00 - ETA: 7s - loss: 88.4838 - acc: 0.00 - ETA: 6s - loss: 88.4646 - acc: 0.00 - ETA: 6s - loss: 88.4039 - acc: 0.00 - ETA: 5s - loss: 88.3921 - acc: 0.00 - ETA: 5s - loss: 88.3348 - acc: 0.00 - ETA: 5s - loss: 88.3041 - acc: 0.00 - ETA: 4s - loss: 88.3062 - acc: 0.00 - ETA: 4s - loss: 88.2572 - acc: 0.00 - ETA: 4s - loss: 88.2497 - acc: 0.00 - ETA: 3s - loss: 88.2149 - acc: 0.00 - ETA: 3s - loss: 88.1215 - acc: 0.00 - ETA: 2s - loss: 88.0269 - acc: 0.00 - ETA: 2s - loss: 88.0520 - acc: 0.00 - ETA: 2s - loss: 88.0271 - acc: 0.00 - ETA: 1s - loss: 88.0324 - acc: 0.00 - ETA: 1s - loss: 88.1185 - acc: 0.00 - ETA: 1s - loss: 88.0965 - acc: 0.00 - ETA: 0s - loss: 88.1188 - acc: 0.00 - ETA: 0s - loss: 88.1604 - acc: 0.00 - 38s 3ms/step - loss: 88.1254 - acc: 0.0081 - val_loss: 97.7583 - val_acc: 0.0047\n",
      "Epoch 14/20\n",
      "11904/11904 [==============================] - ETA: 30s - loss: 81.9804 - acc: 0.015 - ETA: 29s - loss: 83.9900 - acc: 0.011 - ETA: 29s - loss: 85.8068 - acc: 0.007 - ETA: 32s - loss: 85.1893 - acc: 0.005 - ETA: 31s - loss: 85.8685 - acc: 0.006 - ETA: 30s - loss: 86.6965 - acc: 0.006 - ETA: 30s - loss: 85.6526 - acc: 0.005 - ETA: 29s - loss: 85.9949 - acc: 0.005 - ETA: 29s - loss: 86.6631 - acc: 0.005 - ETA: 28s - loss: 86.3410 - acc: 0.005 - ETA: 28s - loss: 86.0598 - acc: 0.006 - ETA: 27s - loss: 86.2520 - acc: 0.008 - ETA: 27s - loss: 86.4931 - acc: 0.008 - ETA: 27s - loss: 86.7132 - acc: 0.008 - ETA: 26s - loss: 87.0938 - acc: 0.008 - ETA: 26s - loss: 87.4158 - acc: 0.009 - ETA: 25s - loss: 87.1827 - acc: 0.009 - ETA: 25s - loss: 87.5105 - acc: 0.008 - ETA: 25s - loss: 87.5798 - acc: 0.008 - ETA: 25s - loss: 87.7445 - acc: 0.009 - ETA: 24s - loss: 87.9860 - acc: 0.008 - ETA: 24s - loss: 88.2331 - acc: 0.008 - ETA: 24s - loss: 88.0870 - acc: 0.008 - ETA: 23s - loss: 88.0590 - acc: 0.008 - ETA: 23s - loss: 87.9516 - acc: 0.008 - ETA: 23s - loss: 88.0236 - acc: 0.008 - ETA: 22s - loss: 88.0856 - acc: 0.008 - ETA: 22s - loss: 88.0308 - acc: 0.008 - ETA: 22s - loss: 87.8569 - acc: 0.008 - ETA: 21s - loss: 87.7650 - acc: 0.009 - ETA: 21s - loss: 87.7243 - acc: 0.008 - ETA: 21s - loss: 87.7115 - acc: 0.008 - ETA: 21s - loss: 87.6134 - acc: 0.008 - ETA: 21s - loss: 87.8241 - acc: 0.008 - ETA: 21s - loss: 87.6691 - acc: 0.008 - ETA: 20s - loss: 87.7796 - acc: 0.008 - ETA: 20s - loss: 87.5790 - acc: 0.008 - ETA: 20s - loss: 87.5299 - acc: 0.008 - ETA: 19s - loss: 87.3806 - acc: 0.008 - ETA: 19s - loss: 87.4534 - acc: 0.009 - ETA: 18s - loss: 87.3847 - acc: 0.008 - ETA: 18s - loss: 87.3605 - acc: 0.008 - ETA: 18s - loss: 87.6165 - acc: 0.008 - ETA: 17s - loss: 87.6473 - acc: 0.008 - ETA: 17s - loss: 87.7024 - acc: 0.008 - ETA: 17s - loss: 87.7479 - acc: 0.008 - ETA: 16s - loss: 87.7623 - acc: 0.008 - ETA: 16s - loss: 87.7472 - acc: 0.008 - ETA: 15s - loss: 87.6853 - acc: 0.008 - ETA: 15s - loss: 87.5076 - acc: 0.008 - ETA: 15s - loss: 87.4906 - acc: 0.008 - ETA: 14s - loss: 87.5868 - acc: 0.008 - ETA: 14s - loss: 87.5964 - acc: 0.008 - ETA: 14s - loss: 87.6416 - acc: 0.008 - ETA: 13s - loss: 87.5185 - acc: 0.008 - ETA: 13s - loss: 87.5458 - acc: 0.008 - ETA: 12s - loss: 87.6075 - acc: 0.007 - ETA: 12s - loss: 87.8241 - acc: 0.007 - ETA: 12s - loss: 87.7560 - acc: 0.007 - ETA: 11s - loss: 87.7516 - acc: 0.007 - ETA: 11s - loss: 87.8334 - acc: 0.007 - ETA: 11s - loss: 87.8929 - acc: 0.007 - ETA: 10s - loss: 87.9611 - acc: 0.007 - ETA: 10s - loss: 88.0233 - acc: 0.007 - ETA: 9s - loss: 87.9424 - acc: 0.007 - ETA: 9s - loss: 87.8792 - acc: 0.00 - ETA: 9s - loss: 87.8549 - acc: 0.00 - ETA: 8s - loss: 87.8546 - acc: 0.00 - ETA: 8s - loss: 87.8267 - acc: 0.00 - ETA: 8s - loss: 87.8476 - acc: 0.00 - ETA: 7s - loss: 87.8853 - acc: 0.00 - ETA: 7s - loss: 87.8991 - acc: 0.00 - ETA: 7s - loss: 87.9345 - acc: 0.00 - ETA: 6s - loss: 88.0404 - acc: 0.00 - ETA: 6s - loss: 88.1662 - acc: 0.00 - ETA: 6s - loss: 88.1780 - acc: 0.00 - ETA: 5s - loss: 88.1256 - acc: 0.00 - ETA: 5s - loss: 88.1488 - acc: 0.00 - ETA: 4s - loss: 88.1530 - acc: 0.00 - ETA: 4s - loss: 88.0862 - acc: 0.00 - ETA: 4s - loss: 88.1184 - acc: 0.00 - ETA: 3s - loss: 88.1218 - acc: 0.00 - ETA: 3s - loss: 88.1009 - acc: 0.00 - ETA: 3s - loss: 88.0742 - acc: 0.00 - ETA: 2s - loss: 88.1093 - acc: 0.00 - ETA: 2s - loss: 88.1022 - acc: 0.00 - ETA: 2s - loss: 88.1005 - acc: 0.00 - ETA: 1s - loss: 88.1043 - acc: 0.00 - ETA: 1s - loss: 88.1082 - acc: 0.00 - ETA: 1s - loss: 88.1792 - acc: 0.00 - ETA: 0s - loss: 88.0980 - acc: 0.00 - ETA: 0s - loss: 88.0855 - acc: 0.00 - 37s 3ms/step - loss: 88.1075 - acc: 0.0070 - val_loss: 97.7555 - val_acc: 0.0047\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 30s - loss: 89.8401 - acc: 0.007 - ETA: 29s - loss: 90.3561 - acc: 0.007 - ETA: 29s - loss: 90.7848 - acc: 0.005 - ETA: 29s - loss: 89.9780 - acc: 0.003 - ETA: 30s - loss: 90.3524 - acc: 0.006 - ETA: 30s - loss: 90.0604 - acc: 0.005 - ETA: 30s - loss: 89.6414 - acc: 0.004 - ETA: 30s - loss: 89.5550 - acc: 0.003 - ETA: 29s - loss: 89.5457 - acc: 0.003 - ETA: 29s - loss: 89.3618 - acc: 0.003 - ETA: 28s - loss: 89.4964 - acc: 0.005 - ETA: 28s - loss: 89.9040 - acc: 0.005 - ETA: 28s - loss: 89.8757 - acc: 0.004 - ETA: 28s - loss: 89.0872 - acc: 0.004 - ETA: 27s - loss: 89.0485 - acc: 0.004 - ETA: 27s - loss: 88.9240 - acc: 0.004 - ETA: 26s - loss: 88.7457 - acc: 0.004 - ETA: 26s - loss: 88.7011 - acc: 0.004 - ETA: 25s - loss: 88.8104 - acc: 0.004 - ETA: 25s - loss: 88.1907 - acc: 0.004 - ETA: 25s - loss: 87.8771 - acc: 0.005 - ETA: 25s - loss: 87.9666 - acc: 0.005 - ETA: 24s - loss: 87.9853 - acc: 0.005 - ETA: 24s - loss: 88.0465 - acc: 0.005 - ETA: 24s - loss: 88.0025 - acc: 0.006 - ETA: 24s - loss: 88.1049 - acc: 0.006 - ETA: 23s - loss: 88.2003 - acc: 0.005 - ETA: 23s - loss: 88.0200 - acc: 0.006 - ETA: 22s - loss: 88.2020 - acc: 0.005 - ETA: 22s - loss: 88.1476 - acc: 0.006 - ETA: 21s - loss: 88.2530 - acc: 0.006 - ETA: 21s - loss: 88.2402 - acc: 0.006 - ETA: 21s - loss: 88.2532 - acc: 0.006 - ETA: 20s - loss: 88.2091 - acc: 0.006 - ETA: 20s - loss: 88.1193 - acc: 0.006 - ETA: 20s - loss: 88.2887 - acc: 0.006 - ETA: 19s - loss: 88.2664 - acc: 0.007 - ETA: 19s - loss: 88.1218 - acc: 0.006 - ETA: 19s - loss: 88.0922 - acc: 0.007 - ETA: 18s - loss: 88.1913 - acc: 0.007 - ETA: 18s - loss: 88.1917 - acc: 0.007 - ETA: 17s - loss: 88.0621 - acc: 0.007 - ETA: 17s - loss: 87.8315 - acc: 0.007 - ETA: 17s - loss: 87.9801 - acc: 0.007 - ETA: 16s - loss: 88.0640 - acc: 0.007 - ETA: 16s - loss: 88.0528 - acc: 0.007 - ETA: 16s - loss: 88.0955 - acc: 0.007 - ETA: 15s - loss: 88.1991 - acc: 0.007 - ETA: 15s - loss: 88.2200 - acc: 0.006 - ETA: 15s - loss: 88.1995 - acc: 0.006 - ETA: 14s - loss: 88.2519 - acc: 0.006 - ETA: 14s - loss: 88.4433 - acc: 0.006 - ETA: 13s - loss: 88.3370 - acc: 0.006 - ETA: 13s - loss: 88.4640 - acc: 0.007 - ETA: 13s - loss: 88.4149 - acc: 0.007 - ETA: 12s - loss: 88.3930 - acc: 0.007 - ETA: 12s - loss: 88.3840 - acc: 0.007 - ETA: 12s - loss: 88.3878 - acc: 0.007 - ETA: 11s - loss: 88.2926 - acc: 0.007 - ETA: 11s - loss: 88.2891 - acc: 0.007 - ETA: 11s - loss: 88.2046 - acc: 0.007 - ETA: 10s - loss: 88.1923 - acc: 0.007 - ETA: 10s - loss: 88.1724 - acc: 0.007 - ETA: 10s - loss: 88.0651 - acc: 0.007 - ETA: 9s - loss: 88.0621 - acc: 0.007 - ETA: 9s - loss: 88.0004 - acc: 0.00 - ETA: 9s - loss: 87.9520 - acc: 0.00 - ETA: 8s - loss: 87.9261 - acc: 0.00 - ETA: 8s - loss: 88.0362 - acc: 0.00 - ETA: 8s - loss: 88.0402 - acc: 0.00 - ETA: 7s - loss: 87.9958 - acc: 0.00 - ETA: 7s - loss: 87.9445 - acc: 0.00 - ETA: 6s - loss: 87.9480 - acc: 0.00 - ETA: 6s - loss: 87.9145 - acc: 0.00 - ETA: 6s - loss: 87.8438 - acc: 0.00 - ETA: 5s - loss: 87.8562 - acc: 0.00 - ETA: 5s - loss: 87.8612 - acc: 0.00 - ETA: 5s - loss: 87.7832 - acc: 0.00 - ETA: 4s - loss: 87.7636 - acc: 0.00 - ETA: 4s - loss: 87.8678 - acc: 0.00 - ETA: 4s - loss: 87.8018 - acc: 0.00 - ETA: 3s - loss: 87.8805 - acc: 0.00 - ETA: 3s - loss: 87.9670 - acc: 0.00 - ETA: 3s - loss: 88.0429 - acc: 0.00 - ETA: 2s - loss: 87.9939 - acc: 0.00 - ETA: 2s - loss: 87.9893 - acc: 0.00 - ETA: 2s - loss: 87.9981 - acc: 0.00 - ETA: 1s - loss: 88.0670 - acc: 0.00 - ETA: 1s - loss: 88.0847 - acc: 0.00 - ETA: 1s - loss: 88.1570 - acc: 0.00 - ETA: 0s - loss: 88.1772 - acc: 0.00 - ETA: 0s - loss: 88.1291 - acc: 0.00 - 36s 3ms/step - loss: 88.0919 - acc: 0.0069 - val_loss: 97.7558 - val_acc: 0.0047\n",
      "Epoch 16/20\n",
      "11904/11904 [==============================] - ETA: 29s - loss: 91.0672 - acc: 0.0000e+0 - ETA: 30s - loss: 89.4381 - acc: 0.0117    - ETA: 31s - loss: 91.4712 - acc: 0.013 - ETA: 31s - loss: 89.0830 - acc: 0.009 - ETA: 30s - loss: 88.0803 - acc: 0.009 - ETA: 29s - loss: 88.1547 - acc: 0.011 - ETA: 29s - loss: 89.0893 - acc: 0.011 - ETA: 28s - loss: 89.4778 - acc: 0.010 - ETA: 27s - loss: 89.1162 - acc: 0.010 - ETA: 27s - loss: 88.7437 - acc: 0.010 - ETA: 26s - loss: 88.1307 - acc: 0.009 - ETA: 26s - loss: 87.3531 - acc: 0.009 - ETA: 26s - loss: 87.3485 - acc: 0.008 - ETA: 25s - loss: 87.6360 - acc: 0.007 - ETA: 25s - loss: 87.7026 - acc: 0.007 - ETA: 25s - loss: 87.8749 - acc: 0.007 - ETA: 24s - loss: 87.9147 - acc: 0.008 - ETA: 24s - loss: 87.8070 - acc: 0.009 - ETA: 23s - loss: 88.1820 - acc: 0.008 - ETA: 23s - loss: 88.2739 - acc: 0.008 - ETA: 23s - loss: 88.6121 - acc: 0.008 - ETA: 23s - loss: 88.5381 - acc: 0.008 - ETA: 22s - loss: 88.4695 - acc: 0.008 - ETA: 22s - loss: 88.6105 - acc: 0.007 - ETA: 22s - loss: 88.5704 - acc: 0.007 - ETA: 21s - loss: 88.6489 - acc: 0.007 - ETA: 21s - loss: 88.7574 - acc: 0.007 - ETA: 21s - loss: 88.8685 - acc: 0.007 - ETA: 21s - loss: 88.8966 - acc: 0.007 - ETA: 20s - loss: 88.7420 - acc: 0.007 - ETA: 20s - loss: 88.6137 - acc: 0.007 - ETA: 20s - loss: 88.3762 - acc: 0.007 - ETA: 19s - loss: 88.4260 - acc: 0.007 - ETA: 19s - loss: 88.3607 - acc: 0.007 - ETA: 19s - loss: 88.3204 - acc: 0.007 - ETA: 19s - loss: 88.1565 - acc: 0.007 - ETA: 18s - loss: 88.0371 - acc: 0.007 - ETA: 18s - loss: 87.9476 - acc: 0.007 - ETA: 18s - loss: 87.9672 - acc: 0.007 - ETA: 17s - loss: 87.9569 - acc: 0.007 - ETA: 17s - loss: 88.0616 - acc: 0.007 - ETA: 17s - loss: 88.0839 - acc: 0.007 - ETA: 16s - loss: 88.1074 - acc: 0.007 - ETA: 16s - loss: 88.1123 - acc: 0.007 - ETA: 15s - loss: 88.1841 - acc: 0.008 - ETA: 15s - loss: 88.2434 - acc: 0.008 - ETA: 15s - loss: 88.2331 - acc: 0.008 - ETA: 15s - loss: 88.1917 - acc: 0.007 - ETA: 14s - loss: 88.1918 - acc: 0.008 - ETA: 14s - loss: 88.1276 - acc: 0.008 - ETA: 14s - loss: 88.0576 - acc: 0.008 - ETA: 13s - loss: 88.0927 - acc: 0.008 - ETA: 13s - loss: 88.1582 - acc: 0.008 - ETA: 13s - loss: 88.1030 - acc: 0.008 - ETA: 12s - loss: 88.1302 - acc: 0.008 - ETA: 12s - loss: 88.0526 - acc: 0.008 - ETA: 12s - loss: 88.0606 - acc: 0.008 - ETA: 11s - loss: 88.0939 - acc: 0.008 - ETA: 11s - loss: 88.1879 - acc: 0.008 - ETA: 11s - loss: 88.1532 - acc: 0.008 - ETA: 10s - loss: 88.1467 - acc: 0.008 - ETA: 10s - loss: 88.1163 - acc: 0.008 - ETA: 10s - loss: 88.1014 - acc: 0.008 - ETA: 9s - loss: 88.1246 - acc: 0.008 - ETA: 9s - loss: 88.1213 - acc: 0.00 - ETA: 9s - loss: 88.0907 - acc: 0.00 - ETA: 8s - loss: 88.0368 - acc: 0.00 - ETA: 8s - loss: 87.9787 - acc: 0.00 - ETA: 8s - loss: 88.0401 - acc: 0.00 - ETA: 7s - loss: 87.9987 - acc: 0.00 - ETA: 7s - loss: 88.0213 - acc: 0.00 - ETA: 7s - loss: 87.9822 - acc: 0.00 - ETA: 6s - loss: 87.9491 - acc: 0.00 - ETA: 6s - loss: 87.8787 - acc: 0.00 - ETA: 6s - loss: 87.7663 - acc: 0.00 - ETA: 5s - loss: 87.7448 - acc: 0.00 - ETA: 5s - loss: 87.7562 - acc: 0.00 - ETA: 5s - loss: 87.6967 - acc: 0.00 - ETA: 4s - loss: 87.6700 - acc: 0.00 - ETA: 4s - loss: 87.6518 - acc: 0.00 - ETA: 4s - loss: 87.6654 - acc: 0.00 - ETA: 3s - loss: 87.7017 - acc: 0.00 - ETA: 3s - loss: 87.7990 - acc: 0.00 - ETA: 3s - loss: 87.8276 - acc: 0.00 - ETA: 2s - loss: 87.9187 - acc: 0.00 - ETA: 2s - loss: 87.9329 - acc: 0.00 - ETA: 2s - loss: 87.9907 - acc: 0.00 - ETA: 1s - loss: 87.9568 - acc: 0.00 - ETA: 1s - loss: 87.9495 - acc: 0.00 - ETA: 1s - loss: 87.9950 - acc: 0.00 - ETA: 0s - loss: 88.0206 - acc: 0.00 - ETA: 0s - loss: 88.0642 - acc: 0.00 - 35s 3ms/step - loss: 88.0728 - acc: 0.0072 - val_loss: 97.7561 - val_acc: 0.0047\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 37s - loss: 85.7332 - acc: 0.023 - ETA: 33s - loss: 85.1365 - acc: 0.019 - ETA: 31s - loss: 83.0355 - acc: 0.013 - ETA: 30s - loss: 85.0601 - acc: 0.011 - ETA: 30s - loss: 85.0894 - acc: 0.012 - ETA: 29s - loss: 85.1185 - acc: 0.013 - ETA: 29s - loss: 84.8271 - acc: 0.014 - ETA: 28s - loss: 85.2062 - acc: 0.013 - ETA: 28s - loss: 85.4022 - acc: 0.013 - ETA: 27s - loss: 85.5642 - acc: 0.012 - ETA: 28s - loss: 86.5514 - acc: 0.012 - ETA: 27s - loss: 86.9578 - acc: 0.011 - ETA: 27s - loss: 86.7875 - acc: 0.010 - ETA: 27s - loss: 86.8517 - acc: 0.010 - ETA: 26s - loss: 86.8347 - acc: 0.009 - ETA: 26s - loss: 86.9521 - acc: 0.009 - ETA: 26s - loss: 87.0605 - acc: 0.009 - ETA: 25s - loss: 87.3396 - acc: 0.009 - ETA: 25s - loss: 87.1079 - acc: 0.008 - ETA: 25s - loss: 87.2312 - acc: 0.008 - ETA: 24s - loss: 87.3179 - acc: 0.007 - ETA: 24s - loss: 87.5543 - acc: 0.007 - ETA: 24s - loss: 87.9775 - acc: 0.007 - ETA: 23s - loss: 88.1164 - acc: 0.007 - ETA: 23s - loss: 88.0809 - acc: 0.007 - ETA: 22s - loss: 88.1325 - acc: 0.007 - ETA: 22s - loss: 88.1974 - acc: 0.007 - ETA: 22s - loss: 88.0606 - acc: 0.007 - ETA: 21s - loss: 88.2623 - acc: 0.007 - ETA: 21s - loss: 88.1801 - acc: 0.007 - ETA: 21s - loss: 88.0866 - acc: 0.007 - ETA: 20s - loss: 87.9672 - acc: 0.008 - ETA: 20s - loss: 87.9138 - acc: 0.007 - ETA: 20s - loss: 87.8725 - acc: 0.007 - ETA: 19s - loss: 87.8508 - acc: 0.007 - ETA: 19s - loss: 87.7965 - acc: 0.007 - ETA: 19s - loss: 87.8457 - acc: 0.007 - ETA: 18s - loss: 87.9148 - acc: 0.007 - ETA: 18s - loss: 87.8314 - acc: 0.007 - ETA: 18s - loss: 87.8782 - acc: 0.007 - ETA: 17s - loss: 87.7734 - acc: 0.007 - ETA: 17s - loss: 87.7484 - acc: 0.007 - ETA: 17s - loss: 87.8881 - acc: 0.007 - ETA: 16s - loss: 87.8902 - acc: 0.007 - ETA: 16s - loss: 87.8219 - acc: 0.007 - ETA: 16s - loss: 87.7613 - acc: 0.007 - ETA: 15s - loss: 87.8833 - acc: 0.007 - ETA: 15s - loss: 87.8889 - acc: 0.007 - ETA: 15s - loss: 87.9046 - acc: 0.007 - ETA: 14s - loss: 87.9821 - acc: 0.007 - ETA: 14s - loss: 88.0791 - acc: 0.007 - ETA: 14s - loss: 88.0231 - acc: 0.007 - ETA: 13s - loss: 88.1055 - acc: 0.007 - ETA: 13s - loss: 88.0652 - acc: 0.007 - ETA: 13s - loss: 88.0302 - acc: 0.007 - ETA: 12s - loss: 88.0641 - acc: 0.007 - ETA: 12s - loss: 88.0791 - acc: 0.007 - ETA: 11s - loss: 88.0674 - acc: 0.006 - ETA: 11s - loss: 88.0851 - acc: 0.006 - ETA: 11s - loss: 88.1292 - acc: 0.006 - ETA: 10s - loss: 88.1025 - acc: 0.006 - ETA: 10s - loss: 87.9105 - acc: 0.006 - ETA: 10s - loss: 87.9707 - acc: 0.006 - ETA: 9s - loss: 88.0066 - acc: 0.006 - ETA: 9s - loss: 88.0247 - acc: 0.00 - ETA: 9s - loss: 87.9495 - acc: 0.00 - ETA: 8s - loss: 87.8676 - acc: 0.00 - ETA: 8s - loss: 87.8759 - acc: 0.00 - ETA: 8s - loss: 87.8831 - acc: 0.00 - ETA: 7s - loss: 87.9017 - acc: 0.00 - ETA: 7s - loss: 87.8668 - acc: 0.00 - ETA: 7s - loss: 87.8801 - acc: 0.00 - ETA: 6s - loss: 87.9975 - acc: 0.00 - ETA: 6s - loss: 88.0091 - acc: 0.00 - ETA: 6s - loss: 88.0671 - acc: 0.00 - ETA: 6s - loss: 88.0428 - acc: 0.00 - ETA: 5s - loss: 88.0317 - acc: 0.00 - ETA: 5s - loss: 88.0755 - acc: 0.00 - ETA: 5s - loss: 88.0594 - acc: 0.00 - ETA: 4s - loss: 88.1039 - acc: 0.00 - ETA: 4s - loss: 88.1285 - acc: 0.00 - ETA: 3s - loss: 88.1145 - acc: 0.00 - ETA: 3s - loss: 88.1483 - acc: 0.00 - ETA: 3s - loss: 88.1015 - acc: 0.00 - ETA: 2s - loss: 88.1175 - acc: 0.00 - ETA: 2s - loss: 87.9674 - acc: 0.00 - ETA: 2s - loss: 87.9325 - acc: 0.00 - ETA: 1s - loss: 87.9129 - acc: 0.00 - ETA: 1s - loss: 87.9862 - acc: 0.00 - ETA: 1s - loss: 88.0164 - acc: 0.00 - ETA: 0s - loss: 87.9974 - acc: 0.00 - ETA: 0s - loss: 87.9801 - acc: 0.00 - 39s 3ms/step - loss: 88.0349 - acc: 0.0067 - val_loss: 97.7538 - val_acc: 0.0047\n",
      "Epoch 18/20\n",
      "11904/11904 [==============================] - ETA: 49s - loss: 91.9917 - acc: 0.0000e+0 - ETA: 58s - loss: 90.1527 - acc: 0.0039    - ETA: 55s - loss: 88.1518 - acc: 0.002 - ETA: 54s - loss: 88.3973 - acc: 0.002 - ETA: 49s - loss: 89.1508 - acc: 0.004 - ETA: 49s - loss: 89.2871 - acc: 0.003 - ETA: 46s - loss: 89.2224 - acc: 0.004 - ETA: 44s - loss: 88.8641 - acc: 0.004 - ETA: 42s - loss: 88.0569 - acc: 0.005 - ETA: 40s - loss: 88.4286 - acc: 0.004 - ETA: 39s - loss: 87.9508 - acc: 0.004 - ETA: 38s - loss: 88.5289 - acc: 0.003 - ETA: 37s - loss: 88.3394 - acc: 0.003 - ETA: 36s - loss: 88.1305 - acc: 0.004 - ETA: 35s - loss: 87.9870 - acc: 0.004 - ETA: 34s - loss: 88.1117 - acc: 0.005 - ETA: 33s - loss: 88.4449 - acc: 0.006 - ETA: 33s - loss: 88.1105 - acc: 0.005 - ETA: 32s - loss: 88.2519 - acc: 0.005 - ETA: 32s - loss: 88.4730 - acc: 0.005 - ETA: 31s - loss: 88.7828 - acc: 0.004 - ETA: 32s - loss: 88.6858 - acc: 0.004 - ETA: 32s - loss: 88.7166 - acc: 0.004 - ETA: 32s - loss: 88.7257 - acc: 0.004 - ETA: 31s - loss: 88.4684 - acc: 0.004 - ETA: 30s - loss: 88.2467 - acc: 0.004 - ETA: 30s - loss: 88.4558 - acc: 0.004 - ETA: 30s - loss: 88.4687 - acc: 0.004 - ETA: 29s - loss: 88.3719 - acc: 0.004 - ETA: 29s - loss: 88.1022 - acc: 0.005 - ETA: 28s - loss: 87.9484 - acc: 0.005 - ETA: 27s - loss: 87.8697 - acc: 0.005 - ETA: 27s - loss: 87.8148 - acc: 0.005 - ETA: 26s - loss: 88.0393 - acc: 0.005 - ETA: 25s - loss: 88.0724 - acc: 0.005 - ETA: 25s - loss: 88.1277 - acc: 0.005 - ETA: 24s - loss: 88.2309 - acc: 0.005 - ETA: 23s - loss: 88.2552 - acc: 0.004 - ETA: 23s - loss: 88.2154 - acc: 0.005 - ETA: 22s - loss: 88.3186 - acc: 0.005 - ETA: 22s - loss: 88.3949 - acc: 0.005 - ETA: 21s - loss: 88.3610 - acc: 0.005 - ETA: 21s - loss: 88.3978 - acc: 0.005 - ETA: 20s - loss: 88.4699 - acc: 0.005 - ETA: 20s - loss: 88.5054 - acc: 0.005 - ETA: 19s - loss: 88.3872 - acc: 0.005 - ETA: 19s - loss: 88.4248 - acc: 0.005 - ETA: 18s - loss: 88.4556 - acc: 0.005 - ETA: 18s - loss: 88.4326 - acc: 0.005 - ETA: 17s - loss: 88.5397 - acc: 0.005 - ETA: 17s - loss: 88.4803 - acc: 0.005 - ETA: 16s - loss: 88.4765 - acc: 0.005 - ETA: 16s - loss: 88.4313 - acc: 0.006 - ETA: 15s - loss: 88.4059 - acc: 0.006 - ETA: 15s - loss: 88.4225 - acc: 0.006 - ETA: 15s - loss: 88.2922 - acc: 0.006 - ETA: 14s - loss: 88.2961 - acc: 0.006 - ETA: 14s - loss: 88.2703 - acc: 0.006 - ETA: 13s - loss: 88.2779 - acc: 0.006 - ETA: 13s - loss: 88.2008 - acc: 0.006 - ETA: 12s - loss: 88.2780 - acc: 0.006 - ETA: 12s - loss: 88.1452 - acc: 0.006 - ETA: 11s - loss: 88.1981 - acc: 0.006 - ETA: 11s - loss: 88.1934 - acc: 0.006 - ETA: 11s - loss: 88.1377 - acc: 0.006 - ETA: 10s - loss: 88.1096 - acc: 0.006 - ETA: 10s - loss: 88.1424 - acc: 0.006 - ETA: 9s - loss: 88.1971 - acc: 0.006 - ETA: 9s - loss: 88.2635 - acc: 0.00 - ETA: 9s - loss: 88.2494 - acc: 0.00 - ETA: 8s - loss: 88.2053 - acc: 0.00 - ETA: 8s - loss: 88.2370 - acc: 0.00 - ETA: 7s - loss: 88.2110 - acc: 0.00 - ETA: 7s - loss: 88.1248 - acc: 0.00 - ETA: 7s - loss: 88.0816 - acc: 0.00 - ETA: 6s - loss: 88.1347 - acc: 0.00 - ETA: 6s - loss: 88.1488 - acc: 0.00 - ETA: 5s - loss: 88.1686 - acc: 0.00 - ETA: 5s - loss: 88.2085 - acc: 0.00 - ETA: 5s - loss: 88.2651 - acc: 0.00 - ETA: 4s - loss: 88.1898 - acc: 0.00 - ETA: 4s - loss: 88.3245 - acc: 0.00 - ETA: 3s - loss: 88.2847 - acc: 0.00 - ETA: 3s - loss: 88.2227 - acc: 0.00 - ETA: 3s - loss: 88.1710 - acc: 0.00 - ETA: 2s - loss: 88.1468 - acc: 0.00 - ETA: 2s - loss: 88.1082 - acc: 0.00 - ETA: 1s - loss: 88.0225 - acc: 0.00 - ETA: 1s - loss: 87.9530 - acc: 0.00 - ETA: 1s - loss: 87.9248 - acc: 0.00 - ETA: 0s - loss: 88.0066 - acc: 0.00 - ETA: 0s - loss: 87.9645 - acc: 0.00 - 39s 3ms/step - loss: 88.0198 - acc: 0.0066 - val_loss: 97.7566 - val_acc: 0.0047\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/11904 [==============================] - ETA: 28s - loss: 82.8329 - acc: 0.015 - ETA: 28s - loss: 88.1995 - acc: 0.007 - ETA: 29s - loss: 89.0977 - acc: 0.005 - ETA: 29s - loss: 87.3334 - acc: 0.007 - ETA: 28s - loss: 88.4415 - acc: 0.006 - ETA: 28s - loss: 87.6733 - acc: 0.005 - ETA: 27s - loss: 87.5771 - acc: 0.004 - ETA: 27s - loss: 87.4294 - acc: 0.003 - ETA: 27s - loss: 87.3791 - acc: 0.003 - ETA: 27s - loss: 87.2561 - acc: 0.003 - ETA: 26s - loss: 87.0072 - acc: 0.003 - ETA: 26s - loss: 87.1480 - acc: 0.003 - ETA: 26s - loss: 87.3039 - acc: 0.004 - ETA: 26s - loss: 87.3638 - acc: 0.004 - ETA: 25s - loss: 87.3952 - acc: 0.004 - ETA: 25s - loss: 87.8791 - acc: 0.003 - ETA: 25s - loss: 88.5062 - acc: 0.004 - ETA: 24s - loss: 88.3002 - acc: 0.003 - ETA: 24s - loss: 88.0014 - acc: 0.004 - ETA: 24s - loss: 87.9610 - acc: 0.004 - ETA: 23s - loss: 88.0073 - acc: 0.004 - ETA: 23s - loss: 87.9362 - acc: 0.005 - ETA: 23s - loss: 87.8293 - acc: 0.005 - ETA: 22s - loss: 87.6125 - acc: 0.005 - ETA: 22s - loss: 87.5381 - acc: 0.005 - ETA: 22s - loss: 87.4949 - acc: 0.005 - ETA: 21s - loss: 87.3353 - acc: 0.005 - ETA: 21s - loss: 87.2658 - acc: 0.005 - ETA: 21s - loss: 87.4419 - acc: 0.005 - ETA: 20s - loss: 87.5242 - acc: 0.005 - ETA: 20s - loss: 87.7205 - acc: 0.005 - ETA: 20s - loss: 87.9168 - acc: 0.005 - ETA: 19s - loss: 87.8606 - acc: 0.005 - ETA: 19s - loss: 87.7621 - acc: 0.005 - ETA: 19s - loss: 87.5925 - acc: 0.004 - ETA: 18s - loss: 87.6464 - acc: 0.004 - ETA: 18s - loss: 87.5617 - acc: 0.005 - ETA: 18s - loss: 87.4194 - acc: 0.005 - ETA: 17s - loss: 87.5046 - acc: 0.005 - ETA: 17s - loss: 87.5635 - acc: 0.005 - ETA: 17s - loss: 87.6782 - acc: 0.005 - ETA: 16s - loss: 87.7164 - acc: 0.005 - ETA: 16s - loss: 87.5890 - acc: 0.005 - ETA: 16s - loss: 87.6887 - acc: 0.005 - ETA: 15s - loss: 87.6633 - acc: 0.005 - ETA: 15s - loss: 87.7842 - acc: 0.005 - ETA: 15s - loss: 87.8647 - acc: 0.005 - ETA: 14s - loss: 87.9652 - acc: 0.005 - ETA: 14s - loss: 88.1154 - acc: 0.005 - ETA: 14s - loss: 88.0833 - acc: 0.005 - ETA: 13s - loss: 88.0943 - acc: 0.005 - ETA: 13s - loss: 88.0698 - acc: 0.005 - ETA: 13s - loss: 88.2532 - acc: 0.005 - ETA: 12s - loss: 88.1184 - acc: 0.005 - ETA: 12s - loss: 88.2274 - acc: 0.005 - ETA: 12s - loss: 88.3201 - acc: 0.005 - ETA: 11s - loss: 88.3505 - acc: 0.005 - ETA: 11s - loss: 88.3582 - acc: 0.005 - ETA: 11s - loss: 88.3773 - acc: 0.005 - ETA: 10s - loss: 88.3691 - acc: 0.005 - ETA: 10s - loss: 88.4447 - acc: 0.005 - ETA: 10s - loss: 88.4000 - acc: 0.005 - ETA: 9s - loss: 88.3185 - acc: 0.005 - ETA: 9s - loss: 88.3353 - acc: 0.00 - ETA: 9s - loss: 88.1834 - acc: 0.00 - ETA: 8s - loss: 88.1583 - acc: 0.00 - ETA: 8s - loss: 88.2104 - acc: 0.00 - ETA: 8s - loss: 88.2357 - acc: 0.00 - ETA: 7s - loss: 88.1801 - acc: 0.00 - ETA: 7s - loss: 88.1758 - acc: 0.00 - ETA: 7s - loss: 88.0726 - acc: 0.00 - ETA: 6s - loss: 88.0546 - acc: 0.00 - ETA: 6s - loss: 88.0114 - acc: 0.00 - ETA: 6s - loss: 87.9485 - acc: 0.00 - ETA: 5s - loss: 87.8512 - acc: 0.00 - ETA: 5s - loss: 87.8489 - acc: 0.00 - ETA: 5s - loss: 87.8659 - acc: 0.00 - ETA: 4s - loss: 87.9657 - acc: 0.00 - ETA: 4s - loss: 87.9976 - acc: 0.00 - ETA: 4s - loss: 87.9767 - acc: 0.00 - ETA: 3s - loss: 88.0113 - acc: 0.00 - ETA: 3s - loss: 87.9771 - acc: 0.00 - ETA: 3s - loss: 87.9414 - acc: 0.00 - ETA: 2s - loss: 87.8940 - acc: 0.00 - ETA: 2s - loss: 87.8604 - acc: 0.00 - ETA: 2s - loss: 87.8612 - acc: 0.00 - ETA: 1s - loss: 87.9588 - acc: 0.00 - ETA: 1s - loss: 88.0313 - acc: 0.00 - ETA: 1s - loss: 88.0186 - acc: 0.00 - ETA: 0s - loss: 87.9599 - acc: 0.00 - ETA: 0s - loss: 87.9817 - acc: 0.00 - ETA: 0s - loss: 87.9671 - acc: 0.00 - 34s 3ms/step - loss: 88.0190 - acc: 0.0059 - val_loss: 97.7530 - val_acc: 0.0047\n",
      "Epoch 20/20\n",
      "11904/11904 [==============================] - ETA: 28s - loss: 90.2171 - acc: 0.007 - ETA: 29s - loss: 89.4275 - acc: 0.003 - ETA: 29s - loss: 88.0072 - acc: 0.005 - ETA: 29s - loss: 87.8967 - acc: 0.007 - ETA: 30s - loss: 87.6087 - acc: 0.007 - ETA: 30s - loss: 86.9492 - acc: 0.007 - ETA: 31s - loss: 86.7343 - acc: 0.006 - ETA: 31s - loss: 87.6414 - acc: 0.005 - ETA: 31s - loss: 87.7723 - acc: 0.006 - ETA: 31s - loss: 88.0255 - acc: 0.005 - ETA: 31s - loss: 87.9617 - acc: 0.005 - ETA: 30s - loss: 87.6914 - acc: 0.006 - ETA: 30s - loss: 87.7816 - acc: 0.006 - ETA: 30s - loss: 88.1381 - acc: 0.005 - ETA: 29s - loss: 88.4734 - acc: 0.006 - ETA: 29s - loss: 88.4033 - acc: 0.005 - ETA: 28s - loss: 88.0705 - acc: 0.005 - ETA: 27s - loss: 87.8707 - acc: 0.005 - ETA: 27s - loss: 88.0044 - acc: 0.004 - ETA: 26s - loss: 87.9990 - acc: 0.005 - ETA: 26s - loss: 87.7041 - acc: 0.004 - ETA: 25s - loss: 87.8027 - acc: 0.004 - ETA: 25s - loss: 87.8649 - acc: 0.005 - ETA: 25s - loss: 87.9155 - acc: 0.004 - ETA: 24s - loss: 87.8772 - acc: 0.005 - ETA: 24s - loss: 87.9010 - acc: 0.006 - ETA: 23s - loss: 87.9687 - acc: 0.006 - ETA: 23s - loss: 87.9921 - acc: 0.006 - ETA: 22s - loss: 87.6889 - acc: 0.006 - ETA: 22s - loss: 87.7614 - acc: 0.006 - ETA: 22s - loss: 87.6522 - acc: 0.005 - ETA: 21s - loss: 87.5505 - acc: 0.005 - ETA: 21s - loss: 87.6194 - acc: 0.005 - ETA: 20s - loss: 87.5450 - acc: 0.005 - ETA: 20s - loss: 87.5064 - acc: 0.005 - ETA: 20s - loss: 87.5359 - acc: 0.005 - ETA: 19s - loss: 87.3802 - acc: 0.005 - ETA: 19s - loss: 87.5450 - acc: 0.005 - ETA: 18s - loss: 87.5928 - acc: 0.005 - ETA: 18s - loss: 87.6466 - acc: 0.004 - ETA: 18s - loss: 87.7906 - acc: 0.005 - ETA: 17s - loss: 87.6658 - acc: 0.005 - ETA: 17s - loss: 87.5887 - acc: 0.005 - ETA: 17s - loss: 87.4979 - acc: 0.005 - ETA: 16s - loss: 87.4395 - acc: 0.005 - ETA: 16s - loss: 87.4784 - acc: 0.005 - ETA: 15s - loss: 87.6538 - acc: 0.005 - ETA: 15s - loss: 87.6547 - acc: 0.005 - ETA: 15s - loss: 87.7861 - acc: 0.005 - ETA: 14s - loss: 87.8902 - acc: 0.005 - ETA: 14s - loss: 87.8720 - acc: 0.005 - ETA: 14s - loss: 87.9339 - acc: 0.005 - ETA: 13s - loss: 87.8565 - acc: 0.005 - ETA: 13s - loss: 87.6617 - acc: 0.005 - ETA: 13s - loss: 87.6100 - acc: 0.005 - ETA: 12s - loss: 87.6401 - acc: 0.005 - ETA: 12s - loss: 87.6398 - acc: 0.005 - ETA: 11s - loss: 87.6113 - acc: 0.005 - ETA: 11s - loss: 87.6496 - acc: 0.005 - ETA: 11s - loss: 87.5682 - acc: 0.005 - ETA: 10s - loss: 87.5290 - acc: 0.005 - ETA: 10s - loss: 87.6117 - acc: 0.005 - ETA: 10s - loss: 87.6675 - acc: 0.005 - ETA: 9s - loss: 87.6133 - acc: 0.005 - ETA: 9s - loss: 87.6268 - acc: 0.00 - ETA: 9s - loss: 87.5645 - acc: 0.00 - ETA: 8s - loss: 87.5295 - acc: 0.00 - ETA: 8s - loss: 87.5534 - acc: 0.00 - ETA: 8s - loss: 87.6104 - acc: 0.00 - ETA: 7s - loss: 87.7571 - acc: 0.00 - ETA: 7s - loss: 87.6826 - acc: 0.00 - ETA: 7s - loss: 87.7862 - acc: 0.00 - ETA: 6s - loss: 87.8883 - acc: 0.00 - ETA: 6s - loss: 87.8532 - acc: 0.00 - ETA: 6s - loss: 87.9140 - acc: 0.00 - ETA: 5s - loss: 87.8519 - acc: 0.00 - ETA: 5s - loss: 87.8617 - acc: 0.00 - ETA: 5s - loss: 87.9485 - acc: 0.00 - ETA: 4s - loss: 87.9861 - acc: 0.00 - ETA: 4s - loss: 88.0133 - acc: 0.00 - ETA: 4s - loss: 87.9923 - acc: 0.00 - ETA: 3s - loss: 87.9670 - acc: 0.00 - ETA: 3s - loss: 87.9824 - acc: 0.00 - ETA: 3s - loss: 87.9583 - acc: 0.00 - ETA: 2s - loss: 87.9687 - acc: 0.00 - ETA: 2s - loss: 87.9339 - acc: 0.00 - ETA: 2s - loss: 87.9329 - acc: 0.00 - ETA: 1s - loss: 87.9692 - acc: 0.00 - ETA: 1s - loss: 87.9969 - acc: 0.00 - ETA: 1s - loss: 88.0326 - acc: 0.00 - ETA: 0s - loss: 87.9696 - acc: 0.00 - ETA: 0s - loss: 88.0602 - acc: 0.00 - 35s 3ms/step - loss: 87.9901 - acc: 0.0053 - val_loss: 97.7574 - val_acc: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-04 16:53:45,531] Finished a trial resulted in value: 0.00215053763441. Current best value is 0.00215053763441 with parameters: {'n_units_l1': 17.088067551657936, 'n_units_l0': 126.64573450984726, 'n_layers': 2, 'lr': 0.00015707417334894226, 'dropout_l0': 0.4049191965146334, 'dropout_l1': 0.34702893287427206}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11904 samples, validate on 2976 samples\n",
      "Epoch 1/20\n",
      "11904/11904 [==============================] - ETA: 2:38 - loss: 91.9796 - acc: 0.0000e+ - ETA: 1:34 - loss: 109.0968 - acc: 0.0039   - ETA: 1:12 - loss: 122.0803 - acc: 0.013 - ETA: 1:01 - loss: 127.8411 - acc: 0.009 - ETA: 54s - loss: 126.7900 - acc: 0.009 - ETA: 49s - loss: 125.9833 - acc: 0.00 - ETA: 46s - loss: 124.9159 - acc: 0.00 - ETA: 43s - loss: 123.3286 - acc: 0.01 - ETA: 41s - loss: 121.8100 - acc: 0.01 - ETA: 39s - loss: 120.8053 - acc: 0.01 - ETA: 38s - loss: 118.8243 - acc: 0.01 - ETA: 37s - loss: 116.9175 - acc: 0.01 - ETA: 36s - loss: 115.4949 - acc: 0.01 - ETA: 35s - loss: 114.0803 - acc: 0.01 - ETA: 34s - loss: 112.9304 - acc: 0.01 - ETA: 33s - loss: 111.9430 - acc: 0.01 - ETA: 32s - loss: 110.5766 - acc: 0.02 - ETA: 31s - loss: 110.4907 - acc: 0.01 - ETA: 30s - loss: 109.7073 - acc: 0.02 - ETA: 30s - loss: 108.8254 - acc: 0.02 - ETA: 29s - loss: 108.4154 - acc: 0.02 - ETA: 28s - loss: 107.5317 - acc: 0.02 - ETA: 28s - loss: 106.7479 - acc: 0.02 - ETA: 27s - loss: 106.2915 - acc: 0.02 - ETA: 27s - loss: 105.7266 - acc: 0.02 - ETA: 26s - loss: 105.3456 - acc: 0.02 - ETA: 26s - loss: 104.9214 - acc: 0.02 - ETA: 25s - loss: 104.5089 - acc: 0.02 - ETA: 25s - loss: 104.2374 - acc: 0.02 - ETA: 24s - loss: 104.1065 - acc: 0.02 - ETA: 24s - loss: 103.8963 - acc: 0.02 - ETA: 23s - loss: 103.7444 - acc: 0.02 - ETA: 23s - loss: 103.5335 - acc: 0.02 - ETA: 22s - loss: 103.5848 - acc: 0.02 - ETA: 22s - loss: 103.4652 - acc: 0.02 - ETA: 21s - loss: 103.4107 - acc: 0.02 - ETA: 21s - loss: 103.3320 - acc: 0.02 - ETA: 20s - loss: 103.2053 - acc: 0.02 - ETA: 20s - loss: 103.0798 - acc: 0.02 - ETA: 20s - loss: 102.9439 - acc: 0.02 - ETA: 19s - loss: 102.6370 - acc: 0.02 - ETA: 19s - loss: 102.5842 - acc: 0.02 - ETA: 18s - loss: 102.4983 - acc: 0.02 - ETA: 18s - loss: 102.2126 - acc: 0.02 - ETA: 18s - loss: 102.0691 - acc: 0.02 - ETA: 17s - loss: 101.8790 - acc: 0.02 - ETA: 17s - loss: 101.7493 - acc: 0.02 - ETA: 16s - loss: 101.5948 - acc: 0.02 - ETA: 16s - loss: 101.3752 - acc: 0.02 - ETA: 16s - loss: 101.0437 - acc: 0.02 - ETA: 15s - loss: 100.7709 - acc: 0.02 - ETA: 15s - loss: 100.5616 - acc: 0.02 - ETA: 14s - loss: 100.4271 - acc: 0.02 - ETA: 14s - loss: 100.4251 - acc: 0.02 - ETA: 14s - loss: 100.3734 - acc: 0.02 - ETA: 13s - loss: 100.3552 - acc: 0.02 - ETA: 13s - loss: 100.3034 - acc: 0.02 - ETA: 12s - loss: 100.3038 - acc: 0.02 - ETA: 12s - loss: 100.3681 - acc: 0.02 - ETA: 12s - loss: 100.2507 - acc: 0.02 - ETA: 11s - loss: 100.1665 - acc: 0.02 - ETA: 11s - loss: 100.0791 - acc: 0.02 - ETA: 11s - loss: 100.0218 - acc: 0.02 - ETA: 10s - loss: 100.0685 - acc: 0.02 - ETA: 10s - loss: 100.0809 - acc: 0.02 - ETA: 9s - loss: 100.2248 - acc: 0.0288 - ETA: 9s - loss: 100.1908 - acc: 0.028 - ETA: 9s - loss: 100.0393 - acc: 0.027 - ETA: 8s - loss: 100.0925 - acc: 0.027 - ETA: 8s - loss: 100.0511 - acc: 0.027 - ETA: 8s - loss: 100.0230 - acc: 0.028 - ETA: 7s - loss: 100.1052 - acc: 0.028 - ETA: 7s - loss: 100.1464 - acc: 0.029 - ETA: 6s - loss: 100.1631 - acc: 0.028 - ETA: 6s - loss: 100.0654 - acc: 0.028 - ETA: 6s - loss: 100.0485 - acc: 0.028 - ETA: 5s - loss: 99.9098 - acc: 0.029 - ETA: 5s - loss: 99.8831 - acc: 0.02 - ETA: 5s - loss: 99.7965 - acc: 0.02 - ETA: 4s - loss: 99.7325 - acc: 0.02 - ETA: 4s - loss: 99.6597 - acc: 0.02 - ETA: 4s - loss: 99.5597 - acc: 0.02 - ETA: 3s - loss: 99.4902 - acc: 0.02 - ETA: 3s - loss: 99.3994 - acc: 0.02 - ETA: 2s - loss: 99.4356 - acc: 0.02 - ETA: 2s - loss: 99.4294 - acc: 0.02 - ETA: 2s - loss: 99.4978 - acc: 0.02 - ETA: 1s - loss: 99.5621 - acc: 0.02 - ETA: 1s - loss: 99.6799 - acc: 0.02 - ETA: 1s - loss: 99.5432 - acc: 0.02 - ETA: 0s - loss: 99.5052 - acc: 0.02 - ETA: 0s - loss: 99.4602 - acc: 0.02 - 38s 3ms/step - loss: 99.4938 - acc: 0.0270 - val_loss: 108.4329 - val_acc: 6.7204e-04\n",
      "Epoch 2/20\n",
      "11904/11904 [==============================] - ETA: 29s - loss: 93.8326 - acc: 0.0000e+0 - ETA: 28s - loss: 94.4509 - acc: 0.0156    - ETA: 28s - loss: 94.6798 - acc: 0.010 - ETA: 28s - loss: 94.8848 - acc: 0.007 - ETA: 28s - loss: 96.5040 - acc: 0.023 - ETA: 29s - loss: 96.0172 - acc: 0.019 - ETA: 30s - loss: 95.7317 - acc: 0.016 - ETA: 29s - loss: 95.6644 - acc: 0.014 - ETA: 29s - loss: 95.8307 - acc: 0.013 - ETA: 28s - loss: 96.2001 - acc: 0.012 - ETA: 28s - loss: 95.9452 - acc: 0.012 - ETA: 27s - loss: 96.0812 - acc: 0.011 - ETA: 27s - loss: 96.6758 - acc: 0.010 - ETA: 27s - loss: 96.4723 - acc: 0.021 - ETA: 26s - loss: 95.9153 - acc: 0.020 - ETA: 26s - loss: 95.8395 - acc: 0.019 - ETA: 26s - loss: 95.8135 - acc: 0.018 - ETA: 25s - loss: 95.4617 - acc: 0.017 - ETA: 25s - loss: 95.6105 - acc: 0.018 - ETA: 25s - loss: 95.6264 - acc: 0.019 - ETA: 26s - loss: 95.6334 - acc: 0.020 - ETA: 25s - loss: 95.7156 - acc: 0.019 - ETA: 25s - loss: 95.8614 - acc: 0.019 - ETA: 25s - loss: 95.7229 - acc: 0.018 - ETA: 24s - loss: 95.7762 - acc: 0.017 - ETA: 24s - loss: 95.7609 - acc: 0.017 - ETA: 23s - loss: 95.9871 - acc: 0.016 - ETA: 23s - loss: 95.9623 - acc: 0.016 - ETA: 23s - loss: 96.0963 - acc: 0.015 - ETA: 24s - loss: 96.1848 - acc: 0.015 - ETA: 23s - loss: 95.9860 - acc: 0.017 - ETA: 23s - loss: 95.7271 - acc: 0.016 - ETA: 23s - loss: 95.6327 - acc: 0.016 - ETA: 23s - loss: 95.5687 - acc: 0.015 - ETA: 22s - loss: 95.5110 - acc: 0.015 - ETA: 22s - loss: 95.7137 - acc: 0.015 - ETA: 21s - loss: 95.9231 - acc: 0.015 - ETA: 21s - loss: 95.9740 - acc: 0.015 - ETA: 21s - loss: 96.0192 - acc: 0.015 - ETA: 20s - loss: 96.0674 - acc: 0.014 - ETA: 20s - loss: 96.1066 - acc: 0.014 - ETA: 19s - loss: 95.8534 - acc: 0.014 - ETA: 19s - loss: 95.7815 - acc: 0.014 - ETA: 18s - loss: 95.9467 - acc: 0.013 - ETA: 18s - loss: 95.9076 - acc: 0.014 - ETA: 18s - loss: 95.7647 - acc: 0.014 - ETA: 18s - loss: 95.6522 - acc: 0.019 - ETA: 17s - loss: 95.7969 - acc: 0.019 - ETA: 17s - loss: 95.6961 - acc: 0.018 - ETA: 16s - loss: 95.7906 - acc: 0.018 - ETA: 16s - loss: 95.8478 - acc: 0.018 - ETA: 15s - loss: 95.8138 - acc: 0.018 - ETA: 15s - loss: 95.9696 - acc: 0.018 - ETA: 15s - loss: 95.9515 - acc: 0.017 - ETA: 14s - loss: 96.0485 - acc: 0.018 - ETA: 14s - loss: 96.0523 - acc: 0.017 - ETA: 13s - loss: 96.0246 - acc: 0.017 - ETA: 13s - loss: 96.1065 - acc: 0.017 - ETA: 12s - loss: 96.0913 - acc: 0.016 - ETA: 12s - loss: 95.9913 - acc: 0.017 - ETA: 12s - loss: 96.0996 - acc: 0.017 - ETA: 11s - loss: 96.1292 - acc: 0.017 - ETA: 11s - loss: 96.2446 - acc: 0.017 - ETA: 10s - loss: 96.3589 - acc: 0.017 - ETA: 10s - loss: 96.3245 - acc: 0.017 - ETA: 9s - loss: 96.3108 - acc: 0.017 - ETA: 9s - loss: 96.3491 - acc: 0.01 - ETA: 9s - loss: 96.3337 - acc: 0.01 - ETA: 8s - loss: 96.3593 - acc: 0.01 - ETA: 8s - loss: 96.3153 - acc: 0.01 - ETA: 8s - loss: 96.2952 - acc: 0.01 - ETA: 7s - loss: 96.3307 - acc: 0.01 - ETA: 7s - loss: 96.3673 - acc: 0.02 - ETA: 6s - loss: 96.4414 - acc: 0.02 - ETA: 6s - loss: 96.4356 - acc: 0.02 - ETA: 6s - loss: 96.3959 - acc: 0.02 - ETA: 5s - loss: 96.3830 - acc: 0.02 - ETA: 5s - loss: 96.3992 - acc: 0.02 - ETA: 5s - loss: 96.4076 - acc: 0.02 - ETA: 4s - loss: 96.3582 - acc: 0.02 - ETA: 4s - loss: 96.3845 - acc: 0.02 - ETA: 3s - loss: 96.4259 - acc: 0.02 - ETA: 3s - loss: 96.5364 - acc: 0.02 - ETA: 3s - loss: 96.3958 - acc: 0.02 - ETA: 2s - loss: 96.4628 - acc: 0.02 - ETA: 2s - loss: 96.5189 - acc: 0.02 - ETA: 2s - loss: 96.4902 - acc: 0.02 - ETA: 1s - loss: 96.4259 - acc: 0.02 - ETA: 1s - loss: 96.3604 - acc: 0.02 - ETA: 1s - loss: 96.4199 - acc: 0.02 - ETA: 0s - loss: 96.4199 - acc: 0.02 - ETA: 0s - loss: 96.4820 - acc: 0.02 - 35s 3ms/step - loss: 96.5067 - acc: 0.0215 - val_loss: 107.2867 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4608/11904 [==========>...................] - ETA: 26s - loss: 94.0842 - acc: 0.0000e+0 - ETA: 26s - loss: 94.2237 - acc: 0.0469    - ETA: 25s - loss: 95.3590 - acc: 0.033 - ETA: 25s - loss: 94.9788 - acc: 0.027 - ETA: 25s - loss: 95.0872 - acc: 0.075 - ETA: 25s - loss: 94.9268 - acc: 0.079 - ETA: 24s - loss: 94.0652 - acc: 0.068 - ETA: 24s - loss: 94.2937 - acc: 0.059 - ETA: 24s - loss: 94.1822 - acc: 0.053 - ETA: 24s - loss: 93.7876 - acc: 0.052 - ETA: 24s - loss: 93.9828 - acc: 0.048 - ETA: 24s - loss: 93.8766 - acc: 0.044 - ETA: 23s - loss: 94.1594 - acc: 0.040 - ETA: 23s - loss: 94.3275 - acc: 0.039 - ETA: 23s - loss: 94.2761 - acc: 0.044 - ETA: 22s - loss: 93.8577 - acc: 0.041 - ETA: 22s - loss: 94.0409 - acc: 0.039 - ETA: 22s - loss: 94.3448 - acc: 0.037 - ETA: 21s - loss: 94.5616 - acc: 0.035 - ETA: 21s - loss: 94.7306 - acc: 0.034 - ETA: 21s - loss: 94.8821 - acc: 0.032 - ETA: 21s - loss: 94.9883 - acc: 0.030 - ETA: 20s - loss: 95.0759 - acc: 0.029 - ETA: 20s - loss: 94.9697 - acc: 0.036 - ETA: 20s - loss: 94.9410 - acc: 0.036 - ETA: 19s - loss: 95.1372 - acc: 0.035 - ETA: 19s - loss: 95.1999 - acc: 0.034 - ETA: 19s - loss: 95.2715 - acc: 0.032 - ETA: 18s - loss: 95.3055 - acc: 0.032 - ETA: 18s - loss: 95.4832 - acc: 0.031 - ETA: 18s - loss: 95.3863 - acc: 0.030 - ETA: 18s - loss: 95.2827 - acc: 0.029 - ETA: 17s - loss: 95.3064 - acc: 0.028 - ETA: 17s - loss: 95.6025 - acc: 0.027 - ETA: 17s - loss: 95.6717 - acc: 0.026 - ETA: 17s - loss: 95.7409 - acc: 0.0265"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fd24bd9be330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Study statistics: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/optuna/study.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/optuna/study.pyc\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/optuna/study.pyc\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Setting trial status as {}. {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-2c8eb092acca>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Evaluate the model accuracy on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=100)\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
